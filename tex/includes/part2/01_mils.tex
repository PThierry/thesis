%%
%%
%% hardware_impacts.tex for thesis in /doctorat/these/tex
%%
%% Made by Philippe THIERRY
%% Login   <Philippe THIERRYreseau-libre.net>
%%
%% Started on  Fri Mar 12 16:36:41 2010 Philippe THIERRY
%% Last update Mon Aug 30 17:00:21 2010 Philippe THIERRY

\chapter{Proposition d'une architecture logicielle sécurisée pour le MLS orientée traitement de flux}
\doMinitoc
\label{chap:solution_secu}

\section{Proposition d'architecture et choix structuraux}

\subsection{A propos du principe de passerelle de traitement de flux MultiLevel Security}
\label{sec:mls_gw_principle}

\paragraph{}
Dans le cadre de la problématique des systèmes Systronique, il est nécessaire
de considérer la colocalisation de domaines de sûreté et de sécurité disjoints
sur un même matériel. Cette exigence correspond à l'Exigence \hyperlink{REQSECUR005}{REQ\_SECUR\_005}
de la matrice de conformité du Chapitre \ref{sec:matrix}. Pour répondre à cette problématique, je propose
de définir une solution logicielle répondant aux besoins de Multiple
Independent Levels of Security
(MILS). En plus des contraintes de cloisonnements assurant une étanchéité
suffisante pour répondre aux exigences de sûreté et de sécurité, il est
également nécessaire de considérer des mécanismes logiciels permettant de
transférer de l'information entre les différents domaines de sécurité. Cette
contrainte correspond à l'Exigence \hyperlink{REQSECUR001}{REQ\_SECUR\_001} du Chapitre
\ref{sec:matrix}.
Ce transfert ne doit pas impacter les contraintes de sécurité de chacun des
domaines. Pour cela :
\begin{itemize}
  \item Les données transitant du niveau de sécurité le plus élevé au niveau
    de sécurité le plus bas doivent être complètement contrôlées, afin de valider que ces
    dernières peuvent être désensibilisées.
  \item Le flux transitant du niveau de sécurité le plus bas au niveau de
    sécurité le plus élevé n'exige pas de filtrage en terme de contenu.
    Cependant, l'action de transmission du flux ne doit pas fournir d'information
    sur le domaine de sécurité le plus haut aux éléments émetteurs ou tout autre
    élément du niveau de sécurité le plus bas.
\end{itemize}

\paragraph{}
Afin d'être compatible avec l'exigence de colocalisation, je m'appuie sur le
principe des systèmes MLS et MILS.
Les mécanismes définis pour répondre aux besoins de type MLS et MILS impliquent le
respect des exigences définies dans le Chapitre \label{sec:mils}, et
formalisées initialement en 2006 \cite{alves2006mils}.
Je m'appuie, dans le cadre de ma thèse, sur le principe de Separation Kernel,
compatible avec les systèmes MILS et MLS, auquel j'ajoute des modules de sécurité
complémentaires. L'ensemble est alors appelé Extended Secure Separation Kernel
(ESSK):

\PhDdefinition{essk}{Extended Secure Separation Kernel}{
  J'appelle Extended Secure Separation Kernel une architecture logicielle
  associant un socle logiciel assurant une compartimentation forte et des
  compartiments certifiables répondant à des exigences de sécurité. L'ensemble
  est intégrable comme une TCB (Trusted Computing Base) et ses principes de
  modularité lui permet de répondre à diverses exigences de sécurité.
}

Au dessus du Separation Kernel, je propose l'implémentation de modules logiciels
en charge de répondre aux mêmes besoins que les éléments de sécurité matériels
définis dans le cadre des systèmes d'information. Ces modules sont en charge de répondre aux
exigences fonctionnelles et sécuritaires décrite dans la Problématique.
L'architecture logicielle que j'ai choisie est décrite dans ce chapitre.

\subsection{À propos de la présence d'éléments non certifiables}
\label{sec:noncert}

\paragraph{}
La solution de passerelle systronique que je propose connecte des domaines
de sécurité disjoints. Elle
doit donc être compatible avec les propriétés \ref{pro:noncontournable},
\ref{pro:evaluable}, \ref{pro:validation} et \ref{pro:inviolable}
des architectures MLS.

\paragraph{}
Les solutions logicielles pour du traitement télécom, incluant entre autres
une implémentation d'une pile TCP/IP, sont trop volumineuses pour être
compatibles avec une certification de sécurité à haut niveau. De manière générale, seul
l'usage d'éléments logiciels à faible volumétrie de code permet de supporter
une telle certification à coût raisonnable.\\
Parce que l'implémentation logicielle d'un passerelle de type télécom ne peut être certifiée en
terme de sécurité, les éléments d'implémentation de celle-ci
sont donc considérés comme ne pouvant pas être de confiance. Il devient alors
nécessaire de définir :
\begin{itemize}
  \item deux famille logicielles $Sec$ et $Unsec$, l'une étant de confiance, l'autre non
  \item des mécanismes permettant de pouvoir intégrer des éléments non certifiables tout en
    assurant la sécurité du système dans son ensemble
\end{itemize}

\paragraph{}
Dans un premier temps, je définit pour les familles $Sec$ et $Unsec$ les
propriétés suivantes afin d'assurer un cloisonnement strict entre ce qui est
certifiable et ce qui ne l'est pas:

\begin{property}
$Sec$ définit l'ensemble des éléments logiciels certifiables. Ces derniers
sont aptes à contrôler des éléments matériels ou auditer d'autres éléments
logiciels de la famille $Sec$ et $Unsec$. Ces éléments font partie de la TCB
(Trusted Computing Base).
\end{property}

\begin{property}
$Unsec$ définit l'ensemble des éléments logiciels non-certifiables. Ces derniers
ne doivent pas accéder directement à un quelconque élément matériel, en dehors
de ma mémoire principale, dont l'accès est vérifié par la MMU.
\end{property}

\begin{property}
Aucun élément logiciel ne peut être à la fois sûr et non sûr:
$$Sec \cap Unsec = \emptyset$$
\end{property}

\begin{figure}
  \label{fig:iofilter}
  \input{figures/io_filtering.tex}
  \caption{filtrage des entrées/sorties par un élément logiciel de confiance}
\end{figure}

\paragraph{}
Les éléments logiciels non certifiables doivent donc être entourés d'éléments
logiciels de confiance (appartenant au groupe $Sec$) afin de valider
l'ensemble de leurs entrées/sorties. Ainsi, la propriété \ref{pro:validation}
des architectures MLS est respectée, comme le montre la Figure
\ref{fig:iofilter}.

\subsection{A propos des moniteurs de sécurité}

\paragraph{}
Il est montré dans la Section précédente que la présence d'éléments logiciels
non certifiables est un mal nécessaire pour permettre un certain nombre de
traitements à valeur ajoutée sur des flux télécoms. En effet, l'implémentation d'une pile
réseau certifiable étant trop couteuse, j'ai fait le choix d'intégrer de tels
logiciels, en prenant en compte le problème de non-certification associée dans
l'architecture.

\paragraph{}
Dans le Chapitre \ref{sec:noncert}, je montre que l'usage de tels logiciels peut
être envisagé si des éléments certifiables extérieurs sont présents, afin de
rester compatible avec les quatre exigences initiales des architecture MLS.
Dans le cadre de ma solution, je définit donc des éléments logiciels autonomes
et certifiables portant une fonction de sécurité. Par la suite, j'appelle ces éléments logiciels
des {\bf moniteurs de sécurité}:\\
\PhDdefinition{secumonit}{Moniteur de sécurité}{
  J'appelle moniteur de sécurité un élément logiciel autonome et certifiable
  portant une fonction de sécurité. Il a pour charge de répondre à un besoin
  sécuritaire particulier.
}

Les moniteurs de sécurité permettent de répondre aux différentes exigences du MLS car :
\begin{itemize}
  \item Ils valident les entrées/sorties des éléments non certifiables.
  \item Ils détectent et remontent les évènements invalides auprès d'un tiers
    de confiance.
  \item Ils assurent le cloisonnement entre les différents éléments logiciels
    et le matériel, pour assurer l'inviolabilité de l'ensemble de la TCB
    (confer Définition \ref{def:tcb}).
\end{itemize}

%%%%%%%%%%%%%%%%%%
\subsection{Synthèse des choix structuraux}

\paragraph{}
Dans ce chapitre, je décris les choix structuraux que j'ai fait dans le cadre
de la définition de la solution. J'ai caractérisé deux familles d'entités
logicielles répondant à des exigences disjointes, et j'ai proposé le principe
de moniteur de sécurité, autonome, permettant de respecter les exigences des
architectures MLS.\\
A partir de ces éléments, je vais définir l'architecture logicielle complète
permettant de répondre aux besoins d'une passerelle multi-domaines de
sécurité, telle que décrite dans la problématique.
Une validation de la compatibilité de ces choix structuraux a été
faite via un maquettage chez Thales donnant lieu à un premier brevet \cite{thierry2013part}.

\section{Caractérisation du risque sécuritaire}

\subsection{Définition des données à protéger}

\paragraph{}
J'ai identifié dans les Sections \ref{sec:mls_gw_principle} et
\ref{sec:mls_gw_hypothesis} les principes généraux qui doivent être considérés
dans le cadre de la définition d'une architecture logicielle pour le
traitement de données entre domaines de sécurité disjoints (i.e. MultiLevel
Security). En complément de ces principes généraux, permettant d'être
compatible avec le besoin MLS, il faut décrire plus en détail ceux nécessaires pour
répondre aux besoins de la problématique générale. Pour cela, je m'appuie
sur les principes de base d'une méthode qui a été proposée initialement par
l'ANSSI\footnote{Agence Nationale pour la Securité des Systèmes
  d'Information}, nommée EBIOS \cite{hemery2007utilisation}.
La méthode EBIOS permet de pouvoir définir un niveau de sécurisation
nécessaire et suffisant pour répondre au besoin sécuritaire du système cible.
Sans entrer dans
la rédaction d'un document EBIOS, trop volumineux dans le cadre de ma thèse,
je m'appuie néanmoins sur les principes présents derrière le formalisme de ce
type de document.

\paragraph{}
La définition de l'architecture logicielle pour le besoin d'une passerelle
multi-domaines de sécurité implique de répondre aux questions suivantes:

\begin{question}
  \label{que:donnees}
  Quelles sont les données à protéger ?
\end{question}

\begin{question}
\label{que:protec}
Quel(s) type(s) de protection la passerelle souhaite fournir sur ces
    données (confidentialité, intégrité, disponibilité) ?
\end{question}

\begin{question}
\label{que:threats}
Quels sont les attaques impactant ces protections dans le cadre de
    la solution ?
\end{question}

\begin{question}
\label{que:risque}
Pour chaque attaque, quel est le niveau de risque associé (probabilité
    de l'attaque, complexité technique, etc.)
\end{question}

\begin{question}
\label{que:foncsecu}
Quels sont les fonctions de sécurité nécessaires pour se prémunir
    contre chacune de ces attaques ?
\end{question}

\paragraph{}
Les sections suivantes mettent en pratique les principes de la méthode EBIOS
pour mettre en adéquation une solution technique avec les besoins sécuritaires
liés à la fonction passerelle multi-domaines. Ainsi, l'usage d'une fonction de
sécurité doit être mis en adéquation avec le risque sécuritaire auquel elle
répond. Lorsque la présence d'une fonction de sécurité dépasse le coût
(financier ou managérial) associé au risque sécuritaire, sa présence n'est
plus requise.\\
Néanmoins, dans le cadre de ma thèse, je cherche à pouvoir répondre à divers
niveaux de sécurité en fonction du positionnement de la passerelle et du type
de véhicule. Je dois donc répondre à des besoins sécuritaires plus ou moins
élevés. Je considère donc l'ensemble des attaques identifiées en
réponse à la Question \ref{que:risque} comme probables et je cherche à répondre
à chacune d'entre elles. 

\subsubsection{Définition des données à protéger}
\label{sec:donneeaproteger}

\paragraph{}
Dans le cadre de ma thèse, je cherche à répondre au besoin d'une passerelle
multi-domaines de sécurité et multi-domaines de criticité. La fonction de
cette passerelle est de permettre le transfert de flux réseau entre deux
domaines dont le niveau de sécurité et le niveau de criticité sont différents.
Aux propriétés du MLS décrites dans le Chapitre \ref{subsec:mls}, que le logicel
doit supporter, il faut également intégrer des exigences complémentaires liées
au flux de données transmis entre deux domaines de sécurité. En effet, la
capacité à transférer des données entre deux domaines de sécurité ne doit pas
impacter le cloisonnement général de ceux-ci. Ces exigences sont les suivantes
:

\begin{requirement}
\label{req:transit_up}
L'action de transmission des flux ne doit pas révéler d'information sur le domaine de
plus haute sécurité
\end{requirement}
La transmission de flux vers le domaine de plus haute sécurité ne doit pas
être dépendant de l'état d'exécution de ce dernier. Dans
le cas contraire, le domaine de sécurité le plus bas peut déterminer l'état
d'exécution du domaine de sécurité le plus haut, et peut récupérer de
l'information comme une clef de chiffrement, si le domaine de plus haute sécurité
fait varier son état d'exécution à son escient. Cette exigence est nécessaire
pour assurer la compatibilité de la solution avec les contraintes des systèmes
MLS.

\begin{requirement}
\label{req:desensibilisation}
Si les flux sont transmis du domaine de plus haute sécurité au domaine de
plus basse sécurité, ces derniers doivent contenir exclusivement des données autorisées à
être désensibilisées.
\end{requirement}
La désensibilisation d'information, qui correspond à autoriser le passage de
données d'un domaine de sécurité à un autre domaine de niveau inférieur,
implique la gestion d'une politique de filtrage permettant d'autoriser ou non
une telle désensibilisation. 

\begin{requirement}
\label{req:integrity}
Les flux transmis doivent être garantis en terme d'intégrité
\end{requirement}
En effet, si les données transmises sont modifiées, elles ne permettent plus
d'assurer une action valide de la part du domaine de plus haut niveau de
sécurité. Cette exigence correspond à l'Exigence \hyperlink{REQSECUR003}{REQ\_SECUR\_003} de la matrice
d'exigence de la solution, décrite dans le Chapitre \ref{sec:matrix}.


\begin{requirement}
  \label{req:escape}
  Les flux doivent transiter exclusivement dans la direction initialement choisie, au
  travers des canaux logiques et physiques initialement choisis
\end{requirement}
La présence de canaux logiques ou physiques non prévus entraine une faille
dans la mécanique de validation des flux transmis. Il devient possible de
transmettre de l'information sans contrôle par un moniteur de sécurité
certifiable, et rend la solution incompatible avec la propriété
\ref{pro:noncontournable} des systèmes MLS, et donc avec l'Exigence
\hyperlink{REQSECUR001}{REQ\_SECUR\_001}.

\paragraph{}
À partir de ces exigences, je détermine la répartition des responsabilités
sécuritaires en terme de confidentialité, intégrité et disponibilité.
\begin{itemize}
  \item La confidentialité des données, correspondant à l'Exigence
  \hyperlink{REQSECUR002}{REQ\_SECUR\_002}, est partagée entre:
    \begin{itemize}
      \item La configuration de la passerelle, qui est une donnée d'entrée de
        celle-ci donc en dehors du cadre de ma thèse. C'est cette
        configuration qui détermine entre autre quel type de flux est autorisé
        à transiter, et vers quelle destination. La configuration de la
        passerelle peut potentiellement intégrer des éléments nécessaires au
        bon fonctionnement de l'interconnexion réseau
      \item Les propriétés de cloisonnement de la passerelle, qui répondent
      également à l'exigence \ref{req:escape}
    \end{itemize}
  \item L'intégrité des données est assurée par la passerelle durant le temps
    de leur transit (en réponse à l'Exigence \hyperlink{REQSECUR003}{REQ\_SECUR\_003}).
  \item Comme précisé dans le cadre de la matrice de conformité aux
    contraintes de la problématiques générale, la disponibilité n'est pas
    considéré dans le cadre de ma thèse. A ce jour, la solution que je propose
    est donc incompatible avec l'Exigence \hyperlink{REQSECUR004}{REQ\_SECUR\_004} du Chapitre
    \ref{sec:matrix} 
\end{itemize}

\subsection{Intégration des problématiques réseaux}

\subsubsection{Problématique générale}

\paragraph{}
La solution consiste à permettre l'interconnexion sécurisée de deux domaines
indépendants, avec des exigences temps réel et sécuritaires.
Dans le cadre de la définition d'une telle architecture, la gestion des plans
d'adressage IP est problématique pour le respect de l'Exigence
\ref{req:transit_up}. Il est en effet nécessaire de permettre l'interconnexion
de deux services sur deux réseaux disjoints tout en assurant que ces derniers
ne soient pas capables de déterminer tout ou partie des informations réseaux
associées à l'autre service. Une telle problématique impacte fortement le
comportement de la passerelle.

\subsubsection{Intégration des proxys}
\label{subsec:sep_proto}

\paragraph{}
Il devient alors nécessaire de prévoir un mécanisme de séparation
protocolaire. Ce mécanisme doit répondre à plusieurs besoins:
\begin{itemize}
  \item En entrée, les en-têtes de niveau réseau et transport (couches OSI) doivent être
    retirées, afin d'empêcher toute information dérivant de ces en-têtes, comme le plan
    d'adressage IP
  \item En sortie, de nouvelles en-têtes appartenant au plan d'adressage de
    sortie doivent être construite pour se substituer aux précédantes.
\end{itemize}
On parle alors d'un mécanisme de séparation protocolaire \cite{baum2002protocol}. Ces
mécanismes impliquent l'usage d'applications de type proxy, se substituant d'une
part à la destination et d'autre part à la source afin de permettre une
interconnexion entre deux services de part et d'autre de la passerelle.

\paragraph{}
Une telle architecture est décrite dans la Figure \ref{fig:sep_proto}. Ainsi
l'ensemble des communications internes à la passerelle se font indépendamment
des protocoles couches 1 à 4, s'appuyant directement sur des buffers. L'usage
de proxys n'est pas forcément un mécanisme aisé. Les applications proxys
doivent être aptes à gérer des contextes de communications de manière
synchrone. Une telle synchronisation peut ainsi impliquer un mécanisme de
communication plus ou moins complexe entre les deux proxy corolaires.

\paragraph{}
Dans le cadre de ma thèse, les proxys sont considérés pour des protocoles
simples. Ainsi, on considère comme service un proxy spécialisé dans un
protocole de niveau application. Ce proxy est à l'écoute sur un port donné, et
interagit avec son corolaire dans l'autre domaine de sécurité, utilisant comme
source le même numéro de port. Il est considéré les restrictions suivantes :
\begin{restrictions}
 Pour un service donné, une et une seule destination (couple IP et port
 destination) est considéré par configuration.
\end{restrictions}
\begin{restrictions}
 Pour un service donné, un seul contexte est considéré à la fois, ne
 nécessitant ainsi pas de mécanisme de synchronisation.
\end{restrictions}

\paragraph{}
Un véritable mécanisme de passerelle doit être apte à traiter un ensemble de
flux reçus de manière concurrente par un même service. Cela implique alors
une capacité de synchronisation des contextes de flux entre le service entrant
et le service sortant afin de permettre la différentiation des flux en sortie,
tout en respectant l'exigence \ref{req:transit_up}.

\begin{figure}
  \label{fig:sep_proto}
  \input{figures/sep_proto.tex}
  \caption{Exemple de séparation protocolaire couche transport}
\end{figure}

\subsection{Définition des profils d'attaque}

\subsubsection{Généralités sur les profils d'attaques}

\paragraph{}
De la définition des Exigences \ref{req:integrity}, \ref{req:transit_up},
\ref{req:desensibilisation} et \ref{req:escape}, conséquentes à la conformité
à l'Exigence \hyperlink{REQSECUR001}{REQ\_SECUR\_001} du Chapitre \ref{sec:matrix}, 
il faut dériver des exigences techniques. Pour
cela, je détermine d'abord la surface d'attaque. On appelle surface d'attaque
les éléments d'interfaces à partir desquels on considère une attaque possible.
La surface d'attaque est décomposée en trois environnements disjoints:
\begin{enumerate}
  \item Les attaques externes initiées du coté du domaine de plus haute
    sécurité. Je considère alors qu'un éléments de ce domaine cherche à faire
    sortir de l'information non autorisée vers le domaine de plus faible
    sécurité, avec ou sans l'aide d'un élément de ce dernier
  \item Les attaques externes initiées du coté du domaine de plus faible
    criticité. Je considère qu'un élément du domaine de plus faible sécurité
    cherche à récupérer de l'information sur le domaine de plus haute
    sécurité, sans l'aide d'un élément de ce dernier
  \item Les attaques internes, venant des éléments de la passerelle
    appartenant à la famille $Unsec$, telle que décrite dans la Section
    \ref{sec:noncert}, impactantes pour l'exigence \ref{req:escape}
\end{enumerate}
Les éléments de la TCB (appartement à la famille $Sec$) sont considérés comme
de confiance. En conséquence, ils ne sont pas considérés comme source
d'attaque potentielle.\\
La Figure \ref{fig:threats_surface} schématise la répartition de la surface
d'attaque sur le système englobant la passerelle multi-domaines de sécurité.

\begin{figure}
  \label{fig:threats_surface}
  \input{figures/threats_surces.tex}
  \caption{Répartition des surfaces d'attaque sur la passerelle de sécurité}
\end{figure}

\paragraph{}
À ces trois surfaces d'attaque, on associe un niveau de faisabilité de
l'attaque, qui permet de déterminer le niveau de risque, et donc l'exigence de
protection associée. Dans le cadre de ma thèse, je cherche à définir une
solution modulaire associant des éléments non certifiables à des éléments
certifiables. Les domaines extérieurs à la solution ne sont de plus
pas connus initialement. Il n'est alors pas possible d'en déterminer le risque
sécuritaire associé. Pour répondre à un maximum de besoin, je considère alors le
risque élevé sur ces trois surfaces et je répond donc en terme de
contre-mesures de sécurité à l'ensemble de ces environnements.

\subsubsection{Définition des attaques et impact sur les exigences
 sécuritaires de la solution}

\paragraph{}
Cette Section décrit un certain nombre d'attaques connues impactant les
exigences de sécurité de la passerelle.\\
Le Tableau \ref{tab:threats} liste les différents types d'attaques et leur
impact sur les exigences de sécurité.

\begin{table}[h!]
\label{tab:threats}
\begin{tabular}{|l|p{8.5cm}|c|c|c|c|}
  \hline
\cellcolor{blue!25}Source & \cellcolor{blue!25}Attaque & \multicolumn{4}{|c|}{\cellcolor{blue!25}Exigence} \\
  \hline
  \multicolumn{2}{|c|}{ } & \ref{req:integrity} & \ref{req:transit_up} & \ref{req:desensibilisation} & \ref{req:escape} \\ 
  \hline
  {\it Domaine inférieur} & Étude temporelle de la vitesse de transit du flux vers le domaine supérieur & & X & & \\
  \hline
  {\it Domaine supérieur} & Émission de flux non conforme de la configuration de sécurité & & & X & \\
  \hline
  {\it Domaine supérieur} & Transfert de donnée par canal caché via variation du profil de flux & & & X & \\
  \hline
  {\it Interne} & Retransmission du flux au travers d'un canal non autorisé & & & & X \\
  \hline
  {\it Interne} & Modification du contenu du flux avant retransmission & X & & & \\
  \hline
  {\it Interne} & Écoute par canal auxiliaire d'un flux transitant par un autre compartiment pour retransmission & & & & X \\
  \hline
  {\it Interne} & Communication entre deux compartiments au travers d'un canal caché & & & & X \\
  \hline
\end{tabular}
\caption{Profils d'attaques et impact sur les exigences sécuritaires}
\end{table}

\paragraph{}
Ces différents comportements permettent de mettre à mal le principe de
cloisonnement associé à la passerelle inter-domaines, et doivent donc être
bloqués ou à défaut tracés.\\

\subsection{Synthèse du risque sécuritaire}

\paragraph{}
On peut constater que la surface d'attaque de la solution est grande et
nécessite un ensemble d'élements logiciels en charge de se prémunir contre les
différents types d'attaque recensés dans cette section.\\
Dans le cadre de ma thèse, je propose un certain nombre de solutions
(contre-mesures) permettant de réagir à ces attaques, ainsi qu'un certain
nombre d'éléments de protection, pour les rendre inefficaces ou à défaut
réduire leur portée et accroître leur complexité. Ces différents
éléments de sécurité sont construits sous forme de {\it moniteurs de
sécurité}, portant chacun une fonction de sécurité particulière. C'est au
travers de l'association de tous ces moniteurs qu'il est possible de
construire une solution répondant à l'ensemble des exigences de sécurité de
la problématique générale de la thèse (\hyperlink{REQSECUR001}{REQ\_SECUR\_001} à \hyperlink{REQSECUR006}{REQ\_SECUR\_006}).

% les moniteurs
\section{Définition des moniteurs de sécurité}

% exigence 1 : intégrité des données
\subsection{Protection de l'intégrité des données}

\subsubsection{Problématique générale}

\paragraph{}
Les moniteurs de sécurité décrits ici ont pour but d'assurer le respect de
l'Exigence \hyperlink{REQSECUR003}{REQ\_SECUR\_003}. L'intégrité des données transmises est une
exigence dont le but est d'assurer que le flux de données qui transite au
travers de la passerelle multi-domaines de sécurité n'est jamais modifié sans
autorisation préalable. Cela se fait usuellement en définissant une liste de
droits d'accès associé au flux, définissant quel élément logiciel (sujet) est
autorisé à accéder au contenu du flux (objet). Seuls les sujets explicitement
autorisés sont aptes à accéder à ces données et potentiellement les modifier.
Dans le cadre de l'architecture choisie, il est nécessaire de faire transiter
le flux télécom par des compartiments ne pouvant être considérés comme de
confiance. Il s'agit de compartiment appartenant à la famille $Unsec$, qu'il
est difficile de réimplémenter sans accroître fortement le coût financier de la
passerelle. Il devient alors nécessaire de prévoir des éléments de
contre-mesure, permettant de détecter toute modification non autorisée et de
réagir à celle-ci.

\subsubsection{A propos des moniteurs d'intégrité}

\paragraph{}
Dans le cadre de ma thèse, je propose l'implémentation d'un moniteur de
sécurité particulier, afin d'assurer l'intégrité des données transitant par la
passerelle. En effet, comme le montre la Figure \ref{fig:threats_surface},
certains composants de la passerelle ne peuvent être certifiés et sont donc
potentiellement attaquables ou corruptibles. Il devient donc nécessaire de
vérifier par un moyen certifiable que les données transitant par la passerelle
ne sont pas modifiées.

\paragraph{}
J'appelle moniteur d'intégrité un couple de deux compartiments logiciels, l'un
en entrée et l'autre en sortie, interagissant pour valider la signature des
données transitant dans la passerelle. Du fait du mécanisme de séparation
protocolaire, seule les données de la couches applicative sont vérifiées. Ces
deux compartiments s'intègrent en amont et en aval des compartiments télécoms et
plus généralement des compartiments de l'ensemble $Unsec$.\\
Le principe général est de calculer en amont et en aval la somme de contrôle
de l'ensemble des données de la couche applicative transitant par la passerelle.
Les deux moniteurs se partagent alors une mémoire afin que le second moniteur
vérifie l'existence de la somme de contrôle qu'il a calculé dans la liste fournie
par le premier moniteur. Une telle architecture logicielle implique plusieurs
exigences:
\begin{requirement}
  L'intégration de la signature dans la mémoire partagée doit être garantie avant
  l'arrivé du paquet dans le second moniteur.
\end{requirement}

\begin{requirement}
  Les données de la couche applicatives ne doivent pas être sectionnées. C'est
  une exigence dure car cela implique que la MTU en aval doit être suffisante
  pour tout type de paquet reçu en amont.
\end{requirement}

\begin{requirement}
  Des paquets peuvent être perdus ou droppés par un autre moniteur de sécurité
  (e.g. un filtre DPI). En conséquence, les sommes de contrôles doivent avoir
  une durée de présence dans la mémoire partagée maximum, pour éviter tout
  débordement.
\end{requirement}
Dans ma thèse, je considère la problématique temps réel et cherche à
déterminer la durée maximum de traversée d'un paquet. Ceci permet de déterminer
la durée de présence pire cas de la somme de contrôle (e.g. md5, sha1, sha2)
dans la mémoire partagée. En conséquence, si les flux valider en terme
d'intégrité sont dimensionnés (taille de trame, débit, burst), on peut alors
dimensionner la mémoire partagée nécessaire au bon fonctionnement du moniteur
d'intégrité. On peut alors respecter l'exigence suivante:

\begin{requirement}
La mémoire partagée est suffisamment grande pour permettre au moniteur amont
d'y ajouter les nouvelles sommes de contrôle au fur et à mesure de la
réception des paquets.
\end{requirement}

Bien que ce moniteur de sécurité n'a pas été validé dans le cadre de ma thèse,
les exigences nécessaire à son implémentation sont supportée au travers de
l'usage d'un moniteur de sécurité décrit ci-après, dans la Section
\ref{sec:emet_period}. Bien que ce moniteur de sécurité ne cible pas la
maîtrise du flux entrant pour des raisons de temps réel, il répond néanmoins
aux exigences ci-dessus.

% exigence 2 : sens unique 
\subsection{Garantie de transmission de flux sans canal auxiliaire inverse}

\paragraph{}
Le moniteur de sécurité décrit ici répond à l'Exigence \hyperlink{REQSECUR001}{REQ\_SECUR\_001}.
Sa présence doit assurer que tout flux transmis entre deux domaines de
sécurité puisse se faire sans que les propriétés de confidentialité du domaine
de plus haute sécurité ne soit impacté. Le but est d'assurer que le domaine de
plus faible niveau ne puisse pas récupérer d'information sur le domaine de
plus haute sécurité.

\paragraph{}
Il existe plusieurs cas qui doivent être considérés dans le cadre du besoin
associé à la Problématique générale:
\begin{enumerate}
\item Le transfert sens unique de données d'un domaine de plus faible niveau à un domaine
de plus haut niveau (Exigence \hyperlink{REQSECUR001}{REQ\_SECUR\_001})
\item Le transfert de flux désensibilisé d'un domaine de plus haut niveau de
sécurité vers un domaine de plus faible niveau de sécurité (Exigence \hyperlink{REQSECUR006}{REQ\_SECUR\_006})
\end{enumerate}

\subsubsection{A propos d'une architecture de diode logicielle pour le transfert de données}

\paragraph{}
Il existe dans l'état de l'art des solutions permettant d'assurer le transfert
de flux unidirectionnel entre deux domaines. C'est le cas des différentes
diodes matérielles \cite{sstic2006diode}. Ces solutions impliquent cependant de déployer
plusieurs équipements distincts dont la consommation et la volumétrie ne sont
pas toujours compatibles avec les exigences de l'embarqué.

\paragraph{}
Pour répondre à ce besoin, j'ai contribué à la rédaction de deux brevets
\cite{thierry2013dctrl}\cite{thierry2013daudit}
et à l'implémentation d'un moniteur de sécurité permettant de
répondre aux Exigences \hyperlink{REQSECUR001}{REQ\_SECUR\_006} et \hyperlink{REQSECUR001}{REQ\_SECUR\_006}, sans nécessiter l'usage de plusieurs matériels
distinct.\\
Pour répondre à ces exigences, il est nécessaire d'implémenter une fonction
logicielle dont le comportement est prévu pour assurer une opacité forte lors
du transit des données entre son entrée et sa sortie, quel que soit le
comportement des éléments source et destination du flux.\\
Ce moniteur de sécurité est accompagné d'une fonction d'audit, permettant de
remonter des informations statistiques sur son comportement, le rendant
compatible avec l'exigence \hyperlink{REQMAINT002}{REQ\_MAINT\_002}. Ce dernier ne nécessite par contre
pas de mécanisme de configuration, son comportement ne nécessitant pas de
traitement spécifique au flux qu'il fait transiter. Il est donc compatible
avec l'exigence \hyperlink{REQMAINT001}{REQ\_MAINT\_001}.

\paragraph{}
Ce moniteur de sécurité a été évalué avec succès dans le cadre d'une Cible de
Sécurité de Premier Niveau (CSPN), suivi d'une pré-évaluation au sens des
Critères Communs, de niveau EAL5+. De plus, ce moniteur de sécurité est
capable de garantir une latence de traversée maximum ainsi qu'un débit garanti
par construction, le rendant compatible avec l'exigence
\hyperlink{REQTEMPS001}{REQ\_TEMPS\_001}.\\
Ces travaux ont donné lieu à deux brevets \cite{thierry2013daudit}\cite{thierry2013dctrl},
mais la majorité des éléments techniques sont aujourd'hui maintenu secrets par
Thales. En conséquence, bien que ce moniteur de sécurité soit aujourd'hui une
réalité, je ne peux pas donner dans le cadre de ce document plus
d'informations sur son implémentation et son fonctionnement.

\subsubsection{Réponse à la problématique des canaux cachés et auxiliaires}
\label{sec:emet_period}

\paragraph{}
La transmission de données entre deux domaines de sécurité nécessite plusieurs
vérifications. Il y a tout d'abord le filtrage des données selon une politique
de sécurité donnée. Ce point est décrit dans la Section \ref{sec:dpi}.
Néanmoins, la vérification des données à transmettre n'est pas suffisante pour
garantir un cloisonnement efficace des deux domaines. En effet, indépendamment
de la donnée à transmettre, il est possible de construire un mécanisme
permettant de faire fuir de l'information au travers d'un canal caché: la
période inter-trame. Le principe est le suivant:
\begin{itemize}
  \item L'émetteur et le récepteur connaissent le protocole de transmission
    d'information cachées. Dans le cadre de ma thèse, je considère qu'il
    s'agit du suivant:
    \begin{itemize}
      \item Une durée inter-trame de 500 milisecondes correspond à la valeur
        \emph{0}.
      \item Une durée inter-trame de 1000 milisecondes correspond à la valeur
        \emph{1}.
    \end{itemize}
  \item L'émetteur émet des paquets dont le contenu est compatible avec la
    politique de sécurité avec une inter-arrivée variable, afin d'émettre de
    l'information binaire.
  \item Le récepteur reçoit les paquets et calcule la durée inter-trame. Il
    détermine si la période est proche des 500 milisecondes (la donnée est
    alors 0) ou proche de la seconde (la donnée est alors 1).
\end{itemize}

\paragraph{}
La durée des inter-arrivées reste élevée dans les deux cas pour que la présence des
filtres entre l'émetteur et le récepteur ne vienne pas impacter la mesure. En
s'appuyant sur ce mécanisme, il est possible de transférer une clef symétrique
de 128 bits dont la confidentialité est restreinte au domaine de plus haut niveau de sécurité
en moins de deux minutes.

\paragraph{}
Afin d'empêcher l'usage de ce canal caché, je propose dans le Chapitre
\ref{sec:passsystronique} l'implémentation d'un
moniteur de sécurité appelé émetteur périodique. L'automate à état de ce
moniteur est le suivant:

\begin{figure}[h!]
Soit $s$ le numéro courant de cellule du buffer interne\\
Soit $S$ le nombre total de cellules du buffer interne\\
Soit $t$ la durée depuis la dernière émission de trame\\
Soit $T$ la période inter émission\\
\begin{center}
\input{figures/emet_periodique.tex}        
\end{center}
\caption{Automate du moniteur de sécurité émetteur périodique\label{fig:emet_period}}
\end{figure}

\paragraph{}
Ce moniteur de sécurité est en charge de bufferiser les données à émettre
pour les transmettre ensuite de manière périodique, à l'unité ou par burst.
Si aucun paquet n'est reçu entre deux vidanges du buffer, le dernier paquet
est réémis en lieu et place. Le but d'un tel comportement est d'empécher
l'utilisation d'un canal caché basé sur l'émission ou la non-émission de
paquet, comme décrit plus haut.\\
Etant donné que la profondeur du buffer de réception du moniteur est fixe, et
que l'inter-émission est un paramètre d'entrée, l'émetteur périodique ne peut
dépasser un débit de paquet maximum. En conséquence, il peut être amené à
dropper des paquets si le buffer de réception est plein, comme le montre la
Figure \ref{fig:emet_period}. Ce moniteur de sécurité doit donc gérer des
compteurs de drop, auditable par un élément d'audit externe. La mécanique
d'audit utilisable peut être similaire à celle décrite dans un des brevets que
j'ai co-écrit \cite{thierry2013daudit}, car les données audités sont
identiques.

\paragraph{}
L'usage d'un tel moniteur implique des hypothèses sur le flux réordonnancé. Ce
dernier doit en effet supporter la perte de certains paquets sans pour autant
remettre en cause son usage. Il doit de plus supporter la possibilité de
recevoir des données dupliquées, lors de la réémission de paquet en cas de
buffer vide. Bien que ces hypothèses soient fortes, elles correspondent à un
certain nombre de flux utilisés dans les systèmes systroniques entre plusieurs
domaines de sécurité. C'est le cas des diverses remontées de sondes comme le
positionnement GPS, les données de température ou encore les éléments de
positionnement géographique de plusieurs véhicules dans le cadre d'un système
de cartographie. Ainsi, ce moniteur peut limiter l'usage de canaux cachés
entre deux domaines de sécurité pour un grand nombre de flux spécifiques à la
systronique.

%%%%%%%%%%%%%% END
% conformité du flux à une politique de sécurité
\subsection{Conformité des données transmises à la politique de sécurité}

\paragraph{}
Les moniteurs de sécurité de cette section répondent à l'exigence
\ref{req:desensibilisation}. Il en existe plusieurs car cette exigence
implique plusieurs fonctions, à la fois sur le contenu transmis et sur le
comportement du flux, afin d'empêcher l'usage d'un canal auxiliaire de type
temporel.

\subsubsection{Moniteurs de sécurité pour la vérification des données}
\label{sec:dpi}

\paragraph{}
Il est habituellement demandé, dans le cadre d'un transfert de données entre deux
domaines de sécurité, de prévoir un mécanisme garantissant la validité des
contenus à transmettre auprès d'une politique de sécurité prédéfinie. On
parle alors d'un filtre dit DPI (Deep Packet Inspection) \cite{smith2008deflating}\cite{kumar2006algorithms}.

\PhDdefinition{dpi}{Deep Packet Inspection}{
  On appelle DPI l'ensemble des fonctions en charge de valider un ou plusieurs
  flux réseau afin de garantir que son contenu, mais également son
  comportement (profil, débit, émetteur, destination, etc.) sont conformes
  d'une politique de sécurité.
}

\paragraph{Problématique générale du DPI}
Un tel moniteur de
sécurité est plus ou moins complexe selon le besoin.
La problématique de cette fonction est la grande difficulté à pouvoir
déterminer une borne supérieure au traitement DPI. Une fonction DPI
correspondant à un ensemble de traitements unitaires successifs sur un ou
plusieurs flux, c'est typiquement une fonction candidate au principe de
criticité mixte, afin de pouvoir garantir une borne supérieure à l'exécution
de la fonction DPI sur un paquet réseau donné. A ce jour, les travaux de
l'état de l'art sur le DPI ne prennent pas en considération la contrainte
d'exécution bornée. Dans le cadre de ma thèse je n'ai néanmoins pas étudié
de manière détaillée la fonction DPI, cette dernière étant particulièrement
complexe est sujet de nombreux travaux qui lui sont dédié encore aujourd'hui.

\paragraph{Fonction DPI et passerelle multi-niveaux de sécurité}
Étant donné que la passerelle intègre un mécanisme de séparation protocolaire
(décrit dans la Section \ref{subsec:sep_proto}), il
n'est pas nécessaire, dans le cadre de ce moniteur, de prendre en
considération les couches transport et inférieures de la pile TCP/IP. Seule la couche
applicative est considérée. Selon le type de protocole de niveau application
utilisé dans le cadre du transfert de données, il peut être nécessaire
d'attendre la fin de transmission avant de pouvoir valider les données. C'est
clairement le cas si l'on fait transiter des données de types XML, trop
grosses pour être traitées au travers d'un seul paquet. Il devient nécessaire
de dimensionner la mémoire du moniteur de sécurité afin de lui permettre de
stocker l'information jusqu'à être apte à la valider auprès d'une politique de
sécurité. Un tel stockage implique également un accroissement de la latence de
traversée de la passerelle égale au pire cas d'attente de l'ensemble des
paquets nécessaire à la validation de l'ensemble du flux.\\
La complexité du filtre DPI est directement dépendante de la complexité du
protocole à traiter et de la politique de sécurité afférente. Je considère
donc qu'un filtre DPI est spécialisé pour un protocole donné. Il en va de même
pour la politique de sécurité associée pour ce protocole.\\
Le filtre DPI est directement lié au protocole qu'il traite. Ainsi, une
passerelle multi-protocoles implique de considérer un ensemble de filtres DPI.
Je considère dans le cadre de ma thèse que le moniteur de sécurité de filtrage
DPI gère l'ensemble des filtres DPI associés à l'ensemble des protocoles
devant être transmis. Ces derniers sont regroupés, pour des raisons de
performances, dans un seul compartiment, avec une gestion de priorisation et
d'ordonnancement qu'il est nécessaire de considérer afin de garantir le bon
fonctionnement de l'ensemble des filtres.

\paragraph{}
Il est également nécessaire de considérer un mécanisme permettant de flasher, dans le cadre
d'une préparation de mission, la politique de sécurité du filtre. Ce mécanisme
ne doit être actif que durant le cycle de préparation, et débrayé une fois la passerelle en
mode de fonctionnement nominal. En général, on s'appuie sur une connexion
locale (e.g. via une interface UART) au travers
d'un port physique sécurisé une fois placé dans l'enceinte du véhicule.
Je n'ai pas pris en compte la problématique de gestion du flashage de
politiques de sécurité, cette dernière ayant déjà des réponses dans le cadre
des travaux existants dans les radios militaires (sans références dans le
cadre de ma thèse car soumis à des exigences de confidentialité fortes).

% canaux cachés internes et compartimentation
\subsection{Compartimentation garantie}

\paragraph{}
Il a été décrit dans la Section \ref{sec:noncert} l'usage, dans la passerelle, d'éléments non
certifiables (éléments appartenant à l'ensemble $Unsec$). Pour être compatible
avec les Exigences \hyperlink{REQSECUR001}{REQ\_SECUR\_001} et 
\hyperlink{REQSECUR005}{REQ\_SECUR\_005},
il est nécessaire d'assurer que l'ensemble des canaux de communications
utilisés sont explicitement ceux qui ont été validés dans le cadre de la
définition de l'architecture. La compartimentation garantie est faite au
niveau du micro-noyau de sécurité (SSK, Secure Separation Kernel), au travers
d'un ordonnancement TDM strict avec une séparation spatiale entre chaque
compartiment logiciel. Le SSK que j'ai choisi est le micro-noyau PikeOS de la société
Sysgo, pour sa compatibilité avec les différentes exigences du MILS, comme
décrit dans la Section \ref{sec:pikeos}. De plus, sa récente certification \cite{pikesil4}
SIL (Safety Integrity Level - ISO 26262 \cite{iso26262web}) niveau 4 fait de lui un bon candidat pour les
contraintes véhiculaires.

\section{Problématique d'exploitation des canaux auxiliaires}
\label{sec:caches}

\subsection{Caches processeurs et canaux cachés}

\paragraph{}
L'usage de canaux auxiliaires basés sur le temps de réponse des accès mémoire
au travers des contrôleurs de caches est aujourd'hui connu et efficace pour la
transmission de données entre deux compartiments
\cite{percival2005cache}\cite{bernstein2005cache}. Il existe différentes
manières de répondre à ce problème. La plus simple consiste à s'appuyer sur
des c{\oe}urs processeurs différents pour chaque domaine de sécurité, tout en
débrayant les caches partagés entre les c{\oe}urs. Selon l'architecture
matérielle, la désactivation des caches partagés est plus ou moins impactante
sur les performances du logiciel, au point de rendre ce dernier complètement
inefficace. Dans ce cas, l'usage d'une architecture multi-CPU en lieu est
place d'un SoC mono-CPU et multi-c{\oe}urs permet d'éviter un partage trop conséquent des
contrôleurs de caches. Cependant, dans le cadre de ma thèse, l'usage d'une
architecture multi-CPU est incompatible avec les exigences de consommation.\\
Un autre moyen est de positionner temporellement les domaines de sécurité de
manière à ce qu'à un instant $t$, un et un seul domaine de sécurité s'exécute.
Lors du changement de domaine, les caches sont alors flushés afin de ne pas
transmettre d'information. Il est alors nécessaire de prendre en compte
l'impact du flush de cache sur l'exécution de la solution.
J'ai donc proposé un mécanisme permettant de
supporter l'intégration, sur un même c{\oe}ur du processeur, de plusieurs domaines de sécurité tout
en contrecarrant les attaques de type analyse de temps d'accès à la mémoire au travers du
contrôleur de cache. La proposition cible exclusivement le sans
permettre cache L1 data. Le cache L1 code et le TLB (Translation Lookaside
Buffer) ne sont cependant pas pris en compte. 

\subsection{Hypothèses sur le comportement du contrôleur de cache proposé}

\paragraph{}
Dans le cadre de ma thèse, j'ai travaillé sur un mécanisme de partitionnement
du contrôleur de cache L1 data. Je m'appuie sur les principes généraux des
caches partitionnés considérés dans le temps réel \cite{coopcachepart}, mais pour des besoins
sécuritaire.\\
Ainsi, la solution que je propose a pour but de partitionner le contrôleur de
cache en fonction des domaines de sécurité s'exécutant. Le nombre de partition
est alors égal au nombre de domaines de sécurité, auquel on
ajoute une partition pour le {\it Secure Separation Kernel}.\\
Je considère que le domaine de plus faible sécurité est limité à
un et un seul compartiment, ordonnancé dans un c{\oe}ur du processeur où deux
domaines de sécurité sont ordonnancés.
Le contrôleur de cache n'ayant pas une mémoire extensible, je définit un
nombre maximum de slots limité (égal à huit dans mon étude). Chaque
slot se comporte de manière autonome avec un nombre de ligne de cache
configurable, ceci afin d'avoir une plus grande liberté dans la découpe du
contrôleur de cache. Le principe de partitionnement est décrit plus loin.
Je prend comme hypothèse que la politique de substitution des lignes de caches de chaque
slot reste identique à l'état de l'art. Le nombre de ligne de cache de
chacun d'entre eux doit donc être compatible de l'algorithme de substitution
considéré. Par exemple, dans le cas d'un algorithme pseudo-LRU de type 4-ways,
chaque compartiment doit alors pouvoir fournir un nombre
de lignes de caches multiple de quatre.

\subsection{Formalisme de l'interface de contrôle du contrôleur de cache}

\paragraph{}
Le contrôleur de cache fournit jusqu'à huit slots dans lesquels les
contextes de caches de chaque domaine de sécurité sont maintenus. Il reste
nécessaire de pouvoir configurer le contrôleur de cache afin de
pouvoir passer d'un domaine de cache à un autre. Cette configuration doit être
faite par un élément de confiance en charge du changement de domaine de
sécurité, qui correspond, dans le cadre de l'architecture logicielle que j'ai
choisie, au {\it Secure Separation Kernel}. Cela implique de la part de la routine de
configuration du contrôleur certaines propriétés:
\begin{itemize}
  \item La routine est positionnée dans un espace mémoire non-cachable ou
    durant un laps de temps où le cache n'est pas actif
  \item La routine doit être la plus petite possible (pour des raisons de
    performances)
  \item La routine doit être exécutée en mode superviseur exclusivement
\end{itemize}

\paragraph{}
Une fois la mécanique de partitionnement active, les canaux auxiliaires
de type mesure de temps ne doivent plus être utilisables. Les exigences
suivantes doivent alors être respectées par le contrôleur de cache:

\begin{requirement}
\label{sec_hyp_1}
L'usage du contrôleur de cache par une partition logicielle donnée ne doit pas avoir
d'impact sur l'état du cache d'une autre partition.
\end{requirement}
\begin{requirement}
\label{sec_hyp_2}
Une partition logicielle donnée ne doit pas pouvoir accéder à l'état du cache d'une autre
partition logicielle.
\end{requirement}

\begin{requirement}
\label{global_hyp_2}
L'hyperviseur doit être capable de configurer les slots du contrôleur de cache.
Cette configuration, qui initie le mode partitionné du cache, doit
avoir pour conséquence un flush du cache afin de retirer toute ligne de cache
préexistante.
\end{requirement}

\begin{requirement}
\label{global_hyp_2}
L'hyperviseur doit être capable de changer le slot de cache actif. Ce
changement doit être rapide et ne doit pas impacter le contenu du slot de
cache précédemment actif, ni celui sur le point d'être activé.
\end{requirement}


\begin{requirement}
\label{global_hyp_3}
Les évènements externes asynchrones (type interruption matérielle) doivent
être supportés. La routine de gestion de l'interruption ne doit pas impacter
la partition de cache en cours d'exécution lors de l'interruption, mais
s'exécuter dans la partition de cache dédiée à l'hyperviseur.
\end{requirement}

\begin{requirement}
\label{global_hyp_4}
Le contrôleur de cache doit supporter un mode générique non partitionné, actif
par défaut à l'initialisation du contrôleur sans aucune configuration par le
logiciel.
\end{requirement}

\subsection{Description de l'interface de contrôle du partitionnement du contrôleur de cache}

\paragraph{}
Dans cette Section, je décrit une proposition d'interface matérielle
permettant au logiciel de gérer une décomposition du contrôleur de cache en
plusieurs slots indépendants. Cette interface cherche à être simple d'usage
pour l'implémentation logicielle tout en supportant un comportement générique
non partitionné par défaut.

\subsection{Principe et automate}

Afin de limiter au maximum la taille du code traitant de la configuration du
contrôleur de cache, cette dernière a été définie sur une base de quelques
registres spécifiques. 

\begin{figure}[h!]
\label{fig:arch_design}
\input{figures/arch_design.tex}
\caption{Design d'architecture macroscopique du Contrôleur de cache L1 data proposé}
\end{figure}

Le contrôleur de cache possède plusieurs états:
\begin{itemize}
  \item Désactivé. Le contrôleur est alors complètement désactivé et ne fait
    que transférer les requêtes du processeur vers la mémoire centrale
  \item configuration générique, le contrôleur se comporte alors comme un
    contrôleur de cache classique. C'est sa configuration par défaut
  \item Partitionné. Le contrôleur a été configuré et activé. La partition
    active est celle qui a été sélectionnée lors de la configuration
\end{itemize}


\begin{figure}[h!]
	\begin{center}
		\begin{tt}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
				            thick,every label/.style={draw,black}]
		\tikzstyle{every state}=[fill=white,rectangle,draw=black,text=black, rounded corners = 3]
		\tikzstyle{trait}=[rectangle,fill=white,inner sep=0pt,rounded corners = 10]
		\tikzstyle{traite}=[ellipse,fill=white,inner sep=0pt,rounded corners = 10]
		  
		\node[state]		(desac)		at (0,14) {Désactivé};
		\node[state]		(gen)		at (0,10) {
                  \begin{tabular}{c}
                    Configuration\\
                    générique
                  \end{tabular}
                };
		\node[state]		(part)		at (0,6) {Partitionné};
		
		\path 		(desac)	edge[bend right]        node[left] {\footnotesize Activation}	(gen)
				(gen)	edge[bend right]	node[right] {
                                  \begin{tabular}{c}
                                    \footnotesize Désactivation \\
                                    \footnotesize $flush$ \\
                                  \end{tabular}
                                }	(desac)
				(gen)	edge[bend right]	node[left] {
                                  \begin{tabular}{c}
                                    \footnotesize Validation\\
                                    \footnotesize de configuration \\
                                    \footnotesize $flush$ \\
                                  \end{tabular}
                                }	(part)
				(part)	edge[bend right]	node[right] {
                                  \begin{tabular}{r}
                                  \footnotesize Reset \\
                                    \footnotesize $flush$ \\
                                  \end{tabular}
                                }	(gen)
				(part)	edge[bend left=90]	node[left] {
                                  \begin{tabular}{c}
                                    \footnotesize Désactivation \\
                                    \footnotesize $flush$ \\
                                  \end{tabular}
                                }	(desac)
				(gen)	edge[loop right]	node[] {
                                  \begin{tabular}{c}
                                    \footnotesize Configuration \\
                                    \footnotesize du partitionnement
                                  \end{tabular}
                                }	(gen);
		\end{tikzpicture}
		\end{tt}
	\end{center}
        \caption{Automate à état du contrôleur de cache\label{fig:cache_automaton}}
\end{figure}

\subsubsection{Définition des registres de contrôle}

\paragraph{}
J'ai défini un premier registre, que je dénote PCR (\emph{Partition Control
  Registrer}).  Ce dernier est décrit dans la Figure \ref{fig:pcr}\\

%%%%%%%%%%%%%%%%%%%%% PCR register structure %%%%%%%%%%%%%%%%%%%%%
\begin{center}
  \begin{figure}[h!]
    \begin{bytefield}[boxformatting={\centering\itshape},
      bitwidth=0.8em]{32}
      \bitheader[b]{31,30,29,14,13,10,9,3,2,1,0} \\
      \bitbox{1}{\tiny A/B} & \bitbox{1}{\tiny H} & \bitbox{16}{\tiny Reserved} & \bitbox{4}{\tiny slot count} & \bitbox{7}{\tiny Reserved} & \bitbox{1}{\tiny H\\V\\M}& \bitbox{2}{\tiny SBF}\\
    \end{bytefield}
    \caption{Structure du registre PCR\label{fig:pcr}}
  \end{figure}
\end{center}

La description des différents champs du registre PCR est faite dans le
Tableau \ref{tab:pcr}.
%%%%%%%%%%%%%%%%%%%%% PCR register table %%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{table}[h!]
\begin{tabular}{|l|p{12cm}|c|}
\hline
\textsc{champ} & \textsc{signification} & \textsc{droits} \\
\hline
bit A/B & 
\begin{minipage}{12cm}
\vspace{2mm}
Bit d'activation. Positionné à 0 au boot. Doit être positionné à 1 afin
d'activer le mécanisme de partitionnement du contrôleur de cache. L'ensemble
de la configuration du contrôleur doit être fait au moment où ce bit est mis
à 1. La mise à 1 de ce bit implique un changement d'état du contrôleur de
cache de l'état générique à l'état partitionné. L'ensemble des données en
cache à cet instant sont flushées.
\vspace{2mm}
\end{minipage} &
RW
\\
\hline
bit H &
\begin{minipage}{12cm}
\vspace{2mm}
Fige la configuration du contrôleur de cache. Si positionné à 1, plus aucune
configuration des slots du contrôleur de cache ne peut être effectuée, y
compris par l'hyperviseur. Seul le retour en mode générique peut être
effectuée, via la mise à 0 du bit A/B. Ce retour implique un flush complet des
lignes de cache.
\vspace{2mm}
\end{minipage} &
RW
\\
\hline
Slot count & 
\begin{minipage}{12cm}
\vspace{2mm}
Spécifie le nombre de slots qui seront utilisés. L'hyperviseur doit spécifier
le nombre de slots configurés dans ce
champ, avant de rendre la configuration active. Le nombre de slot doit être
inférieur au nombre de slots maximum (définit à huit dans l'étude).
\vspace{2mm}
\end{minipage} &
RW
\\
\hline
HVM & 
\begin{minipage}{12cm}
\vspace{2mm}
Active le support HVM (Hardware Virtual Machine). Le but est de permettre une
gestion par le mécanisme de gestion de la virtualisation plutôt que par
l'hyperviseur. Il s'agit d'une prise en compte pour un usage futur, et n'est
pas considéré dans le cadre de ma thèse.
\vspace{2mm}
\end{minipage} &
RW
\\
\hline
SBF &
\begin{minipage}{12cm}
\vspace{2mm}
Ce bit (Status Bit Field) est renseigné par le contrôleur de cache lors du
passage en mode partitionné. Une
relecture du registre permet de récupérer la valeur de ce champ. Si SBF vaut
00, la configuration est valide et le contrôleur est passé en mode partitionné.
Dans le cas contraire, le cache est resté en mode générique. Le status de la
configuration est alors accessible dans ce même registre, avec le tableau de
correspondance ci-dessous:
\begin{itemize}
\item {\texttt{00}}: configuration active
\item {\texttt{01}}: l'espace total consommé est trop grand. Il faut vérifier la taille des
  slots et leur nombre.
\item {\texttt{10}}: conflit sur la taille d'un ou plusieurs slots. Le nombre
  de lignes de caches ne permet pas l'usage de l'algorithme Pseudo-LRU 4-ways
  (le nombre de lignes de cache doit être un multiple de 4).
\item {\texttt{11}}: {\it usage futur}
\end{itemize}
\vspace{2mm}
\end{minipage} &
RO
\\
\hline
\end{tabular}
\caption{Description des champs du registre PCR\label{tab:pcr}}
\end{table}
\end{center}

Le registre PCR permet d'activer et de valider la configuration globale du
mode partitionné du cache. Néanmoins, il ne spécifie pas la taille des
différents slots.
Dans le cadre de ma thèse, je souhaite pouvoir supporter des tailles de
slots configurables. En effet, afin de ne pas sous consommer le cache,
ou de pouvoir, dans le cadre d'un compartiment logiciel particulier, accroître
la taille du slot associé pour des raisons de performances, j'ai rendu la
taille de chaque slot configurable. Néanmoins, il existe des restrictions:
\begin{itemize}
  \item La taille d'un slot (en nombre de lignes de cache) doit être
    compatible avec l'algorithme de substitution choisi (e.g. pseudo-LRU
    4-ways).
  \item La somme des tailles de slots actifs doit être inférieure ou égale à
    la taille totale de l'espace mémoire du contrôleur de cache.
\end{itemize}

La configuration des slots est faite dans les différents registre SCR (Slot
Configuration Register). Il en existe 8, pour un nombre de slots maximum de 8.


%%%%%%%%%%%%%%%%%%%%% SCR table structure %%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{figure}[h!]
\begin{bytefield}[boxformatting={\centering\itshape},bitwidth=0.8em]{32}
\bitheader[b]{31,30,15,14,0} \\
\bitbox{1}{\tiny A\\B} & \bitbox{16}{\tiny Slot size} & \bitbox{15}{\tiny {\it reserved}}\\
\wordbox[lr]{1}{} \\
\skippedwords \\
\wordbox[lr]{1}{} \\
\bitbox{1}{\tiny A\\B} & \bitbox{16}{\tiny Slot size} & \bitbox{15}{\tiny {\it reserved}}\\
\end{bytefield}
\caption{Slot configuration table\label{fig:sct}}
\end{figure}
\end{center}

Chaque registre SCR définit la configuration d'un slot. Sa structure est
définie dans le Tableau \ref{tab:cssr}. Par défaut, l'ensemble de ces
registres ont une valeur mise à 0x0.


%%%%%%%%%%%%%%%%%%%%% SCR register table %%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{table}[h!]
\begin{tabular}{|l|p{12cm}|c|}
\hline
\textsc{champ} & \textsc{signification} & \textsc{droits} \\
\hline
AB &
\begin{minipage}{12cm}
\vspace{2mm}
Bit d'activation. Sa valeur par défaut est 0. Si l'hyperviseur change sa
valeur pour 1, le contrôleur de cache, au moment de la validation de la
configuration, considère le slot actif, et utilise alors les valeurs des
autres champs pour configurer le slot.
\vspace{2mm}
\end{minipage} &
RW
\\
\hline
Slot size &
\begin{minipage}{12cm}
\vspace{2mm}
Définit le nombre de lignes de caches du slot. Ce nombre doit être un multiple
de 4.
\vspace{2mm}
\end{minipage} &
RW
\\
\hline
\end{tabular}
\caption{Description des registre de configuration des slots de cache\label{tab:cssr}}
\end{table}
\end{center}

Les deux registres précédents permettent l'activation du mode partitionné et
la configuration des différents slots de cache. Néanmoins, il reste à
déterminer quel slot est le slot courant, et en informer le contrôleur de
cache pour permettre le changement de slot. Afin de permettre ce mécanisme,
je propose un registre supplémentaire dédié à ces deux fonctions. Ce registre
est nommé CSSR (\emph{Current Slot Selector Register}). Le registre est
schématisé dans la Figure \ref{fig:cssr}.


%%%%%%%%%%%%%%%%%%%%% CSSR register structure %%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{figure}[h!]
\begin{bytefield}[boxformatting={\centering\itshape},
bitwidth=0.8em]{32}
\bitheader[b]{0,1,15,16,31} \\
\bitbox{16}{\tiny slot id bitfield SIB} & \bitbox{15}{\tiny Reserved} & \bitbox{1}{\tiny U}\\
\end{bytefield}
\caption{Structure du registre CSSR\label{fig:cssr}}
\end{figure}
\end{center}

La Table \ref{tab:cssr} décrit les différents champs du registre CSSR.

%%%%%%%%%%%%%%%%%%%%% CSSR register table %%%%%%%%%%%%%%%%%%%%%
\begin{center}
\begin{table}[h!]
\begin{tabular}{|l|p{12cm}|c|}
\hline
\textsc{champ} & \textsc{signification} & \textsc{droits} \\
\hline
SIB &
\begin{minipage}{12cm}
\vspace{2mm}
définit l'identifiant du slot courant. Il s'agit d'un masque où le numéro du
slot est calculé par rapport au numéro du bit positionné à 1. Ainsi, soit
$S_{id}$ le numéro du slot, la valeur du champ vaut alors:
$$SIB = 2^{S_{id}}$$
\vspace{2mm}
\end{minipage} &
RW
\\
\hline
U &
\begin{minipage}{12cm}
\vspace{2mm}
Champ {\it update}. Quand ce champ est positionné à 1 par l'hyperviseur, le
contrôleur de cache relit le registre et change de slot en cours. Ainsi, dans
le cadre du fonctionnement nominal du système avec le contrôleur de cache en
mode partitionné, seul ce registre nécessite une modification pour changer de
slot.
\vspace{2mm}
\end{minipage} &
RW \\
\hline
\end{tabular}
\caption{Description des champs du registre CSSR\label{tab:cssr}}
\end{table}
\end{center}

La configuration initiale du contrôleur de cache doit se faire de la manière
suivante:
\begin{enumerate}
\item Configuration de chaque SCR
\item Configuration du CSSR, afin de spécifier le slot courant. Le bit {\it
    update} doit être mis à 1
\item Configuration du PCR, pour activer le mode partitionné. Si le passage en
  mode partitionné s'est bien déroulée, le cache est complètement flushé et le
  slot courant déterminé dans le registre CSSR commence à être utilisé
\item Vérification du champ SBF du registre PCR, afin de valider le passage en
  mode partitionné
\end{enumerate}
Une fois cette configuration effectuée, le contrôleur de cache utilise donc le
slot courant défini dans le registre CSSR. Je considère dans ma thèse trois
slots utilisés dans un cas classique de sécurisation:
\begin{enumerate}
  \item Un slot {\it hyperviseur}, utilisé par l'hyperviseur et la gestion des
    pieds d'interruption. Si les interruptions sont ensuite remontées au
    niveau des machines virtuelles, l'hyperviseur change de slot avant de
    donner la main à la machine virtuelle. Cela implique de démarrer le pied
    d'interruption par un changement de slot vers le slot hyperviseur et un
    changement de slot juste avant l'ordonnancement de la machine virtuelle
    pour le traitement de la routine d'interruption associée
  \item Un slot {\it domaine de sécurité bas}, pour la ou les machines
    virtuelles de plus bas niveau de sécurité
  \item Un slot {\it domaine de sécurité haut}, pour la ou les machines
    virtuelles de plus haut niveau de sécurité
\end{enumerate}
Le changement de slot se fait donc facilement via l'écriture dans un seul
registre. Dans le cadre de l'architecture PowerPC, l'écriture pourrait se
faire via l'usage de l'instruction {\tt mtspr} \cite{semiconductor2005powerpc}, dédiée à l'écriture dans les
registres de type {\it Special Purpose Registers}.\\
Le segment de code en charge de cette écriture ne doit pas être mis en cache, ce dernier impactant le slot
courant. Il doit donc être positionnable dans un segment mémoire non-cachable
ou placé dans un espace mémoire dédié type scratchpad, dont l'accès est plus
rapide est local au c{\oe}ur processeur.\\

Dans le cas d'usage que je propose, je n'utilise que trois slots sur les huit
présents. Il reste néanmoins possible d'utiliser jusqu'à huit slots dans le contrôleur de
cache, afin de supporter une plus grande séparation, en cas d'usage de plus de
deux domaines de sécurité ou pour des contraintes temps réel.

\paragraph{}
Cette proposition a pour but d'éviter le flush de caches en réponse à la
problématique d'utilisation de canaux auxiliaires basées sur les contrôleurs de
cache. Néanmoins, pour qu'une telle solution soit efficace, il faudrait
prévoir un partitionnement pour les caches L1 data, L1 code, mais également
le TLB. De plus, la problématique des caches L2 et plus globalement des caches
partagés reste entière.
