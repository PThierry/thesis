%%
%%
%% 03_all.tex for  in /home/phil/Travail/Doctorat/these/tex
%%
%% Made by Philippe THIERRY
%% Login   <Philippe THIERRYreseau-libre.net>
%%
%% Started on  ven. 14 juin 2013 12:52:20 CEST Philippe THIERRY
%% Last update ven. 14 juin 2013 12:52:20 CEST Philippe THIERRY
%%

\chapter{Vers une passerelle sécurisée et temps réel pour le traitement de
  flux multi-critiques : cas d'usage véhiculaire}
\doMinitoc
\label{sec:passsystronique}
\section{Rappel du besoin vétronique}

\subsection{Évolution des systèmes véhiculaires}

\paragraph{}
L'intégration des systèmes d'aide à la conduite et de gestion du multimédia a
beaucoup évolué ces dernières année. De tels systèmes intègre à la fois des
mécanique de protection de l'usager tel que l'{\it Anti-Lock Breaking System}
(ABS) ou l'{\it Electronic Stability Control} (ESP). De tels sous-systèmes
fonctionnent de manière autonome et n'autorisent aucune interaction
utilisateur dans le cadre de leur fonctionnement. Ils restent cependant
activable ou desactivable par le conducteur via une interface de contrôle.
Ses sous-systèmes sont compatible d'exigences temps réel fortes, dûe à la
problèmatique de sureté de fonctionnement qui leur est associée.\\
Avec l'accroissement des performances des architectures embarquées basse
consommation, de nouveaux sous-systèmes voient le jour dans l'infrastructure
véhiculaire. C'esgt par exemple le cas des radars de reculs, parfois couplés à
des caméras, ou encore de nouveaux modes d'interaction avec les terminaux
utilisateurs, via du réseau sans-fil courte portée. C'est également le cas de
sous-systèmes comme le {\it stop and go}, permettant de couper le moteur lors
de l'arrêt du véhicule afin de réduire la consommation moyenne d'essence.

\paragraph{}
Les systèmes vétroniques sont aujourd'hui très complexes, intégrant à la fois
des éléments avec de fortes exigences temps réel comme l'ABS ou l'ESP, avec
des exigences de sûreté élevées comme le stop-and-go ou encore des exigences de
sécurité également élevées, comme la gestion du démarrage sans contact.
A cela, il faut intégrer un réseau de contrôle et de diagnostic, permettant de
simplifier l'audit d'un véhicule en cas de problème électronique.

\paragraph{}
Dans \cite{invehicle_survey}, l'auteur montre à quel point les réseaux
d'interconnexion de systèmes vétroniques peuvent être complexes. Ces réseaux
sont habituellement basés sur une infrastructure de bus CAN ({\it Controller
  Area Network}) interconnectés au travers de gateways. Ces dernières sont
parfois à sens unique, afin d'assurer la sureté de fonctionnement de certains
sous-systèmes.\\
Avec l'intégration de terminaux utilisateurs dans le cadre de la gestion du
multimédia, viennent se greffer ces réseaux IP dont le coisonnement est
aujourd'hui de plus en plus complexe à assurer. En effet, l'utilisateur peut
accéder, via ces derniers, à diverses informations moteurs, impliquant un
média de remontée d'information. Le niveau de sûreté mais aussi de sécurité
des passerelles d'interconnexion devient alors de plus en plus élevé.\\
L'ordonateur de bord, élément dont l'interface utilisateur est unifié, permet
à la fois le paramétrage des élément non-sûrs (multimédia, gestion des
périphériques utilisateurs) et des éléments critiques ((des)activation des
différents sous-sytèmes d'aide à la conduite, etc). Une telle architecture
implique un support à la fois des problématiques de sûreté de fonctionnement
mais aussi de sécurité, afin de protéger les sous-systèmes critiques de toute
attaque ou impact dû à un comportement invalide d'un sous-système non-sûr
comme les terminaux utilisateurs.

\paragraph{}
Comme le décrit l'auteur dans \cite{ttsoc} la gestion des flux en provenances des différents sous-systèmes
se fait au travers d'un ordonnancement de type TDM, assurant un cloisonnement
temporel strict entre les traitements à fortes exigences de sûreté et les
traitements non sûrs, comme le multimédia. Les réseaux sont également
strictement séparés afin d'assurer un cloisonnement spatial strict.

\subsection{Problématiques techniques des architectures vétroniques civiles et militaires}

\paragraph{}
Lorsque systèmes critiques et non-sûrs ne sont plus indépendants et que la
notion de réseau IP apparaît dans le cadre de l'interconnexion de systèmes
non-sûrs, on parle alors de systèmes {\it systroniques}.
C'est le cas principalement dans les véhicules militaires avec l'intégration
des sous-systèmes de gestion des caméras, de la radio véhiculaire courte,
moyenne et longue portée mais également au travers des terminaux de gestion
intégrés nécessitant un cloisonnement sécuritaire fort. En effet, un véhicule
de ce type émet et reçoit des données dont la confidentialité peut être
restreinte au pays ou à la coalition. Une telle problématique apparaît également
dans les véhicules de police ou encore dans les véhicule médicalisés pouvant
interagir avec une bases de données patients centralisée, du fait des exigences
de confidentialité associées aux données médicales.\\
Dans le cas des véhicules militaires, des exigences de sûreté de
fonctionnement sont également présente sur la partie caméra, lorsque le
véhicule possède un blindage {\it transparent} (i.e. le conducteur s'appuie
sur des caméras et des capteurs plutôt que sur des vitres).

\paragraph{}
Les exigences de certification, tant en terme de sécurité qu'en terme de
sûreté de fonctionnement, exigent que lorsque deux sous-systèmes
interagissent directement, ces derniers doivent être compatibles du niveau de
certifiabilité de celui ayant la plus forte contrainte.\\
La conséquence directe est bien entendu le coût associé à la certification.
Cela limite en conséquence la complexité de l'ensemble du système et peut
interdire certains usages, comme l'intégration de terminaux non-sûrs.

\paragraph{}
Dans les véhicules militaires, la demande pousse vers l'usage de terminaux
fantassins type smartphone/tablette, à l'instar de la poussée du BYOD (Bring
Your Own Device) dans les systèmes d'information civils. Bien que maîtrisés
par le fournisseur, ces terminaux restent par nature non-sûr, de par la
complexité de leur architecture logicielle. Ils peuvent de plus
potentiellement être multi-niveaux de sécurité, impliquant une gestion de leur
interconnexion avec le {\it système d'information} véhiculaire complexe.\\
Cette problématique là apparaît également sur les terminaux GPS, dont la
maîtrise par le pays utilisateur n'est pas toujours assuré, la technologie GPS
étant une solution militaire américaine.

\begin{figure}
\input{figures/prv.tex}
\caption{Exemple d'intégration d'un système systronique pour véhicule blindé léger\label{fig:armoured}}
\end{figure}

\paragraph{}
Dans les systèmes systroniques sont définit trois réseaux d'interconnexion:
\begin{itemize}
  \item Le réseau moteur, basé sur une architecture complexe de bus CAN,
    permettant de remonter l'ensemble des informations des différentes sondes,
    mais aussi de contrôler certains relais et fonctions électroniques
  \item Le réseau critique, ayant de forte exigences de sûreté de
    fonctionnement, mais pas d'exigence de sécurité lorsqu'il est pris seul.
    Ce réseau gère les éléments critique du véhicule tels que les caméras ou
    les systèmes de désactivation des mécanismes défensif en cas d'ouverture
    de portes
  \item Le réseau d'interconnexion au système d'information et de
    commandement, qui gère les antennes, les connexions avec les terminaux
    fantassin, la gestion de la voix ou encore le GPS
\end{itemize}
Aujourd'hui, il est demandé dans les systèmes systroniques une solution
permettant de faire transiter certaines données entre ces trois réseaux, afin
principalement de simplifier la supervision de l'ensemble de ces
sous-systèmes. Cela implique d'interconnecter des réseaux aux exigences de
sûreté et de sécurité variables. Il devient alors nécessaire de prévoir une
passerelle permettant de faire transiter certains flux avec un contrôle
strict, à la fois afin de garantir la sûreté et la sécurité du système entier. 
Pour des raison de poids, de température et de surface, cette passerelle doit
être embarcable et de petite taille. Elle doit de plus répondre aux exigences
physiques en terme de vibration, de température ou encore de résistance à un
air chargé en particules comme le sable.\\
Le fait d'interconnecter des réseaux de niveaux de sûreté et de sécurité
différents implique une architecture de passerelle particulière, permettant
de maintenir le niveau de sécurité demandé tout en permettant le transfert de
certaines informations. La passerelle doit également permettre d'interagir
avec le réseau moteur, tout en assurant un filtrage suffisant pour ne pas
impacter la sûreté de fonctionnement associée à ce réseau.\\
Afin de répondre aux problématiques de sécurité, j'ai proposé plusieurs
moniteurs de sécurité dans le Chapitre \ref{chap:solution_secu}. L'association
de ces différents moniteurs permet d'assurer le cloisonnement des données
sensibles. Leur usage sera décrit plus loin dans ce chapitre.
Il faut également garantir le maintient du niveau de sûreté des réseaux
moteur et caméras. Pour cela, je propose de m'appuyer sur le moniteur de
sécurité diode logicielle, permettant d'assurer une remontée d'information à
sens unique entre sonde moteur et console de supervision d'une part et caméras
et console conducteur d'autre part. Pour ces deux flux, il est de plus
important d'assurer une latence maximum garantie. C'est une exigence
particulièrement critique pour la remontée de flux d'information des caméras
lorsque le véhicule s'appuie sur un blindage transparent.

\paragraph{}
Dans le cadre du réseau d'interconnexion du système d'information, le
transport de la voix est un élément important. Non seulement il permet aux
chef de patrouille de communiquer via la radio avec le système d'information
et de commandement, mais il permet également au personnel de communiquer
entre eux, le bruit ambiant étant trop élevé pour permettre une discussion
directe. Cette problématique induit un usage important de l'infrastructure
VoIP de bord, avec une conséquence en terme de multi-criticité. En effet,
lorsque la passerelle de traitement de la voix ne permet pas un traitement
concurrent de l'ensemble des flux voix, la priorité passe aux plus haut gradé,
impliquant une potentielle coupure du flux d'un (ou plusieurs) des
subordonnés.

\paragraph{}
L'interconnexion doit être garantie en terme de bande passante afin de pouvoir
répondre aux besoins du domaine de sureté le plus faible. C'est un besoin
important dans le traitement de flux vidéo ou voix émis à partir d'un domaine
de sureté élevé. Dans ces deux cas, un débit et une latence garantis sont
nécessaires, comme définit dans l'exigence
\hyperlink{REQTEMPS001}{REQ\_TEMPS\_001}. C'est également le
cas de certains flux d'alerte, comme la remonté d'alarme des différentes
sondes moteur.\\
Néanmoins, les données transmises peuvent avoir à être filtrées afin d'éviter
le transfert non maîtrisé de données confidentielles. Parce que les système de
sureté plus faible ne peuvent être certifiés pour le traitement de flux
dont le niveau de sureté est supérieur, ces derniers ne peuvent émettre de
requêtes vers un domaine de sureté supérieur sans validation préalable par un agent de
confiance. Il peut parfois être exigé que la communication soit garantie à
sens unique entre deux domaines de sureté hétérogènes. Dans ce dernier cas, un
moniteur de sécurité de type diode logicielle doit permettre de garantir que
le flux d'interconnexion est à sens unique. Cela peut être le cas pour les
sondes moteurs, qui ne devrait pas recevoir de requête de la part d'un élément
de domaine de sureté plus faible, mais plutôt émettre une information de
manière périodique, simplifiant dans le même temps leur comportement.

\paragraph{}
Les systèmes systroniques sont basés sur une interconnexion complexe de
systèmes de niveau de sureté et de sécurité hétérogènes avec un grand nombre
d'interactions.\\
Ces interactions nécessite d'être filtrées, validées voire inspectée afin de
garantir à la fois le besoin sécuritaire et le besoin de sureté des différents
sous-systèmes présents. Afin de permettre ces différents traitement, un
équipement d'interconnexion doit être mis en place aux différents points de
communications inter-domaines, et doit être compatible des exigences de sureté
et de sécurité des différents domaines qu'il interconnecte.\\
Dépendant des réseaux qu'il interconnecte, ce dernier doit pouvoir fournir
différents services à la fois en terme de sécurité et de temps réel. Ainsi,
la remonté d'informations moteur sur un smartphone ne nécessite pas de
conformité à des exigences temps réel. A l'inverse, la remonté de flux vidéo à
partir d'un système de type blindage transparent doit garantir un comportement
temps réel dur afin d'assurer une bonne vision de l'environnement immédiat du
véhicule.\\
En terme de sûreté, l'interconnexion d'une console de gestion du système
d'arme doit pouvoir accéder aux informations de status de ces dernières, mais
ne doit pas pouvoir émettre d'ordre de mise en route. En terme de sécurité,
les données de positionnements auxquelles accède le véhicule ne doivent pas
être réémise sur l'ensemble des systèmes radios qui sont interconnectés, mais
uniquement à ceux qui sont utilisés dans le cadre de la coalition voire
exclusivement du pays utilisateur.\\
On constate ainsi que les systèmes systroniques, décrit ici dans le cas
militaires, impliquent à la fois l'interconnexion de systèmes de sureté et de
sécurité hétérogènes, avec des exigences variables et des données multiples.
La définition d'un équipement d'interconnexion modulaire est donc important
pour limiter le coût de la solution complète. Cette problématique se retrouve
dans différents secteurs, comme le médical ou la police.

%The consequence of such problematic is that various interconnection node
%should be deployed, with various behaviors.\\
% end of updated part. below needs to be updated

\section{Définition d'une architecture logicielle pour une passerelle systronique}
\label{sec:passerelle_systronique}

\subsection{Terminologie}

\subsection{Définition d'une architecture de filtrage multi-fonctions pour les systèmes systroniques}

\paragraph{}
La conséquence de la problématique montré en \ref{subsec:problematics} et que
plusieurs type de connecteurs sont nécessaires, à divers endroits du systèmes
systronique, avec des contraintes différentes, tant en terme de service rendu
qu'en terme de sécurité et de temps réel.\\
Définir une solution modulaire, apte à intégrer en entrée une configuration
extérieur lors de la production serait un atout en terme de coût dans le cadre
de la définition du système.

\paragraph{}
Comme décrit dans le Chapitre \ref{chap:solution_secu}, l'architecture
logicielle du connecteur est basée sur un ensemble de conteneurs autonomes
communicants. Chaque conteneur est dédié à un traitement unitaire dont je
limite la complexité. Ces traitements sont par exemple un filtre DPI, un
mécanisme de shaping de flux, une diode logiciel assurant un transfert sens
unique ou tout autre traitement nécessaire au service que doit rendre le
connecteur. Ces conteneurs ont pour but d'être réutilisables, et ce
indépendamment des autres conteneurs déployés, afin de limiter le coût de
réimplémentation des fonctions et de re-certification de ces dernières.\\
Certains traitements peuvent correspondre à des besoins sécuritaire ou de
sureté de fonctionnement, comme la diode logicielle. Dans ce cas, le conteneur
doit pouvoir être certifié afin de garantir la fonction. Dans ce cas, on
souhaite considérer cette fonction comme un moniteur de sécurité (ou de
sureté), comme je l'ai décrit dans le Chapitre \ref{chap:solution_secu}. Dans
d'autre cas, comme par exemple pour le filtre DPI, il peut être nécessaire
d'intégrer un ensemble de fonctions comme une pile réseau, impliquant un
volume de code plus grand et accroissant fortement le coût de certification
associée. L'intérêt des conteneurs est donc de permettre une dissociation de
la certification des différentes fonction, si ces dernières sont garanties
disjointes en terme logiciel. C'est par exemple le cas lorsque l'on s'appuie
pour la séparation spatiale et temporelle sur des compartiments PikeOS
\ref{sec:pikeos}.\\
Dans le cadre du besoin systronique, j'ai proposé un premier maquettage de
plusieurs de ces fonctions:
\begin{itemize}
    \item Une fonction diode, assurant le transit en sens unique des données.
    \item Une fonction DPI, assurant un filtrage des données en fonction d'une
      politique de filtrage déterminée en avance.
    \item Un émetteur périodique, assurant un profil de flux en sortie
      garanti, tout en empêchant l'usage du profil d'entrée pour faire
      transiter de l'information via un canal caché.
\end{itemize}

\paragraph{}
Ces différents conteneurs peuvent correspondre à une fonction de faible
empreinte, qui peut être difficile à superviser. En conséquence, ces derniers
doivent tous fournir une interface de supervision, pour interagir avec un
conteneur de supervision. Ce dernier a pour but de récolter les différentes
informations de status voire de débogue associées à ces différents conteneurs,
pour les renvoyer vers un environnement de supervision déterminé.

\paragraph{}
Dans le cadre du besoin systronique, il est souvent demandé que le connecteur
soit capable de fournir une garantie de coût de traversée maximum (WCTT -
Worst Case Traversal Time) pour les flux qu'il fait transiter.
Comme décrit dans la Figure \ref{fig:block}, j'ai implémenter un mécanisme de
mesure du coût de traversée, qui débute lorsqu'un paquet est reçu par le
conteneur {\it VE filter} et se termine lorsqu'un paquet retransmettant cette
même donnée est émis par le conteneur {\it VE sender}.\\
Le respect du WCTT implique que chaque tâche en charge à un instant donné du
traitement de la donnée à faire transiter doit être considérée comme une tâche
temps réel, impactant en conséquence la politique d'ordonnancement en charge
de cette dernière. Dans le cadre du maquettage que j'ai effectué, je me suis
basé sur la technologie des Cgroups Linux, associée aux politique
d'ordonnancement temps réel POSIX de type SCHED\_FIFO. L'usage des Cgroups
dans la maquette impacte l'architecture générale. Ainsi, dans cette dernière,
il ne s'agit pas d'un ordonnancement hiérarchique mais d'un ordonnancement
unique par l'ordonnanceur SCHED\_FIFO du noyau Linux.\\ 
Si la maquette avait été faite sur base d'un ordonnancement hiérarchique,
comme par exemple via l'usage d'un micro-noyau de virtualisation type PikeOS
\ref{sec:pikeos}, il aurait alors nécessaire de déterminer correctement à la
fois l'ordonnancement des différents conteneur et celles des tâches dans ces
derniers. Pour répondre à cette problématique, j'ai défini cinq
Équations \ref{sec:hierarchicalrt} permettant de déterminer si le système est
alors apte à garantir l'ordonnançabilité de l'ensemble des fonctions temps réel.

\subsubsection{A propos du conteneur de supervision}

\paragraph{}
Comme vu précédemment, le connecteur a souvent une fonction de filtrage, soit
pour valider le contenu des flux à transiter, soit pour assurer un transit à
sens unique. Dans ces différents cas, la fonction de filtrage doit pouvoir
remonter des alerte en cas de non-respect de la politique de filtrage ou en
cas d'incapacité à exécuter correctement son traitement (e.g. dans le cas
d'un débit trop important). Ces remontées d'alertes doivent être prises en
compte et transmises à un équipement dédié à la supervision. C'est ce qui est
décrit dans la Figure \ref{fig:block}.

\begin{figure}
\input{figures/bloc_diag.tex}
\caption{architecture logicielle type d'une passerelle filtrante\label{fig:block}}
\end{figure}

\subsubsection{A propos du conteneur de filtrage DPI}

\paragraph{}
Il peut être nécessaire dans les systèmes systroniques que les flux transitant
d'un domaine à un autre soient filtrés afin d'assurer la confidentialité de
certaines données pour ne faire transiter que celles dont le niveau de
déclassification est suffisant pour être transmis dans un domaine de moindre
niveau. C'est par exemple le cas des données de cartographie ou de
positionnement vis à vis d'un système de communication de type coalition.\\
Afin d'assurer un tel filtrage, une fonction DPI doit être implémentée et
prendre en donnée d'entrée une politique de filtrage qui doit être considérée
pour valider chaque flux en cours de transit, afin de valider ou interdire une
remontée d'information vers le domaine de plus faible sécurité. Ce conteneur
est intégré dans la Figure \ref{fig:block} sous la dénomination {\it VE filter}.
Son traitement consiste en une vérification de la conformité du flux d'entrée
envers la politique de sécurité avant validation et réémission. La validation
du flux d'entrée sur la donnée et non sur les en-têtes protocolaires de
couche quatre du modèle OSI et inférieur. Une fois validée, la donnée est
réémise après reforgeage de l'en-tête réseau. La {\it VE filter} étant
considérée de confiance, les en-têtes forgées sont également considérée comme
telles. Un tel mécanisme est appellée séparation protocolaire et permet
d'éviter tout usage des en-têtes réseau comme IP ou TCP pour faire transiter
de l'information.\\
Les traitements de la VE filter sont décomposés comme suit:
\begin{itemize}
  \item Un récepteur de paquet, qui reçoit la donnée et valide son contenu
    auprès d'une politique de sécurité. Le WCET de cette tâche peut être très
    variant selon la complexité de la politique de sécurité et du contenu du
    paquet.
  \item Un émetteur, récupérant les paquets tagués par le recepteur comme
    valide et qui les reexpédie vers le compartiment suivant. Le WCET de cette
    tâche est assez stable, son coût étant dépendant que de la taille de
    trame.
\end{itemize}
Dans le cas d'un véritable système DPI avec une politique de sécurité
complexe, l'implémentation du filtre serait beaucoup plus complexe. Il
impliquerait entre autres un mécanisme permettant de concaténer les message
afin de reconstituer l'information de niveau application avant de pouvoir
déterminer sa compatibilité avec la politique de sécurité. Il impliquerait de
plus un mécanisme de gestion de queues de message multiples couplées à une
politique de qualité de service assurant la priorisation de certains flux par
rapport à d'autres. Dans le cadre de la maquette, la politique DPI en
elle-même n'est pas l'élément dont je souhaite démontrer la faisabilité. Cette
dernière est donc simple et s'appuie sur un protocole TLV qui assure que
l'information de niveau applicatif est entièrement présente dans une et une
seule trame réseau.

\subsubsection{A propos du conteneur Diode}

\paragraph{}
Il arrive dans certains cas que la communication entre deux conteneurs soit
garantie comme étant en sens unique. C'est le cas lorsque l'on change de
domaine de sécurité (lors de la remontée d'informations entre un domaine de
sécurité et un autre de niveau supérieur) mais aussi lorsque l'on change de
domaine de sûreté (afin d'assurer que le domaine de moindre sûreté ne
vient pas impacter le domaine de plus fort niveau de sûreté).\\
Ainsi, dans les systèmes systroniques, les remontées d'informations coalitions
vers le domaine pays ne doivent dans le même temps assurer que les données
pays ne sont pas renvoyées vers le domaine coalition. L'usage d'un élément
certifiable en coupure permet d'assurer cette fonction. C'est le but du
conteneur Diode.\\
Le but de ce conteneur est d'assurer un transfert sens unique entre deux
domaines. Pour des raisons de sécurité liées aux problématiques de canaux
cachés\cite{lampson1973note}, ce conteneur doit également assurer que le comportement
du récepteur de domaine de sécurité plus élevé ne soit jamais connu de
l'émetteur, dont le domaine de sécurité est plus faible. Ainsi, l'émetteur ne
peut retirer aucune information du débit de son émission, ce dernier n'étant
par corrélé au comportement du récepteur.\\
Une telle architecture a pour conséquence que le conteneur diode peut
perdre des paquets si le récepteur n'est pas apte à les recevoir. En effet,
faute d'en informer l'émetteur, le conteneur diode doit alors détruire les
paquets et lever une alerte auprès d'un environnement de supervision de niveau
de sécurité apte à traiter cette information.
Le conteneur de supervision est visible dans la Figure \ref{fig:block}, et a
entre autre pour but de récupérer les alertes du conteneur Diode.

\subsubsection{A propos du conteneur {\it Sender}}
\label{sec:emet_periodinque}

\paragraph{}
L'émetteur périodique (nommée VE Sender) exécute une tache périodique pour
l'émission des paquets en sortie de passerelle. Le but de ce conteneur est
d'assurer un débit (en nombre de trame) fixe, avec une période inter-trames
également garantie. Ce conteneur permet de répondre à plusieurs besoins:
\begin{enumerate}
  \item En cas d'émission vers un domaine de sûreté élevé, ce conteneur
    empêche tout flooding d'interface, en limitant le débit à une valeur
    maîtrisée. Ce comportement permet à la passerelle d'être compatible de
    l'Exigence \hyperlink{REQTEMPS002}{REQ\_TEMPS\_002}.
  \item Afin d'éviter tout canal caché basé sur la période inter-trame, cette
    dernière est remaniée à une valeur fixe. Ainsi, l'utilisation d'une
    variation de période inter-trame par l'émetteur afin d'envoyer de la
    donnée en morse est bloquée. En cas de non émission de trame, l'émetteur
    renvoie alors la dernière trame, jusqu'à arrivée d'une nouvelle trame à
    émettre. Ce comportement permet d'être compatible avec l'Exigence \ref{req:sec_covert}
\end{enumerate}
La période d'émission de l'émetteur périodique définit le débit maximum
supporté par la passerelle.


\begin{figure}
\begin{center}
\input{figures/paquet_forward.tex}
\caption{Contrôle du débit à l'émission de la passerelle par l'émetteur périodique\label{fig:fw}}
\end{center}
\end{figure}

\paragraph{}
Afin d'assurer un comportement temps réel de la passerelle, cette dernière
doit pouvoir assurer un coût de traversée pire cas (WCTT - Worst Case
Traversal Time). La tâche d'émission périodique de paquet s'exécute donc selon
un schéma périodique strict. En fonction du profil de flux entrant, il est
nécessaire de définir un buffer d'entrée permettant de supporter des bursts.
Ce buffer est déterminé en nombre de paquets, afin de garantir une profondeur
dépendante du nombre de paquets exclusivement, sans être impacté par la taille
de ces derniers. Cela permet ainsi de mieux maîtriser le débit entrant en
paquet, sans considérer leur variation de taille. Un telle architecture de
buffer d'entrée s'appuie sur le principe de Queuing Ports de l'ARINC 653
comme décrit dans \cite{alena_communications_2007} et \cite{arinc_653}\\
La Figure \ref{fig:fw} montre un exemple de mécanisme de forwarding d'une
passerelle générique.

\subsubsection{Mesure empirique du coût de traversée pire cas par maquettage d'une passerelle}
\label{subsec:empiric}

\paragraph{{\it Architecture et configuration}}

\paragraph{}
La configuration de la maquette est le flux d'entrée est décrit dans la Table \ref{tab:dut}.\\
\begin{table}
\begin{center}
\begin{tabular}{|l|l|}
  \hline
  {\bf Item} & {\bf Description} \\
  \hline
  \hline
  {\it Architecture} & i686 core 2 duo 2Ghz \\
  {\it NICs} & DLINK-RTL8139, VIA VT6105 \\
  {\it OS} & Debian Squeeze \\
  {\it Noyau} & linux 3.2.12-rt24 \\
         & pas de support ACPI \\
         & mode FULL\_PREEMPT \\
  {\it Type de compartimentation} & LXC \\
  {\it Sécurité} & protection noyau (mémoire et durcissement compartimentation LXC) \\
  \hline
  {\bf Flux d'entrée} & {\bf Description} \\
  {\it type de flux} & UDP sur IPv4 \\
  {\it type de payload} & TLV\\
  & T ({\it champs Type}) taille de champs de 1 octet \\
  & L ({\it champs Taille}) taille de champs de 1 octet \\
  {\it nombre de types} & 5 types\\
  {\it taille de payload} & type 0: 50B \\
   & type 1: 50 octets\\
   & type 2: 30 octets\\
   & type 3: 30 octets\\
   & type 4: 70 octets\\
  {\it contenu de la payload} & contenu ASCII \\
  \hline
\end{tabular}
\caption{Description de la configuration utilisée pour la mesure\label{tab:dut}}
\end{center}
\end{table}

\paragraph{}
Le maquettage initial a été construit sur l'architecture logicielle de
conteneurisation LXC (Linux Containers). Cette architecture s'appuie sur un
seul noyau et un seul ordonnanceur en charge de gérer les tâches des
différents conteneur. Dans ce cadre, l'ordonnancement n'est pas de type
hiérarchique, du fait de l'unicité de l'ordonnanceur. Néanmoins, ce dernier
est apte à différentier les différents conteneurs et donc de gérer une
politique d'ordonnancement variable par conteneur. Dans le cadre du
maquettage, la différenciation est limitée à l'affinité CPU, afin de séparer
les tâches de supervision et de traitement sur des coeurs disjoints.
Ainsi, les sets de tâches des conteneurs DPI, diode et Émetteur périodique
sont tous réunis sur un seul c{\oe}ur, avec une politique d'ordonnancement de
type POSIX SCED\_FIFO.\\
Afin de valider le comportement temps réel souple de Linux, ce dernier a été
validé et utilisé avec le patch Linux-RT. Ce patch permet de fortement réduire
l'impact du système Linux sur l'ordonnancement des tâches temps réel. En effet
ce dernier permet entre autre de :
\begin{itemize}
  \item Supporter le mode FULL\_PREEMPT, rendant le noyau preemptible (à
    l'exception de certains éléments comme les gestionnaires d'interruption)
  \item Débrayer les priorités des différents threads kernel, afin qu'ils ne
    puissent être plus prioritaire que les tâches temps réel
  \item Limiter l'exécution des différentes {\it softirq} Linux au contexte du
    thread ksoftirqd, afin qu'elles ne puissent s'exécuter dans un contexte
    d'appel système
\end{itemize}
La capacité du noyau Linux à supporter le temps réel souple a été mesuré dans 
\cite{rtlinux}.\\

\begin{figure}
\begin{center}
  \includegraphics[width=12cm]{figures/rttest.pdf}
\caption{Latence au démarrage de la tâche de priorité la plus élevée\label{fig:rttest}}
\end{center}
\end{figure}

\paragraph{}
La Figure \ref{fig:rttest} montre que la tâche de priorité la plus élevée
(ordonnancement SCHED\_FIFO, priorité 99) s'exécute avec une latence au
démarrage d'au maximum 300 microsecondes. Cette mesure a été effectué avec
l'outillage de mesure temps réel cycletest utilisé dans \cite{cycletest},
pendant une durée de 5h avec une charge CPU de 40 et un traitement de flux
représentatif du besoin, ce qui correspond à un nombre d'échantillons (en
terme de jobs) supérieur à 100 millions.\\
La mesure a été faite pour une tâche s'exécutant dans le conteneur {\it VE
  sender}, avec une interconnexion des conteneurs via sockets unix, comme
décrit dans la Figure \ref{fig:mockup}.

\begin{figure}
\input{figures/mockup.tex}
\caption{Architecture logicielle générale de la maquette\label{fig:mockup}}
\end{figure}

\paragraph{}
Dans le cadre de la maquette, le système a été implémenté avec une politique
d'ordonnancement de type Rate Monothonic, avec la configuration suivante :
{\small
\begin{table}
\begin{center}
\scalebox{0.9}{
\begin{tabular}{|l||ccccc|}
  \hline
Tâche & Politique & profil & priorité & WCET  & Période \\
 & d'ordonnancement & d'ordonnancement & & (mesuré) & \\
\hline
Filter (nommée $F$) & SCHED\_FIFO & sporadic &  97 & 90us & 1  ms \\
Diode (nommée $D$) & SCHED\_FIFO & sporadic & 98 & 60us & 1 ms \\
Sender (nommée $S$) &  SCHED\_FIFO & periodic & 99 (highest) & 80us & 10 ms\\
\hline
\end{tabular}
}
\end{center}
\caption{Description des choix d'ordonnancement de tâches pour la maquette\label{tab:mockup}}
\end{table}
}

\paragraph{}
La plus grande priorité est donnée à la tache Sender, puis à la tache Diode et
enfin à la tache Filter. Ce choix a été fait afin de réduire la latence de
traversée, en priorisant l'émission de données bufferisée par rapport à la
réception de nouvelles données.

\paragraph{{\it Filtrage de paquets avancé (DPI)}}

\paragraph{}
Afin de déterminer un automate de filtrage de paquets dans la tâche Filter,
j'ai écrit un protocole très simple, basé sur une structure TLV
(Type/Length/Value). Ce protocole permet 5 types différents, sans récursion.
Chaque type possède sa propre taille et son propre contenu. Un émetteur est un
récepteur ont été implémentés pour émettre le flux sur du protocole UDP vers la
tâche Filter de la passerelle d'une part, et recevoir le flux réencapsulé dans
du protocole UDP par la tâche Sender de la passerelle d'autre part.
L'automate de la tâche Filter a pour but de valider les différents types, et
pour chaque vérifier la taille et la conformité du contenu par rapport à une
politique de sécurité chargée en mémoire.\\
Si le paquet est invalide (non conforme à la politique de sécurité) ce dernier
est droppé et un conteur de statistiques est mis à jour. Dans un cas plus
complet, ce dernier serait lu par un conteneur de supervision pour remonter
une alerte.

\paragraph{{\it Diode logicielle}}

\paragraph{}
La Diode logicielle est une tâche sporadique du conteneur {\it VE Diode}. Cette tâche
lit les données transmise par la tâche de Filtrage du conteneur {\it VE
  Filter} et les transmet au conteneur {\it VE Sender}, sans traitement
complémentaire. Son coût d'exécution est donc assez stable, seule la taille
des paquets reçus et émis étant impactant.

\paragraph{{\it Émetteur périodeique}}

\paragraph{}
L'émetteur périodique est la tâche du conteneur {\it VE Sender} en charge
d'assurer la maîtrise du flux de sortie, via un comportement prédictible. En
effet, cette dernière est périodique et assure l'émission d'un paquet vers
l'extérieur à chaque période. Ce dernier peut être un nouveau paquet (si le
buffer d'entrée de la tâche a été remplit par la Diode logicielle) ou le même
paquet que précédement (si aucun nouveau paquet n'est arrivé).\\
L'émetteur périodique ne supportant pas, dans le cadre de ce maquettage, un
mode burst, il est le facteur limitant du débit maximum transféré par la
passerelle.

\paragraph{{\it Communication entre les conteneurs}}

\paragraph{}
Comme vu plus haut, dans le cadre du maquettage la communication entre les
conteneur a été faite au travers de sockets unix, via des sockets nommées
remappées dans les différents conteneurs. En effet, l'usage d'IPC POSIX
standard comme les pipes ou les SHM est rendu impossible par la mise en
conteneur. En effet, le but est de se rapprocher d'une architecture
logicielle dont les canaux de communications entre conteneurs sont réduits
exclusivement à ceux explicitement déclaré, comme je l'ai décrit dans le
Chapitre \ref{sec:donneeaproteger}. De plus, dans le conteneur Diode, la
socket unix partagée avec le conteneur Filter est montée dans un système de
fichier virtuel en lecture seule, afin d'assurer qu'une donnée ne peut être
retransférée vers l'arrière.\\
L'usage de ces sockets permet de transférer des données sans aucun ajout
d'en-têtes protocolaires. Ainsi, les couches 1 à 4 du flux réseau entrant
est décapsulée par la tâche de Filtrage DPI, et seule la tâche Émetteur
périodique réencapsule les données à l'émission.

\paragraph{{\it Résultats empiriques}}

\paragraph{}
Plusieurs mesures ont été effectuée afin de valider l'efficacité de
l'architecture logicielle et sa capacité à supporter les exigences temps
réel. Afin de démontrer que la passerelle garantie la périodicité du flux émis
quel que soit le profil de flux entrant, un flux entrant dont la période
inter-trame est aléatoire a été généré afin de valider le comportement de la
passerelle. Pendant l'émission de ce flux, le WCET et la période des trois
tâches ont été mesurés. Les périodes minimums de la tâche Filter et Diode
n'ont pas été définies, ces dernière étant directement dépendantes de la période
inter-trame du flux entrant.

La Table \ref{tab:test1} décrit le premier jeu de mesures

\begin{table}[h!]
  \begin{center}
  \begin{tabular}{|l|l|}
     \hline
     \multicolumn{2}{|c|}{\bf Jeu de test 1} \\
     \hline
     \hline
     échantillons en entrée & 10.000 \\
     période minimum du flux d'entrée & 10 ms \\
     période maximum du flux d'entrée & 30 ms \\
     variation de la période du flux d'entrée & aléatoire \\
     contenu du flux d'entrée & protocole TLV compatible de la politique de sécurité DPI \\
     choix du type TLV du flux d'entrée & aléatoire \\
     débit moyen du flux d'entrée & 68.8 Ko/s \\
     nombre de paquets perdu(s) & 0 \\
     \hline
  \end{tabular}
  \caption{Profil du jeu de test 1\label{tab:test1}}
\end{center}
\end{table}

\begin{figure}
  \begin{minipage}[b]{.46\linewidth}
    \centering\includegraphics[width=9cm]{figures/measure_all.pdf}
    \caption{Test 1: WCET mesurée pour Filtre, Diode et Émetteur périodique\label{fig:costall}}
  \end{minipage}\hfill
  \begin{minipage}[b]{.46\linewidth}
    \centering\includegraphics[width=9cm]{figures/period_filter.pdf}
    \caption{Test 1: Variation de période pour la tâche Filter\label{fig:filter_p}}
  \end{minipage}
\end{figure}

\begin{figure}
  \begin{minipage}[b]{.46\linewidth}
    \includegraphics[width=9cm]{figures/period_diode.pdf}
    \caption{Test 1: Variation de période pour la tâche Diode\label{fig:diode_p}}
  \end{minipage}\hfill
  \begin{minipage}[b]{.46\linewidth}
    \includegraphics[width=9cm]{figures/period_sender.pdf}
    \caption{Test 1: Variation de période pour la tâche Émetteur périodique\label{fig:sender_p}}
  \end{minipage}
\end{figure}

\paragraph{}
Un premier jeu de mesure a été fait en utilisant un flux d'entrée généré
aléatoireement avec une période inter-trame de 10 millisecondes. Le profil de
flux est donné dans la Table \ref{tab:dut}.\\
Les Figures \ref{fig:filter_p}, \ref{fig:diode_p} et \ref{fig:sender_p}
montrent le le profil d'exécution des trois tâches de la passerelle dans le
cadre du traitement de ce flux. On démontre, au travers de ces mesures, que
quel que soit le profil de flux entrant et son impact sur les tâches Filter et
Diode, l'Émetteur périodique garantit un flux maîtrisé en sortie. La faible
variation de sa période est la conséquence de la variation de la latence
d'exécution du noyau Linux, qui a été mesuré dans le cadre de la Figure 
\ref{fig:rttest}. Ainsi, le flux sortant possède une période inter-trame qui
correspond à la période de l'Émetteur périodique.

\paragraph{}
Afin de vérifier la stabilité de la passerelle, un second flux a été généré
avec une période inter-trame beaucoup plus courte, et supérieur à la capacité
d'absorbtion de la passerelle. Ce flux est décrit dans la Table
\ref{tab:test2}.

\begin{table}[h!]
  \begin{center}
  \begin{tabular}{|l|l|}
     \hline
     \multicolumn{2}{|c|}{\bf Jeu de test 2} \\
     \hline
     \hline
     échantillon d'entrée & 10.000 \\
     période minimum du flux d'entrée & 1 ms \\
     période maximum du flux d'entrée & 1 ms \\
     contenu du flux d'entrée & protocole TLV compatible de la politique de
     sécurité\\
     choix de la payload du flux d'entrée & aléatoire \\
     débit moyen du flux d'entrée & 688 Ko/s \\
     paquets perdu(s)  & 90\% \\
     \hline
  \end{tabular}
  \caption{Profil du jeu de test 2\label{tab:test2}}
\end{center}
\end{table}


\paragraph{}
Étant donné que la période minimum des tâches Filter et Diode n'est pas
spécifiée, leur période minimum correspond à la plus petite période autorisée
par le système d'exploitation, qui dans le cadre de la maquette a été
positionnée à 1 milliseconde. Les Figure \ref{fig:filter_p_2} et
\ref{fig:diode_p_2} le démontre. Ces Figures montrent également des anomalies
dans la période du flux d'entrée, accroissant la période de ces deux tâches
avec une probabilité moyenne de 0.02\% dans le cadre de la mesure. Dans le
même temps, l'Émetteur périodique maintient sa période et n'est d'aucune
manière impacté par l'ordonnancement des tâches Filter et Diode, comme le
montre la Figure \ref{fig:sender_p_2}.

\begin{figure}
  \begin{minipage}[b]{.46\linewidth}
    \centering\includegraphics[width=9cm]{figures/period_filter_2.pdf}
    \caption{Test 2: Variation de la période de la tâche Filter\label{fig:filter_p_2}}
  \end{minipage}\hfill
  \begin{minipage}[b]{.46\linewidth}
    \includegraphics[width=9cm]{figures/period_diode_2.pdf}
    \caption{Test 2: Variation de la période de la tâche Diode\label{fig:diode_p_2}}
  \end{minipage}
\end{figure}

\begin{figure}
\includegraphics[width=9cm]{figures/period_sender_2.pdf}
\caption{Test 2: Variation de la période de la tâche Émetteur périodique\label{fig:sender_p_2}}
\end{figure}

%%%%% EOT %%%%%%
\section{Limitations de la solution technique et compléments}
\label{sec:future}

\paragraph{}
Il est montré dans la Section \ref{sec:secu} que le connecteur ne permet pas
le transfert d'un grand nombre de paquets par seconde, la limitation venant de
la période d'exécution de la tâche émetteur périodique. Il est cependant
possible d'accroître fortement le débit supporté via l'envoi de burst par
l'émetteur périodique. L'usage de bursts permet d'accroître le débit mais
implique plusieurs propriétés afin d'assurer malgré tout une maîtrise du
profil de flux en sortie du connecteur:
\begin{itemize}
  \item La taille du burst doit être fixe
  \item Le profil de flux sortant doit conserver un débit maximum déterminé,
    afin de permettre le calcul de la profondeur des buffers de l'émetteur
    périodique en conséquence
  \item Les profondeurs de buffers doivent être déterminées en nombre de
    paquets et non en octets, afin de ne pas être impacté par la variation de
    la taille des paquets.
\end{itemize}

\paragraph{}
Le maquette est basée sur une solution de compartimentation applicative sous
Linux. Bien que plusieurs éléments de sécurisation et de temps réel y ait été
apportés, cette dernière ne permet ni une certification élevée en sécurité, ni
une certification élevée en temps réel. L'usage d'un micro-noyau temps réel
est nécessaire. Les différentes fonctions de sécurités étant apportées par les
moniteurs de sécurités, hors du champ du micro-noyau. Dans le cadre du
transfert de flux à multiple criticité avec de fortes exigences de sécurité,
la vérification du flux peut impliquer l'attente de plusieurs paquets
successifs afin de reconstruire les informations protocolaires de couche
session et supérieures. Ce traitement, devant être fait au niveau du filtre
DPI, génère une latence dépendante du nombre de paquets devant être disséqués
pour déterminer si le flux peut être autorisé selon la politique de sécurité
locale. Ce calcul est néanmoins réalisable pour un protocole de communication
donné.

