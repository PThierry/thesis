%%
%%
%% hardware_impacts.tex for thesis in /doctorat/these/tex
%%
%% Made by Philippe THIERRY
%% Login   <Philippe THIERRYreseau-libre.net>
%%
%% Started on  Fri Mar 12 16:36:41 2010 Philippe THIERRY
%% Last update ven. 18 avril 2014 18:06:41 CEST phil

\chapter{Compatibilité d'une architecture sécurisée avec des contraintes de temps réel}

\doMinitoc

\section{Architectures compartimentées et temps réel}
\label{sec:solution_rt}

\paragraph{}
Afin de répondre aux exigences sécuritaires de la solution, l'usage
d'architectures logicielles compartimentées strictement dans le temps est nécessaire.
Cette compartimentation, de type TDM (Time Divion Multiplexing) réduit en effet les interactions dues aux variations
de comportement (charge processeur, accès mémoire, etc) des différents
compartiments.\\
Lorsqu'il est nécessaire d'intégrer dans le même temps des exigences temps
réel sur les flux traité par la passerelle, il devient nécessaire de
considérer la bonne adéquation de la solution de compartimentation avec les
contraintes d'exécution (WCET, période, échance) des services de traitement de flux.

\subsection{Rappel des exigences de temps réel}

\paragraph{}
En plus des différentes exigences de sécurité décrites dans le chapitre
précédent, plusieurs exigences de temps réel doivent être respectées dans le
cadre d'une passerelle d'interconnexion. Elle est en effet en charge de faire
transiter des flux plus ou moins critiques, sur lesquels elle va exécuter un
ensemble de traitements. Ces traitements, selon leur nature, ont également des
niveau de criticité variables, impliquant la prise en compte du principe de criticité
mixte afin de pouvoir limiter le nombre de traitements effecutés sur chaque
flux en fonction de la capacité qu'a la passerelle à les exécuter, comme
le précise l'Exigence \hyperlink{REQTEMPS002}{REQ\_TEMPS\_002}.\\
Dans le même temps, la passerelle doit assurer une latence de traversée
bornée, pour que les données transmises soient encore valides (confer
Exigence \hyperlink{REQTEMPS001}{REQ\_TEMPS\_001}.

\subsection{De l'ordonnancement hiérarchique à la virtualisation}
\label{sec:hierarchicalrt}


\subsection{Hiérarchie et Time Division Multiplexing}

\paragraph{}
Les architectures logicielles compartimentées sont ordonnancées de façon
similaire aux systèmes temps réels à ordonnancement hiérarchique \cite{regehr_evolving_2003}. On
définit alors un ordonnancement dit {\it global}, correspondant à l'ordonnancement des compartiments, et un ordonnancement dit {\it local}
correspondant à l'ordonnancement des tâches dans un compartiment donné.\\
Un {\it slot} est associé à chaque compartiment. Ce slot est une fraction
temporelle périodique pendant laquelle le compartiment est autorisé à être
exécuté. L'exécution successive de l'ensemble des slots du systèmes forme un
motif temporel strict et prédictible définissant la période TDM.

\paragraph{}
Dans le cadre de ma thèse, j'ai étudié la problématique d'ordonnancement temps
réel des fonctions logicielles de la passerelle sur une base TDM, pour les
raisons de sécurité évoquées dans le Chapitre \ref{chap:solution_secu}. Les
fonctions de traitement des différents compartiments devant respecter des
exigences de temps réel s'appuient sur une politique d'ordonnancement de type
EDF (Earliest Deadline First). La solution s'appuie donc sur un ordonnancement
global TDM avec un ordonnancement local EDF, qui sera noté dans la suite
TDM/EDF.

\paragraph{}
Dans le cadre de cette architecture, il est cependant nécessaire de
déterminer, pour l'ensemble des compartiments ayant des tâches devant
respecter des exigences de temps réel, l'inter-arrivée et la durée nécessaire
du slot permettant d'assurer leurs échéances. La particularité de la solution de
compartimentation pour la sécurité sur base TDM est que l'ordonnanceur global,
géré au niveau de l'hyperviseur, n'est pas informé en-ligne des propriétés temps réel
des tâches hébergées dans les compartiments. De plus, le respect du
partitionnement TDM strict interdit toute variation du motif d'ordonnancement
des compartiments. En conséquence, bien que l'ordonnancement local des tâches d'un
compartiment donné puisse être considéré en ligne (c'est le cas de la
politique d'ordonnancement EDF), l'ordonnancement global est calculé hors
ligne. C'est ce calcul qui est considéré ici.

\paragraph{}
Plusieurs variables sont introduite dans la Table \ref{tab:vars} afin de formaliser l'ordonnançabilité
d'une architecture logicelle compartimentée sur une base TDM (Time Division
Multiplexing) stricte.

\begin{table}
\begin{tabular}{ll}
 {\it Variables de niveau {\it global}} & {\it Variables de niveau {\it local}} \\
 \begin{minipage}{0.48\linewidth}
 \fbox{
    \begin{minipage}{0.97\linewidth}
        Considérant $m$ compartiments, on définit:\\
        $U_{i}:$ la charge associée au compartiment $C_{i}$\\
        $SC=\{SC_1,\ldots,SC_m\}$ la durée du slot $S_i$ associé à $C_{i}$\\
        $\tau=\{\tau_1,\ldots,\tau_m\}$ l'ensemble des ensembles tâches associés à $C_i$\\
        $ST_{i}$ La période du slot $S_{i}$\\
        $SC_{i}$ La durée du slot $S_i$\\
    \end{minipage}
 }
 \end{minipage}
 &
 \begin{minipage}{0.48\linewidth}
 \fbox{
    \begin{minipage}{0.97\linewidth}
        Considering $n$ tâches, on définit:\\
        $\tau_{i}$ l'ensemble de tâches du compartiment $C_{i}$, $\tau_{i} = \{ \tau_i^{1},
            \ldots, \tau_i^{n} \}$\\
            $d_{j}$ l'échéance de la tâche $\tau_{i}^{j}$ de $C_{i}$\\
            $c_{j}$ le WCET de la tâche $\tau_{i}^{j}$ de $C_{i}$\\
            $t_j$ la période de la tâche $\tau_{i}^{j}$ de $C_{i}$\\
            \vspace{10.5mm}
    \end{minipage}
 }
 \end{minipage}
 \\
\end{tabular}
\caption{Définition des variables de niveau compartiment et de niveau tâches\label{tab:vars}}
\end{table}


\begin{figure}[h]
\input{figures/hypervisor_global_sched.tex}
\caption{Ordonnancement hiérarchique sur base TDM\label{fig:hyp_global_sched}}
\end{figure}


%-------------8<

\paragraph{}
Afin de garantir l'ordonnançabilité d'un tel système, plusieurs contraintes doivent être satisfaites. Certaines sont des
contraintes {\it globales} (au niveau  de l'ordonnanceur de l'hyperviseur) d'autres {\it locales} (au
niveau de l'ordonnanceur local au compartiment). Ces contraintes sont définies
dans la Table \ref{tab:contr_hier_tdm}.

\begin{table}

\begin{tabular}{l}
\begin{minipage}{0.98\textwidth}
\fbox{
    \begin{minipage}{0.98\textwidth}
        %\begin{linearProg}
        %\end{linearProg}
        %\vspace{-5mm}
            \noindent \textbf{Considérant la table \ref{tab:vars}, soit le
              problème:} {\it Maximiser $min_{i=1\ldots,n} SC_i(1-U_{i})$}
            {\bf sous les contraintes:}

        \begin{tabular}{l|l}
                \noindent \textit{contraintes de niveau global} &
                \noindent \textit{contraintes de niveau local}\\
        \begin{minipage}{0.45\textwidth}
                    {\small
            \begin{equation}
                \sum_{i=1}^m U_i \leq 1
                                \label{eqn:vm_load_sum}
            \end{equation}
            \begin{equation}
                \forall i\in \{ 1, \ldots, m \}, \frac{ST}{ST_i}\in
                \mathbb{N}^*
                                \label{eqn:slots_relative}
            \end{equation}
            \begin{equation}
                \sum_{i=1}^m SC_i \leq gcd(ST_1,\ldots,ST_m)
                                \label{eqn:slots_pgcd}
            \end{equation}
                        }
        \end{minipage} &
        \begin{minipage}{0.52\textwidth}
                    {\small
            \begin{equation}
                \forall i\in \{ 1, \ldots, m \}, \forall \tau_i^j \in S_i, d_j>ST_i-SC_i
                                \label{eqn:deadline_vs_ST}
            \end{equation}
                        \begin{center}
                        $\forall k \in \mathbb{N}^*, \forall t \in [ kST_{i} - SC_{i}, kST_{i}],$
            \begin{equation}
                            h(t) \leq t - k(ST_{i} - SC_{i})
                                \label{eqn:edf_sched}
            \end{equation}
                        {\it avec} $h(t) = \sum_{j = 1}^{n} max (0, 1 + \lfloor \frac{t - d_{j}}{t_{j}} \rfloor)c_{j}$,
                        \end{center}
                        }
        \end{minipage}\\
        \end{tabular}
    \end{minipage}
}
\end{minipage} \\
\end{tabular}
\caption{Formalisation des contraintes sur l'ordonnancement hiérarchique de tâches sur base TDM\label{tab:contr_hier_tdm}}
\end{table}

Les contraintes globales sont les suivantes:\\
L'Equation \ref{eqn:vm_load_sum} garantie que la charge processeur est
inférieur à 1. L'Equation \ref{eqn:slots_relative} est une condition
nécessaire pour assurer l'usage de slots temporels périodiques. L'Equation
\ref{eqn:slots_pgcd} est une confition suffisante pour assurer que les slots
ne se chevauchent pas, comme définit dans \cite{schedcond}.\\
La Figure \ref{fig:hyp_global_sched} décrit un exemple de répartition
temporelle entre différents slots.\\
Il est également nécessaire de considérer une contrainte locale. L'Equation
\ref{eqn:deadline_vs_ST} est une condition nécessaire pour garantir que les
tâches des compartiments exécutés dans le cadre de slots temporels ont
toujours une échéance supérieure à la période d'inactivité associées à ce
compartiment. On s'appuie, dans le cadre d'une hiérarchie d'ordonnancement de
type TDM/EDF, sur l'Equation \ref{eqn:edf_sched}, qui est une condition
nécessaire et suffisante de faisabilité dans le cadre de l'ordonnancement EDF.
Cette Équation est démontrée dans la Preuve \ref{proof:hierarch}.

\begin{proof}
\label{proof:hierarch}
Pour démontrer l'Équation \ref{eqn:edf_sched}, considérons le slot $i$ et l'ensemble de tâches
exécuté localement avec une politique d'ordonnancement EDF dans ce slot.\\
\noindent
Le Slot $i$ est exécuté de manière périodique par l'hyperviseur, avec une
période de $ST_i$ unités de temps. Les tâches exécutées dans ce slots le sont
pour une durée contigüe de $SC_i$ unité de temps. On commence par déterminer
le scénario pire cas en terme de faisabilité pour cet ensemble de tâches. Ce
dernier est arrive si:
\begin{itemize}
\item Toutes les tâches sont relâchées simultanément (en $t_0$)
\item Le slot $i$ a déjà été exécuté entre $t_{-SC_i}$ et $t_0$, de telle
sorte que les tâches ont raté l'échéance du slot et ne pourront être exécutées
que lors du prochain slot, soit $ST_i - SC_i$ unités de temps plus tard
\end{itemize}
Ce scénario maximise clairement à la fois la charge associée à l'ensemble de
tâches du slot et le délai avant l'exécution de cet ensemble de tâches.
Le scénario pire cas étant déterminé, il reste ensuite à définir la condition
de faisabilié d'un ensemble de tâche ordonnancé par une politique de type EDF
dans le slot $i$ dans le cadre de ce scénario.\\
Toutes les tâches relâchées dans l'intervalle de temps $[0, t]$ avec une
échéance absolue inférieure ou égale à $t$ sont ordonnançables et respectent
leur échéances si et seulement si elles sont exécutées durant au pire $t -
k(ST_i - SC_i)$ unités de temps. Cela se traduit en:\\
Pour tout entier $k$ avec $k \geq 1$, pour tout $t$ dans l'intervalle $[k ST_i
- SC_i, k ST_i]$, la fonction de demande processeur au temps $t$, $h(t)$ est
  inférieure ou égale à $t - k(ST_i - SC_i)$ (condition de l'équation
  \ref{eqn:edf_sched})
\end{proof}

\section{Moniteurs de sécurité, fonctions temps réel et environnements non sécurisables}

\subsection{Compatibilité des moniteurs de sécurité avec le temps réel}

\paragraph{}
Les moniteurs de sécurité sont considérés, dans le cadre de ma thèse, comme
ordonnancés directement dans l'hyperviseur. Cela découle du choix de
la solution PikeOS \cite{pike_kaiser2007evolution} comme hyperviseur. Ce
dernier est en effet apte à virtualiser des environnements complexes tout en
positionnant à leurs côtés des threads ordonnancés directement par le
micro-noyau. Ces derniers sont ordonnancés avec les contraintes du TDM, mais
peuvent donc être considérés comme des tâches temps réel. Leur simplicité et
leur faible volumétrie de code permet de déterminer leur coût d'exécution pire
cas. Chaque thread étant autonome dans son propre slot TDM, la période
correspond alors à la période de récurrence de ce slot et l'échéance
correspond à la durée de ce dernier. Cette durée est déterminée à partir du
WCET de la fonction.

\subsection{Compatibilité des environnements non certifiables avec le temps réel}

\paragraph{}
Dans le cadre de mes travaux, j'utilise dans les compartiments non certifiables
le système d'exploitation GNU/Linux. Ce dernier fournit une grande richesse
applicative et une pile réseau très complète. Cependant, GNU/Linux n'est pas un
système d'exploitation compatible avec des exigences temps réel dur. En effet,
le noyau Linux étant très riche il s'appuie:
\begin{itemize}
  \item sur des threads noyau ordonnancés avec les politiques d'ordonnancement
    temps réel de POSIX (SCHED\_FIFO et SCHED\_RR) qui intègrent un mécanisme
    complexe de vieillissement. La charge associée à ces threads est
    difficilement bornable car elle correspond pour la plupart à la
    conséquence de traitements d'entrées/sorties comme la gestion du disque.
    Ces threads possèdent néanmoins une affinité CPU, ce qui évite de les
    migrer en fonction de la charge. Malheureusement, l'assignation d'un
    traitement à un coeur processeur plutôt qu'à un autre n'est pas définissable
    sous la forme d'une configuration, mais s'établit en fonction de la charge
    courante de chacun des c{\oe}urs.
  \item sur des fonctions logicielles qui génère une surcharge non maîtrisée
    des traitements via du {\it vol de cycle} : ces fonctions
    (nommées {\it softirq}) ont été intégrées sous formes de codes
    complémentaires exécutés à la suite de divers services comme les appels
    systèmes ou les interruptions, afin de permettre une bonne réactivité de
    certaines fonctions (émission/réception de paquets, timers haute
    résolution, etc.).
    Cependant, une telle solution ne permet pas de garantir un coût d'exécution
    pire cas pour les processus ordonnancés car leur propre exécution est impactée
    par ces fonctions. Ces dernières étant de plus en plus fréquentes avec les
    nouvelles versions du noyau, et sont difficiles à dimensionner. Néanmoins,
    des travaux commencent à être fait pour intégrer leur impact
    dans le cadre d'analyses d'ordonnançabilité \cite{lewandowski2007modeling}.
\end{itemize}

\paragraph{}
Malgré tous ces éléments problématiques pour le temps réel, il existe
plusieurs patchs permettant de rétablir un peu de comportement temps réel dans
le noyau Linux. Dans le cadre de ma thèse, je ne parle cependant
pas des solutions RTAI ou Xenomai, qui impliquent des exigences particulières
sur les tâches temps réel, leur interdisant l'usage des API standard Linux
sous peine de perdre leur propriétés temps réel. Dans le cadre de la
définition d'une passerelle pour du traitement réseau, il est nécessaire que
ces tâches soient aptes à traiter des flux télécom, et donc à s'interfacer
avec l'API POSIX de traitement réseau. Afin de répondre à cette problématique,
je me suis donc appuyé sur la solution Linux-RT, qui intègre les travaux du
patch PREEMPT\_RT d'Ingo Molnar \cite{koolwal2009myths}. Cette solution permet
de modifier le comportement du noyau Linux en divers points:
\begin{itemize}
  \item Les threads noyaux ne s'exécutent plus avec une haute priorité temps
    réel, supprimant la collision de ses derniers avec l'ensemble des tâches
    temps réel.
  \item Les {\it softirqs} ne s'exécutent plus via du vol de cycle, mais
    exclusivement dans un thread kernel spécifique appelé {\it ksoftirqd}.
\end{itemize}

\paragraph{}
Dans le cadre de mes travaux, j'ai dimensionné l'impact de ce patch sur la
variation de latence à l'initialisation d'un job de priorité maximum. Cette
mesure permet de déterminer si il est effectivement possible de définir une
borne supérieure à cette initialisation.\\
Pour cela, je me suis appuyé sur de
l'outillage de test \cite{abeni2002measurement} pour simuler une forte charge à
la fois en terme d'entrées/sorties, d'accès mémoire et de charge processeur.
Je décrit plus précisément ces différentes mesure dans le Chapitre \ref{sec:passsystronique},
dans le cadre d'un maquettage de la solution sur une architecture logicielle
basée sur GNU/Linux. Les mesures ont montré qu'il est possible de garantir une
borne supérieure à l'instanciation d'une tâche temps réel y compris en cas de
forte surcharge de la solution logicielle.

\paragraph{}
Il est donc possible, selon le besoin, de positionner des tâches temps réel
souple dans des compartiments GNU/Linux. Les tâches à contraintes temps réel fortes ne
sont cependant pas intégrables dans les compartiments basés sur des systèmes
d'exploitation sans propriétés temps réel fortes.

\section{Intégration du support des flux à criticité mixte}
\label{sec:mixedcrit}

\subsection{Rappels et enjeux}

\paragraph{}
Les systèmes systroniques possèdent des
exigences impliquant de considérer des niveaux de criticités hétérogènes dans
un même ensemble de tâches. La première cause est la présence d'exigences physiques
associées à la systronique, qui limite la puissance processeur utilisable dans
le cadre de la passerelle. A défaut de pouvoir utiliser un environnement
matériel suffisamment puissant pour traiter l'ensemble des tâches temps réel
avec des mesures de coût d'exécution pessimistes, je me replie sur les
mécanismes de criticité mixte afin d'ordonnancer au mieux l'ensemble des
tâches nécessaire aux divers traitements. L'Exigence
\hyperlink{REQTEMPS002}{REQ\_TEMP\_002},
définie dans le Chapitre \ref{sec:matrix} est alors respectée.

Ainsi, dans le cadre d'une passerelle multi-niveaux en charge de traitements
réseaux, il est possible de classifier ces différents traitements en fonction
de leur impact fonctionnel, et donc de déterminer une classification en terme
de criticité mixte. La Figure \ref{fig:net_multicriticity} décrit ainsi un
ensemble de tâches $\tau$ en charge de traitements divers sur plusieurs flux.
Le niveau de criticité n'est pas porté par le flux lui même mais par le type
de traitement apporté par chaque tâche. A défaut de pouvoir s'appuyer sur de
la qualité de service réseau, on s'appuie alors sur un ordonnancement à
criticité mixte, qui se charge d'assurer le traitement des tâches les plus
critiques, y compris en cas de dépassement de coût d'exécution pire cas de la
part des tâches plus faiblement critiques.

\begin{minipage}[c]{7cm}
      \input{figures/multi_criticity_network_mgmt.tex}
      \captionof{figure}{Traitements multi-critiques de flux réseaux\label{fig:net_multicriticity}}
\end{minipage}
\hfill
\begin{minipage}[c]{7cm}
      \begin{tabular}{c|c|c}
      Tache & Niveau de criticité $l$ & flux associé\\
      \hline
      $\tau_{1,1}$ & 1 & $f_1$\\
      $\tau_{1,2}$ & 2 & $f_1$\\
      $\tau_{1,3}$ & 3 & $f_1$\\
      $\tau_{2,1}$ & 2 & $f_2$\\
      $\tau_{2,2}$ & 1 & $f_2$\\
      $\tau_{3,1}$ & 3 & $f_3$\\
      $\tau_{3,2}$ & 2 & $f_3$\\
      $\tau_{3,1}$ & 1 & $f_3$\\
      \end{tabular}
      \captionof{table}{Niveau de criticité des différentes tâches de traitement de flux}
\end{minipage}

Pour rappel, dans le cadre de la criticité mixte, le WCET des tâches de fortes criticité est
estimé plusieurs fois, avec des méthodes plus ou moins pessimistes selon le
niveau de certification demandé. Plus l'autorité de certification veut
garantir le respect du WCET de la tâche, plus la valeur estimée est
pessimiste. Cela implique que lors de l'exécution du système, si une autre
tâche atteint une estimation de son WCET à un niveau d'assurance qui est
supérieur au niveau de criticité de la tâche initiale, cette dernière est
alors suspendue, les conditions nécessaires à sa faisabilité n'étant plus
respectées \cite{bbalmms}. Néanmoins, cette approche peut être pessimiste, les tâches de
plus faible criticité pouvant potentiellement continuer à s'exécuter, ou du
moins continuer leur traitement pour quelques temps sans pour autant
compromettre les contraintes temporelles des tâches de plus forte criticité.\\
En conséquence, nous appliquons une stratégie précédemment proposée pour les ensembles de
tâches traditionnels \cite{bougueroua_george_midonnet}, habituellement appelée
{\it analyse de sensibilité} et qui permet de définir une marge de
  tolérance dans le cadre des espaces de tâches à criticité mixte.
Nous proposons ensuite une implémentation simple de la marge de tolérance qui
s'appuie exclusivement sur les timers, appelée {\it Latest Execution
  Time} (LET). Afin d'assurer une bonne continuité de l'exécution de l'ensemble
de tâches à criticité mixte, nous montrons également qu'il existe un instant dans
l'exécution de l'ensemble des tâches où il est possible d'exécuter à nouveau
l'intégralité des tâches.

%%%%%%%%%% Model and Definitions %%%%%%%%%%
\subsection{Modèle et Définitions}\label{modelDef}

\paragraph{}
Dans le cadre de ces travaux, la cible est l'ordonnancement préemptif sur
architecture mono-c{\oe}ur. La cible de ma thèse associant des mécanismes de
compartimentations et d'affinité, je considère alors que les environnements
d'exécution nécessitant de la criticité mixte doivent être associés par
affinité CPU à un et un seul c{\oe}ur, afin de rester compatibles avec les
hypothèses nécessaires dans le cadre de l'algorithme LET.\\
Soit un ensemble de tâche 
$\tau = \{\tau_1, \tau_2, ..., \tau_n\}$
où le niveau de criticité maximum d'une tâche est dénoté $\mathnormal{L}$.
Dans un système à criticité mixte, une tâche à criticité mixte est caractérisé
par un 5-uplet 
$\tau_i = \{R_i, T_i, D_i, \chi_i, C_i\}$ où:
%where the maximum criticality of a task is bound by
%$\mathnormal{L}$. A task in a mixed-criticality system is characterized by a 5-tuple
\begin{itemize}
	\item[$\bullet$] $R_i \in \mathbb{N}$ est la charge associée au
          premier job de la tâche $\tau_i$;
	\item[$\bullet$] $T_i \in \mathbb{N}^*$ est la période de la tâche $\tau_i$;
	\item[$\bullet$] $D_i \in \mathbb{N}^*$ est l'échéance de la tâche $\tau_i$, $D_i \leq T_i$;
	\item[$\bullet$] $\chi_i \in \mathbb{N}$ est le niveau de criticité
          maximum de la tâche $\tau_i$,
          $\chi_i \leq \mathnormal{L}$;
	\item[$\bullet$] $C_i \in \mathbb{N}^{\mathnormal{L}}$ est un vecteur
          de taille $L$ de coûts d'exécution pire cas, où $C_i(\ell)$ est une
          estimation du WCET de la tâche $\tau_i$ au niveau de criticité $\ell \in [1,\mathnormal{L}]$.
\end{itemize}
Nous considérons que $C_i(\ell)$ s'accroît de manière monotone pour un accroissement
de $\ell$. Plus précisément, pour une tâche $\tau_i$:
\begin{itemize}
	\item[$\bullet$] $\forall m \in [1, \chi_i[$, $C_i(m) \leq C_i(m+1)$;
	\item[$\bullet$] $\forall m \in [\chi_i, \mathnormal{L}[$, $C_i(m) = C_i(\chi_i)$.
\end{itemize}
Cela suppose qu'aucune tâche ne s'exécute plus longtemps que son WCET pour son
niveau courant de criticité.
Le $k^\text{n}$-ème job $J_k^i$ instancié par une tâche à criticité multiple $\tau_i$
est caractérisé par un 5-uplet $\{r_k^i, d_k^i, \mathcal{X}_k^i, C_k^i,
  c_k^i\}$ où:
\begin{itemize}
	\item[$\bullet$] $r_k^i \in \mathbb{N}$ est l'instant où $J_k^i$ est
          instancié.
          Étant donné que l'on considère un ensemble de tâches sporadique, on
          a $r_k^i \geq r_{k-1}^i + T_i$, et $r_1^i = R_i$;
	\item[$\bullet$] $d_k^i \in \mathbb{N}^*$ est l'échéance absolue de
          $J_k^i$. Plus précisément: $d_k^i = r_k^i + D_i$;
	\item[$\bullet$] $\mathcal{X}_k^i \in \mathbb{N}$ est la criticité de
          $J_k^i$, héritée de la tâche $\tau_i$: $\mathcal{X}_k^i = \mathcal{X}_i$;
	\item[$\bullet$] $C_k^i \in \mathbb{N}^{\mathnormal{L}}$ est la taille
          $L$ du vecteur de WCETs pour $J_k^i$, hérité de la tâche $\tau_i$: $C_k^i = C_i$;
	\item[$\bullet$] $c_k^i \in \mathbb{N}^*$ est l'exact coût d'exécution
          du job $J_k^i$. Du fait des spécifications de $\tau_i$, on peut dire
          que $c_k^i \leq C_i(\mathcal{X}_i)$, mais la valeur exacte de
          $c_k^i$ n'est connue que lorsque $J_k^i$ termine sont exécution.
\end{itemize}

\begin{definition}
Une tâche $\tau_i$ de criticité minimum $\ell+1$ est sujette à un \emph{dépassement
d'exécution de niveau $\ell$}, si un job instancié par $\tau_i$ dépasse sont
coût d'exécution pire cas de niveau $\ell$.
\end{definition}

A tout instant $t$, on appelle le $j^\text{ème}$ job $J_j^i$ instancié par la
tâche $\tau_i$ \emph{disponible} si $t \geq r_j^i$ et $J_j^i$ n'a pas encore
terminé son exécution. Le coût d'exécution effectif du job $J_j^i$ n'est pas
mesurable à partir des spécifications de $\tau_i$, mais ne sera connu qu'une
fois que $J_j^i$ aura terminé sont exécution.
A tout instant $t$ on appelle le \emph{scénario} $s_i^t$ de la tâche $\tau_i$
comme l'ensemble des coûts d'exécution exacts $\{c_1^i, c_2^i, ..., c_k^i\}$
pour chacun des $k$ jobs instanciés par $\tau_i$ qui ont déjà terminé leur
exécution à l'instant $t$. Le scénario de l'ensemble de tâches à criticité
mixte $\tau$ à l'instant $t$ est défini comme $s^t = \{s_1^t, s_2^t, ...,
  s_n^t\}$\\
Le \emph{niveau de criticité} du scénario $s^t$ est défini comme le plus
petit entier $\ell$ pour lequel, pour chaque $s_i^t \in s^t$, $c_k^i \leq C_i(\ell)\, \forall k$
Intuitivement, il représente le plus petit niveau de criticité dans lequel aucune tâche ne
dépasse son coût d'exécution pire cas de niveau de criticité correspondant.
Si cet entier $\ell$ n'existe pas, alors le scénario est dit \emph{erroné},
car au moins une tâche dépasse son coût d'exécution pire cas de son
niveau de criticité propre ($c_j^i > C_i(\chi_i)$).

\begin{definition}
Un ordonnancement pour un scénario $s^t$ de niveau de criticité $\ell$ est
faisable si tous les jobs $J_j^i \in s_i^t$, $\forall i$, avec $\chi_i \geq \ell$,
termine sont temps d'exécution $c_j^i$ entre son instanciation et son
échéance.
\end{definition}
Cette définition implique que l'ordonnancement à criticité mixte n'a pour but
que de garantir les contraintes temporelles des tâches dont le niveau de
criticité est supérieur ou égal au niveau de criticité du scénario.

\begin{definition}
Une politique d'ordonnancement en ligne est correcte pour un ensemble de tâches
$\tau$ si, pour tout scénario non-erroné de $\tau$, la politique génère un
ordonnancement faisable.
\end{definition}
Du fait qu'une politique d'ordonnancement en ligne ne découvre le coût
d'exécution exact des jobs qu'une fois que ces derniers ont terminé leur
exécution, le niveau de criticité du scénario ne peut être connu qu'après
coup. Les jobs instanciés sont alors ordonnancés. Dès qu'un job dépasse son
coût d'exécution pire cas de niveau $\ell-1$, la criticité du scénario est
accrue au niveau $\ell$, les jobs instanciés de criticité inférieure à $\ell$
sont abandonnés, et les requêtes futures des tâches de criticité inférieure à
$\ell$ ne sont plus considérées.

\begin{definition}
Un ensemble de tâche de criticité mixte $\tau$ est dit ordonnançable
si il admet au moins une politique d'ordonnancement en ligne correcte.
\end{definition}

La Figure \ref{extendedModel} étend le modèle traditionnel des états des tâches
\cite{osekvdx} avec des transitions complémentaires, afin de prendre en
considération le mécanisme de suspension de tâche.

\begin{figure}[h!]
	\begin{center}
		\begin{tt}
		\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.8cm,
				            thick,every label/.style={draw,black}]
		\tikzstyle{every state}=[fill=white,rectangle,draw=black,text=black, rounded corners = 3]
		\tikzstyle{trait}=[rectangle,fill=white,inner sep=0pt,rounded corners = 10]
		\tikzstyle{traite}=[ellipse,fill=white,inner sep=0pt,rounded corners = 10]
		  
		\node[state]		(0)		at (10,2.5)                {Exécutée};
		\node[state]		(1)		at (10,-2.5)                {Prête};
		\node[state]		(2)		at (14,0)                {Suspendue};
		
		\path 	(0)	edge[bend left]			node[below]				{}	(1)
				(0)	edge[]					node[above,sloped]		{}	(2)
				(1)	edge[bend left]			node[below]				{}	(0)
				(2)	edge[]					node[below]				{}	(1)
				(1)	edge[in=290,out=340]	node[above, sloped]		{}	(2)
				(2)	edge[loop right]		node[below]				{}	(2);
				
		
		\node[trait]		(3)		at (16.1,0.85)					{	\begin{tabular}{c}
									{\footnotesize Active }\\
									{\footnotesize $[\ell > \chi_i]$}
								\end{tabular}
							};
		\node[traite]		(3)		at (13,-2.5)					{\footnotesize Abandonne};
		
		\node[trait]		(3)		at (12.1,-1.2)					{	\begin{tabular}{c}
									{\footnotesize Active }\\
									{\footnotesize $[\ell \leq \chi_i]$}
								\end{tabular}
							};
		\node[traite]		(3)		at (12,1.25)					{\footnotesize Termine};
		\node[traite]		(4)		at (11,0)						{\footnotesize Préempte};
		\node[traite]		(5)		at (9,0)						{\footnotesize Démarre};
		
		%\node[traite]		(6)		at (11.5,4)					{\footnotesize [Condition]};
		%\node[traite]		(7)		at (13.5,4)					{\footnotesize $\langle$Event$\rangle$};

		  
		\end{tikzpicture}
		\end{tt}
	\end{center}
\caption{Modèle étendu des états de tâches}\label{extendedModel}
\end{figure}


Une tâche peut être dans un des états suivants:
\begin{itemize}
	\item[$\bullet$] Exécutée: une tâche $\tau_i$ est exécutée lorsque
          l'ordonnanceur choisit $\tau_i$ pour l'exécuter. Dans cet état, les
          instructions de $\tau_i$ sont traitées par le CPU. A tout moment, au
          plus une tâche est dans un état {\it Exécutée}.
	\item[$\bullet$] Prête: une tâche $\tau_i$ atteint l'état prêt si tous
          les prérequis fonctionnels pour une transition vers l'état {\it
            Exécutée} sont présents, et $\tau_i$ est en attente uniquement
          d'une élection de la part de l'ordonnanceur.
	\item[$\bullet$] Suspendue: une tâche $\tau_i$ atteint l'état suspendu
          si elle n'est actuellement pas candidate à une élection par
          l'ordonnanceur.
\end{itemize}
Les transitions ont les significations suivantes:

\begin{itemize}
	\item[$\bullet$] Démarre: La tâche est sélectionnée par l'ordonnanceur
          pour être exécutée.
	\item[$\bullet$] Préempte: La tâche est préemptée par une autre tâche.
	\item[$\bullet$] Termine: La tâche a complété correctement sont
          exécution.
	\item[$\bullet$] Abandonne: La criticité du système atteint un niveau
          supérieur à celui de la tâche, qui est en conséquence abandonnée.
          Cela n'arrive que lorsque $\tau_i$ est préemptée par une tâche de
          priorité et de criticité supérieure.
	\item[$\bullet$] Active [$\ell > \chi_i$]: La tâche souhaite
          instancier
          un nouveau job, mais le niveau courant de criticité du système est
          supérieur au niveau de criticité de la tâche.
	\item[$\bullet$] Active [$\ell \leq \chi_i$]: La tâche souhaite
          instancier
          un nouveau job, et le niveau de criticité du système est inférieur
          ou égal à celui de la tâche.
\end{itemize}

\begin{exmpl}\label{ex:mcTaskSet1}
Considérons un ensemble de tâches à triple criticité ($\mathnormal{L} = 3$) 
$\tau = \{\tau_1, \tau_2, \tau_3\}$, avec:
  
\begin{itemize}
	\item[$\bullet$] $\tau_1: \{0, 5, 5, 1, (1,1,1)\}$;
	\item[$\bullet$] $\tau_2: \{0, 7, 7, 2, (1,3,3)\}$;
	\item[$\bullet$] $\tau_3: \{0, 8, 8, 3, (1,3,7)\}$.\\
\end{itemize}
Tout scénario pour lesquels aucun job ne dépasse un coût d'exécution de 1 est
de criticité 1, tandis que tout scénario pour lequel les tâches $\tau_2$ et
$\tau_3$ s'exécutent pour au moins 2 unités de temps et au plus 3 unités de
temps est de criticité 2. Si tout job de la tâche $\tau_3$ s'exécute entre 4
et 7 unités de temps, alors cela définit un scénario de criticité 3. Pour
finir, tout autre scénario est erroné.
\end{exmpl}

\begin{definition}
Le coût d'exécution pire cas $r_i$ de la tâche $\tau_i$ est la durée maximum
pour exécuter la tâche $\tau_i$, en prenant en compte l'exécution de toutes
les tâches de priorités supérieures à $\tau_i$. On a $r_i \geq C_i(\chi_i)$.
\end{definition}

\begin{definition}
  Un \emph{instant critique} pour une tâche $\tau_i$ est défini comme étant un
  instant où $\tau_i$ instancie un travail dont le temps de réponse sera le plus
  grand parmi tous les travaux instanciés par $\tau_i$.
\end{definition}

Liu \cite{Liu2000} a montré que, lorsque l'on considère un ensemble de tâches
traditionnelles ordonnancées en priorité fixe (FP), un instant critique pour une
tâche $\tau_i$ se présente à chaque fois que $\tau_i$ instancie un job de
manière simultanée avec toutes les tâches $\tau_j$ de priorité supérieure.
Comme montré dans le théorème \ref{theo:criticalInstant}, ce principe peut
être étendu aux ensembles de tâches à criticité mixte.

\begin{theorem}\label{theo:criticalInstant}
Soit $\tau = \{\tau_1, \tau_2, ..., \tau_n\}$ un ensemble de tâches
sporadiques à criticité mixte ordonnancé avec une politique d'ordonnancement à
priorité fixe. L'instant critique d'une tâche $\tau_i$ se présente dès lors
que $\tau_i$ instancie un job simultanément avec toutes les tâches $\tau_j$ de
priorité supérieure.
\end{theorem}
\begin{proof}
Sachant que chaque tâche $\tau_i$ est certifiée pour un niveau d'assurance qui
est égal à son niveau de criticité $\mathcal{X}_i$, on peut associer chaque
tâche $\tau_j \in \tau$ à une tâche traditionnelle $\tau_j'$, pour laquelle le
coût d'exécution pire cas de $\tau_j'$ est égal à $C_j(\mathcal{X}_j)$. En
revenant à un ensemble de tâches traditionnel, les résultats démontrés par
Liu \cite{Liu2000} sont réutilisable, ce qui prouve notre théorème.
\end{proof}

\subsection{Ordonnançabilité d'un jeu de tâches à criticité mixte\label{sufficientCondition}}

\paragraph{}
Baruah et al. \cite{bbalmms} ont démontré que le problème de
{MC-scheduling}, appliqué à un ensemble fini de jobs, est ${NP}$-complet.
Plutôt que de s'appuyer sur les conditions exactes du {\it MC-scheduling},
on cible une condition \emph{suffisante} qui peut être vérifiée dans un temps
polynomial.\\
L'algorithme utilisé pour vérifier cette condition, introduit par Vestal \cite{Vestal2007},
détermine hors ligne un ordre total des tâches dans $\tau$. Chaque tâche est
assignée à une priorité fixe distincte dont ses travaux héritent. L'assignation des
priorités est faite en utilisant l'approche d'Audsley \cite{Audsley_1991}, basée
sur la définition suivante (la priorité $n$ est la plus basse priorité, la
priorité 1 la plus élevée).

\begin{definition}
  Une tâche $\tau_i$ dans un ensemble de tâches à criticité mixte $\tau$ est
  dite \emph{viable au plus bas niveau de priorité} si toutes les conditions
  suivantes sont satisfaites:
	\begin{enumerate}
		\item la plus basse priorité est assignée à $\tau_i$;
		\item à toutes les autres tâches de $\tau$ peut être assignée
                  n'importe quelle priorité, du moment que cette priorité est
                  supérieure à celle assignée à $\tau_i$;
		\item tout job instancié par $\tau_i$ respecte son échéance
                  lorsqu'il est exécuté pour au plus $C_i(\chi_i)$ unité de
                  temps et toutes les autres tâches $\tau_j \in \tau$
                  instancient des jobs qui s'exécutent pour au plus
                  $C_j(\chi_i)$ unités de temps.
	\end{enumerate}
\end{definition}

%\begin{algorithm}[H]
\begin{algorithm}
\SetKwIF{Si}{SinonSi}{Sinon}{si}{alors}{sinon si}{alors}{finsi}
\SetKwInOut{Sortie}{sortie}
%\SetLine
\KwIn{$\tau$}
$\mathsf{pr} \leftarrow |\tau|$ \\
\While{$\tau \neq \varnothing$}{
	\If{aucune tâche $\tau_i \in \tau$ n'est viable à la priorité la plus basse}{
		\textbf{renvoyer} erreur\;
	}
	\Else{
		Soit $\tau_i$ une tâche viable à la priorité la plus basse\;
		assigne $\tau_i$ la priorité la plus basse $\mathsf{pr}$\;
		$\tau \leftarrow \tau\setminus\{\tau_i\}$\;
		$\mathsf{pr} \leftarrow \mathsf{pr}-1$\;
	}
}
\caption{Algorithme d'attribution d'un ordre total aux tâches d'un ensemble à
  criticité mixe\label{alg:priorityAssignment}}
\end{algorithm}

\paragraph{}
L'attribution de priorité est alors construite de manière itérative en utilisant
l'algorithme \ref{alg:priorityAssignment}.
Si un tel ordre de priorité existe, i.e. si une tâche viable est trouvée
à chaque niveau de priorité, alors chaque tâche $\tau_i$ est garantie de respecter
son échéance si elle s'exécute pour au plus $C_i(\chi_i)$ unités de temps et
qu'aucune tâche $\tau_j$ de priorité supérieure à $\tau_i$ s'exécute pendant
plus de $C_j(\chi_i)$ unité de temps.

\paragraph{}
Parce que la priorité d'une tâche est basée sur son niveau de criticité, on
dit qu'un ensemble de tâches ordonnançables selon une priorité basée sur
  leur propre criticité (Own Criticality Based Priority (ou
{\it OCPB-schedulability}) si on peut trouver un ordre complet des tâches en
utilisant l'algorithme \ref{alg:priorityAssignment}.

\begin{theorem}\label{theo:mcschedulability}
Si un ensemble de tâches à criticité mixte $\tau$ est OCBP-ordonnançable sur
un processeur donné, alors $\tau$ est ordonnançable sur ce même processeur.
\end{theorem}
\begin{proof}
Cette preuve est principalement inspirée par celle présenté par Baruah et al. \cite{baruah_li_stougie}.
Soit $\tau$ OCBP-ordonnançable, et soit, après renommage des tâches, $\tau_1 \vartriangleright
\tau_2 \vartriangleright ... \vartriangleright \tau_n$ représentant un ordre
complet des tâches de l'ensemble. Soit $\tau_i$ une tâche dans cet ordre de
priorité. Afin de démontrer l'ordonnançabilité au sens de la criticité mixte, on doit pouver que chaque
job instancié par la tâche $\tau_i$ peut avoir $C_i(\chi_i)$ unités de temps
d'exécution entre son instanciation et son échéance dans tout scénarion de
niveau de criticité $\chi_i$ ou inférieur. Mais dans n'importe lequel de ces
scénarios, chaque job instancié par la tâche $\tau_j$ s'exécute pendant pas
plus de $C_j(\chi_i)$ unités de temps. L'OCBP-ordonnançabilité de $\tau$ avec
un ordre de priorité $\tau_1 \vartriangleright \tau_2 \vartriangleright ...
\vartriangleright \tau_n$ implique que chaque job instancié par la tâche
$\tau_i$ aura $C_i(\chi_i)$ unités de temps d'exécution si aucun job instancié par une tâche 
 $\tau_j \in \{\tau_1, \tau_2, ..., \tau_{i-1}\}$ s'exécute plus de
 $C_j(\chi_i)$ unités de temps. En conséquence, $\tau_i$ respecte
 effectivement son échéance dans tout scénario de criticité $\chi_i$ ou
 inférieure.
\end{proof}

\begin{exmpl}\label{ex:mcTaskSet2}
Considérons de nouveau l'ensemble de tâche $\tau$ présenté dans l'exemple
\ref{ex:mcTaskSet1}. Une assignation de priorité qui rend $\tau$ ordonnançable
est $\tau_3 \vartriangleright \tau_2 \vartriangleright \tau_1$.
Dans ce cas, $\tau$ étant un ensemble de tâches périodique à instanciation
simultanées, $t=0$ est un instant critique pour toutes les tâches, ce qui
implique qu'il est nécessaire de considérer uniquement le temps de réponse du
premier job de chaque tâche pour déterminer l'ordonnançabilité. A La tâche
$\tau_1$ peut être assignée la plus basse priorité car son temps de réponse ne
dépasse pas $3 < D_1$ unités de temps quand aucune des autres tâches ne
dépasse son coût d'exécution pire cas de niveau de criticité 1. A La tâche
$\tau_2$ peut être assignée la priorité moyenne parce que son temps de rémonse
ne dépasse pas $6 < D_2$ unités de temps quand la tâche $\tau_3$ ne dépasse
pas son coût d'exécution pire cas de niveau de criticité 2. Pour finir, à la
tâche $\tau_3$ peut être assignée la plus haute priorité car son temps de
rémonse ne dépasse pas $7 < D_3$ unités de temps. $\tau$ étant
OCBP-ordonnançable, on peut alors dire, selon le théorème
\ref{theo:mcschedulability}, que $\tau$ est également ordonnançable au sens de
la criticité mixte.
\end{exmpl}

\paragraph{}
Dans la section suivante, on considère les ensembles de tâches
OCBP-ordonnançable. De plus, dans la Section \ref{sec:allowanceFP}, les
priorités fixes sont considérées comme assignées selon l'algorithme 
\ref{alg:priorityAssignment}.

%%%%%%%%%% delayingCriticalityRising %%%%%%%%%%
\subsection{Retarder l'accroissement de criticité}\label{delayingCriticalityRising}

Les politiques d'ordonnancement à criticité mixte traditionnelles arrêtent un
job dès lors que la criticité du scénario dépasse celle du job. En
particulier, dès que le niveau de criticité du scénario atteint $\ell$, toutes
les tâches $\tau_i$ avec $\chi_i < \ell$ sont suspendues, même si elles ont
encore suffisamment de charge processeur pour pouvoir continuer à s'exécuter
sans impacter les contraintes temporelles des jobs de criticité d'au moins
$\ell$.
Cela est dû à la condition de faisabilité lié à l'OCBP-ordonnançabilité,
présentée dans la Section~\ref{sufficientCondition} qui ne garantie plus les
contraintes temporelles.\\
Nous pensons que ce principe est trop restrictif et peut être réduit sous
certaintes conditions. Dans le cadre d'un ensemble de tâches
OCBP-ordonnançable, le lemme suivant nous permet déjà de réduire l'ensemble
des tâches à suspendre.

\begin{lemma}\label{lem1}
Soit $\tau$ un ensemble de tâche à criticité mixte OCBP-ordonnançable, et
$\tau_i$ n'importe quelle tâche dans l'ordre de priorité définit par
l'algorithme \ref{alg:priorityAssignment}. Quand un job instancié par
$\tau_i$ atteint son coût d'exécution pire cas de niveau de criticité 
$\ell \leq \mathcal{X}_i$, il n'est jamais nécessaire e suspendre les tâches
$\tau_j$ avec $\chi_j < \ell$ qui ont une priorité supérieure à $\tau_i$.
\end{lemma}


\begin{proof}
Soit $\tau_i \in \tau$ une tâche qui atteint sont coût d'exécution pire cas de
niveau de criticité $\ell$. $\tau$ étant OCBP-ordonnançable, chaque job
instancié par $\tau_i$ peut s'exécuter jusqu'à $C_i(\chi_i)$ unités de temps
et respecter son échéance si aucune tâche de priorité supérieure
$\tau_j$ s'exécute plus que $C_j(\chi_i)$. Soit $\tau_p$ une tâche de priorité
supérieure, dont le niveau de criticité $chi_p$ est inférieur à $\chi_i$.
Etant donné que $\chi_i > \chi_p$,  $C_p(\chi_i) = C_p(\chi_p)$, et
la condition d'OCBP-ordonnançabilité garantie que chaque job instancié par
$\tau_i$ peut s'exécuter jusqu'à son coût d'exécution pire cas de son propre
niveau de criticité. En conséquence, seul les tâches de plus basse criticité
qui ont une priorité inférieure à $\tau_i$ doivent être suspendues.\\
\end{proof}

%%%%%%%%%
Le Lemme \ref{lem1} évite la désactivation des tâches de plus basse criticité
pour lesquelles les conditions sont encore suffisantes pour permettre la
terminaison de leur exécution. Nous pourrions néanmoins aller encore plus
loin et et autoriser des tâches de criticité inférieure tant que les jobs que
ces dernières instancient sont aptes à respecter leur échéance. Cela revient à
déterminer combien de temps les tâches $\tau_i$ de criticité d'au moins
$\ell+1$ peuvent reporter la suspension de tâches de niveau de criticité
inférieur en cas de dépassement d'exécution de niveau $\ell$. On appelle cette
durée la \emph{marge de tolérance de niveau $\ell$} de la tâche $\tau_i$,
dénotée $A_i(\ell)$ En se basant sur cette marge de tolérance, on peut
déterminer le dernier instant au delà duquel la criticité doit être augmentée
et les tâches de criticité inférieure ne peuvent plus être assurées d'être
exécutées à temps pour respecter leur échéance.

%%%%%%%%%% Allowance %%%%%%%%%%
\subsection{Marge de tolérance}\label{sec:allowance}

La marge de tolérance dérive du concept d'analyse de sensibilité. L'analyse de
sensibilité a été étudié par Bini et al. \cite{bini_buttazzo,Bini2006}. Ils
discutèrent du concept d'espace de faisabilité qui nous permet de déterminer
l'espace des valeurs possible pour un paramètre spécifique d'une tâche.
Le principe de marge de tolérance a été initialement introduit par 
Bougueroua et al. \cite{bougueroua_george_midonnet} dans le contexte des
ensembles de tâches traditionnels sujets au risque de dépassement de WCET.
Leur travail a ciblé la résolution de la plus grande valeur qui peut être
ajoutée au WCET d'une tâche sans pour autant impacter l'ordonnançabilité de
l'ensemble de tâches, en considérant un modèle de fautes par fenêtre
temporelle glissante.\\

La marge de tolérance de niveau $\ell$ d'une tâche $\tau_i$ dont le niveau de
criticité est d'au moins $\ell+1$ consiste en le calcul de la marge de son
coût d'exécution pire cas de niveau $\ell$. Cela représente le coût d'exécution
maximum qui peut être ajouté à $C_i(\ell)$ sans impacter les contraintes
temporelles des tâches de criticité inférieure $\tau_j$ si elles s'exécutent
jusqu'à $C_j(\chi_j)$ unités de temps et $\tau_i$ s'exécute jusqu'à $C_i(\ell)
+ A_i(\ell)$ unité de temps. La marge de tolérance de niveau $\ell$ des tâches
pour lesquelles la criticité est inférieure ou égale à $\ell$ est alors mise à
zéro.

%%%%%%% Concepts and notations %%%%%%%
\subsubsection{Concepts et Notations}
Au travers de cette section, les concepts et notations suivantes sont utilisés:
\begin{itemize}
	\item[$\bullet$] $U_{\ell} = \sum\limits_{\tau_p \, | \, \chi_p \geq \ell} \dfrac{C_p(\ell)}{T_p}$
          est le facteur d'utilisation processeur au niveau de criticité
          $\ell$.
	\item[$\bullet$] FP$_\text{MC}$ dénote l'algorithme préemptif à
          priorité fixe (\emph{Fixed Priority Highest Priority First}), avec
          une assignation des priorités déterminée par l'algorithme
          \ref{alg:priorityAssignment}, et qui ordonnance uniquement les
          tâches de criticité supérieure ou égale à la criticité du scénario.
	\item[$\bullet$] Un modèle de faute dénoté $\dfrac{k}{W}$. Cela
          correspond, pour chaque niveau de criticité $\ell \in [0, L]$,
          d'au moins $k$ tâches ($0\leq k \leq n$), au risque de dépassement
          d'exécution de niveau de criticité $\ell$ pour une fenêtre glissante
          de taille $W$. On définit $W\leq\min\limits_i(T_i)$ pour éviter
          à une tâche d'être sujette à de multiple démassements de coût
          d'exécution pire cas de niveau $\ell$ dans une même fenêtre
          temporelle. Néanmoins, cela peut être trop pessimiste pour supposer
          que chaque tâche de criticité au moins égale à $\ell+1$ sera sujette
          à un dépassement d'exécution dans la même fenêtre. La valeur de $k$
          est associée à un ensemble de tâches et peut être obtenue de manière
          statistique en observant le véritable nombre de dépassements
          d'exécution de niveau de criticité $\ell$ durant l'exécution du
          système, ou au travers de contraintes de certification.
	\item[$\bullet$] Pour toute tâche $\tau_i$ ordonnancée avec
          FP$_\text{MC}$, et un modèle de faute $\dfrac{k}{W}$:
		\begin{itemize}
			\item[$\circ$] $\mathrm{hp}(i)$: l'ensemble des tâches
                          $\tau_j$ ayant une priorité supérieure à $\tau_i$;
			\item[$\circ$] $\mathrm{hp}^R(i)$: l'ensemble de job
                          disponibles instanciés par les tâches $\tau_j \in \mathrm{hp}(i)$;
			\item[$\circ$] $\mathrm{hp}_{k-1}(i,\ell)$: l'ensemble
                          d'au plus $k-1$ tâches $\tau_j$ ayant une priorité
                          supérieure à $\tau_i$, et une criticité $\chi_j >
                          \ell$. Si plus de $k-1$ tâches satisfont ces
                          conditions, on choisi les tâches les plus
                          récurrentes, i.e. les $k-1$ tâches ayant les périodes
                          les plus petites;
			\item[$\circ$] $\mathrm{lp}(i,\ell)$: l'ensemble de
                          tâches $\tau_j$ ayant une priorité inférieure à
                          $\tau_i$ et une criticité $\chi_j \geq \ell$.
			\item[$\circ$] $\mathrm{lp}^R(i,\ell)$: l'ensemble
                          des jobs disponibles instanciés par les tâches $\tau_j \in \mathrm{lp}(i,\ell)$;
			\item[$\circ$] L'équation suivante permet de calculer
                          la borne supérieure du temps de réponse pire cas
                          $r_i$ de $\tau_i$:
				\begin{equation}\label{equ:responseTime}
					r_i = C_i(\chi_i) + \sum\limits_{\tau_p \in \mathrm{hp}(i)} \left\lceil \dfrac{r_i}{T_p} \right\rceil \times C_p(\chi_i)
				\end{equation}
		\end{itemize}
\end{itemize}

Par la suite, on considère une distribution uniforme de la marge de tolérance
de niveau $\ell$ entre toutes les $k$ tâches de criticité au moins $\ell+1$,
i.e. chaque tâche de criticité au moins égale à $\ell+1$ possède une marge de
tolérance de niveau $\ell$ identique.

\begin{proposition}
Soit $\tau$ un ensemble de tâches à criticité mixte ordonnançable. Il en
découle que pour chaque niveau de criticité $\ell$, la condition suivante est
satisfaite:
	\begin{equation}
		U_{\ell} \leq 1
	\end{equation}
\end{proposition}

%%%%%%% Allowance with FP %%%%%%%
\subsubsection{Marge de tolérance en priorité fixe}\label{sec:allowanceFP}

Le théorème suivant décrit comment calculer la marge de tolérance de niveau
$\ell$ d'une tâche $\tau_i$ dans le cadre d'un ordonnancement à priorité fixe.
Les priorités assignées aux tâches sont celles sont celles qui répondent au
conditions d'OCBP-ordonnançabilité. Le calcul de $A_i(\ell)$ est basé sur le
temps de réponse pire cas des tâches avec la marge de tolérance intégrée.

\begin{theorem}
  Soit $\tau = \{\tau_1, \tau_2, ..., \tau_n\}$ un ensemble de $n$ tâches
  périodiques à criticité mixte ordonnancé en priorité fixe, et soit $\tau_1
  \vartriangleright \tau_2 \vartriangleright ... \vartriangleright
  \tau_n$ l'ordre de priorité qui correspond à une OCBP-ordonnançabilité. La
  marge de tolérance de niveau $\ell$ qui peut être garantie pour une tâche
  $\tau_i$ de criticité au moins égale à $\ell+1$, avec une distribution
  uniforme de la marge de tolérance, et un modèle de faute $\frac{k}{W}$, est
  la valeure positive minimum de $A_i(\ell)$ satisfaisant les équations
  suivantes:
	\begin{equation}\label{equ:cond3}
		C_i(\ell) + A_i(\ell) \leq C_i(\chi_i)
	\end{equation}
	
	\begin{equation}\label{equ:cond1}
		U_{\ell} + \sum\limits_{\tau_p \in \mathrm{hp}_{k-1}(i,\ell) \cup \tau_i} \dfrac{A_i(\ell)}{T_p}\leq 1
	\end{equation}
		
	\begin{equation}\label{equ:cond2}
		\begin{split}
			&\forall \tau_j \in \mathrm{lp}(i,\ell): \\
			&r_j^* = C_j(\chi_j) + \sum\limits_{\tau_p \in \mathrm{hp}(j)} \left\lceil \dfrac{r_j^*}{T_p} \right\rceil \times C_p(\chi_j) \\
			&\quad\quad\quad\quad\quad+ \sum\limits_{\tau_p \in \mathrm{hp}_{k-1}(i,\ell) \cup \tau_i} \left\lceil \dfrac{r_j^*}{T_p} \right\rceil \times A_i(\ell) \leq D_j
		\end{split}
	\end{equation}
	
\end{theorem}
\begin{proof}
  L'équation \ref{equ:cond3} garanti que la marge de tolérance n'autorise
  pas une tâche à s'exécuter pour plus que son coût d'exécution pire cas de
  niveau de criticité $\ell$ modifié pour prendre en compte la consommation de
  la marge de tolérance de niveau $\ell$ d'au plus $k$ tâches. On veut
  s'assurer que les tâches de criticité inférieure puissent continuer à
  respecter leur échéance en cas de dépassement d'exécution d'au plus $k$
  tâches de criticité supérieure pour une durée limitée par la marge de
  tolérance, ce qui nous mène à l'équation \ref{equ:cond2}. Cette équation
  représente le temps de réponse pire cas d'une tâche $\tau_j \in lp(i,l)$ lorsqu'elle
  s'exécute à son plus haut niveau de criticité, les tâches de plus haute
  criticité $\tau_p$ incluant $\tau_i$ s'exécutant pendant au plus
  $C_p(\chi_j)$ unités de temps et $k$ tâches de priorité supérieure $\tau_r$
  incluant $\tau_i$ consommant leur marge de tolérance.
  Cette équation ne doit être vérifiée que pour les tachs ayant une priorité
  inférieure à $\tau_i$ du fait du Lemme \ref{lem1}.
\end{proof}

Il en suit que les tâches de criticité $\ell$ ne doivent pas être suspendues
tant qu'une tâche de priorité supérieure $\tau_i$ de criticité $\chi_i > \ell$
ne s'exécute pas plus longtemps que $C_i(\ell) + A_i(\ell)$ unités de temps.

%%%%%%% Allowance with EDF %%%%%%%
\subsubsection{Marge de tolérance avec EDF}

Le principe de la marge de tolérance, initialement introduit par Bougueroua et
al. \cite{bougueroua_george_midonnet}, a été appliqué à la fois dans les
politiques d'ordonnancement à priorité fixe et dans la politique
d'ordonnancement EDF, pour les ensembles de
tâches traditionnels. Néanmoins, comme le déclare la proposition suivante, la
stratégie EDF (Earliest Deadline First) n'est pas optimale pour les ensembles
de tâches à criticité mixte.

\begin{proposition}
Tout ensemble de tâches à criticité mixte $\tau$ qui est ordonnançable au sens
de la criticité mixte n'admet pas nécessairement EDF comme une politique d'ordonnancement en ligne
correcte. En d'autres termes, EDF n'est pas optimal pour les ensembles de
tâches à criticité mixte.
\end{proposition}
\begin{proof}
Soit $\tau$ un ensemble de tâches à criticité mixte qui a été prouvé comme
ordonnançable au sens de la criticité mixte dans l'exemple \ref{ex:mcTaskSet2}. La Figure
\ref{fig:edfNotOptimal} montre que la criticité du scénario n'est pas accrue
suffisamment pour garantir les contraintes temporelles de la tâche $\tau_3$
quand toutes les tâches s'exécute avec leur coût d'exécution pire cas de leur
propre niveau de criticité.
\end{proof}
\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.40]{./figures/EDFNonOptimal.png}
		\caption{Non Optimalité de l'algorithme EDF}\label{fig:edfNotOptimal}
	\end{center}
\end{figure}
Etant donnée que cette étude cible les ensembles de tâches $\tau$ qui sont
ordonnançable en priorité fixe selon le principe d'{\it
  OCBP-schedulability}, et parce que cette propriété ne permet pas de déterminer
si Earliest Deadline First est une politique d'ordonnancement correcte pour
$\tau$, il n'est pas implémenté de principe de marge de tolérance pour
l'algorithme EDF.

%%%%%%% Allowance Domain %%%%%%%
\subsubsection{Domaine de tolérance}\label{sec:allowanceDomain}

%%%%%%%%%%%%%%
La Section \ref{sec:allowanceFP} a décrit comment calculer une marge de
tolérance de niveau $\ell$ équitablement partagée pour un ensemble de tâches
ordonnancé en priorité fixe. Néanmoins, nous souhaitons utiliser une autre
règle d'allocation pour la marge de tolérance de niveau $\ell$. Dans cette
Section, nous présentons une manière de représenter toutes les valeurs
possibles pour la marge de tolérance de niveau $\ell$, en caractérisant
l'espace des marges de tolérance de niveau $\ell$ faisables.

\begin{definition}
  Soit $A(\ell) = \{A_1(\ell), A_2(\ell), ..., A_n(\ell)\}$ l'ensemble de
  marges de tolérances pour un ensemble de tâches à criticité mixte $\tau$.
  On appelle surface de faisabilité de l'espace $A(\ell)$ l'ensemble des
  valeurs de $A(\ell)$ pour lesquelles $\tau$ reste faisable si chaque tâche
  $\tau_i \in \tau$ consomme jusqu'à $A_i(\ell)$ unité de temps
  supplémentaires au niveau de criticité $\ell$.
\end{definition}

Bini et al. \cite{bini_buttazzo} ont introduit une condition
d'ordonnançabilité pour les ensembles de tâches périodiques. Nous avons adapté
cette condition aux ensembles de tâches à criticité mixte dans le théorème
suivant:
\begin{theorem}
Un ensemble de tâches à criticité mixte $\tau$ est ordonnançable en priorités
fixes si et seulement si:
	\begin{multline}
		\forall i = 1,...,n, \; \exists t \in \mathrm{schedP}_i \, \text{tel que} \, \\
		C_i(\chi_i) + \sum_{\tau_p \in \mathrm{hp}(i)} \left\lceil \dfrac{t}{T_p} \right\rceil C_p(\chi_i) \leq t \label{eq:domain}
	\end{multline}
Où $\mathrm{schedP}_i$ est un ensemble de points d'ordonnancement définis
comme $\mathrm{schedP}_i = \mathcal{P}_{i-1}(D_i)$, et $\mathcal{P}_i(t)$
définit comme suit:
	\begin{equation}
		\left\{
			\begin{split}
				&\mathcal{P}_0(t) \\
				&\mathcal{P}_i(t) = \mathcal{P}_{i-1}\left(\left\lfloor \frac{t}{T_i} \right\rfloor\right) \cup \mathcal{P}_{i-1}(t)
			\end{split}
		\right.
	\end{equation}
En utilisant une notation compacte et des opérateurs logiques, l'Equation
\ref{eq:domain} peut être réécrite:
	\begin{equation}
		\bigwedge \limits_{i = 1,...,n} \bigvee \limits_{t \in \mathrm{schedP}_i} n_i \cdot C_i \leq t \label{eq:domainCompact}
	\end{equation}
où $n_i = \left(\left\lceil \frac{t}{T_1} \right\rceil, \left\lceil \frac{t}{T_2} \right\rceil, ..., \left\lceil \frac{t}{T_{i-1}} \right\rceil, 1\right)$ et $C_i = \left(C_1(\chi_i), C_2(\chi_i), ..., C_i(\chi_i)\right)$
\end{theorem}

Sachant que ce que nous souhaitons représenter est la surface de faisabilité
de l'espace $A(\ell)$, nous avons besoin d'introduire les variables de la marge
de tolérance. L'Equation \ref{eq:domainCompact} doit être étendue afin de
considérer une marge de tolérance de niveau $\ell$ pour chaque tâche de
criticité au moins égale à $\ell$.

\begin{theorem}
Soit $\tau$ un ensemble de tâches à criticité mixte. La surface de faisabilité
de l'espace $A(\ell)$ est calculée comme suit:
	\begin{equation}
		\bigwedge \limits_{\tau_i \, | \, \chi_i \geq \ell} \bigvee \limits_{t \in \mathrm{schedP}_i} \left\lgroup n_i \cdot C_i^{\ell} \leq t \wedge A_i(\ell) \leq C_i(\chi_i) - C_i(\ell) \right\rgroup \label{eq:domainCompactMC}
	\end{equation}
où $C_i^{\ell} = \left(C_1(\ell) + A_1(\ell), C_2(\ell) + A_2(\ell), ..., C_i(\ell) + A_i(\ell)\right)$.
\end{theorem}
\begin{proof}
L'Equation \ref{eq:domainCompactMC} étend l'Equation \ref{eq:domainCompact} en
autorisant chaque tâche à consommer jusqu'à son coût d'exécution pire cas au
niveau de criticité $\ell$ plus sa marge de tolérance, et empêche la marge de
tolérance d'autoriser une tâche à dépasser son coût d'exécution pire cas à son
propre niveau de criticité.
\end{proof}

\begin{exmpl}
Calculons maintenant les espaces de tolérance $A(\ell)$ pour $\ell = 1,2,3$
de l'ensemble de tâches à criticité mixte présenté dans l'Exemple \ref{ex:mcTaskSet1}.
Commençons par renommer les tâches en fonction de l'assignation de priorité.
La tâche $\tau_3$ devient la tâche $\tau_1$ et la tâche $\tau_1$ devient la
tâche $\tau_3$. La tâche $\tau_2$ reste inchangée.

\begin{itemize}
	\item[$\bullet$] l'espace de tolérance $A(1)$: L'ensemble de points
          d'ordonnancement à considérer est donné dans la Table \ref{schedP::1}. \\
		\begin{table}[h!]
		\begin{center}
			\begin{tabular}{|c||c|}
				\hline
				$\tau_i$ & $\mathrm{schedP}_i$ \\
				\hline
				\hline
				$\tau_1$ & \{8\} \\
				\hline
				$\tau_2$ & \{7\} \\
				\hline
				$\tau_3$ & \{5\} \\
				\hline
			\end{tabular}
		\end{center}
		\caption{Points d'ordonnancement dans l'espace $A(1)$}\label{schedP::1}
		\end{table}
		
		L'espace de tolérance $A(1)$ est alors représenté par
                l'ensemble d'équations \ref{equations::1} et est schématisé
                dans la Figure \ref{space::1}, avec $A_3(1)=0$.
		\begin{equation}
			\left\{
				\begin{split}
					& A_1(1) \leq 7 \wedge A_1(1) \leq 6 \\
					& A_2(1) + A_1(1) \leq 5 \wedge A_2(1) \leq 2 \\
					& A_3(1) + A_2(1) + A_1(1) \leq 2 \wedge A_3(1) \leq 0
				\end{split}\label{equations::1}
			\right.
		\end{equation}
		
	\begin{figure}[h!]
		\centering
		\includegraphics[scale=0.25]{./figures/A1_space.png}
		\caption{Espace de tolérance $A(1)$}\label{space::1}
	\end{figure}
	\item[$\bullet$] Espace de tolérance $A(2)$: L'ensemble de points
          d'ordonnancement à considérer est donné dans la Table \ref{schedP::2}. \\
		\begin{table}[h!]
		\begin{center}
			\begin{tabular}{|c||c|}
				\hline
				$\tau_i$ & $\mathrm{schedP}_i$ \\
				\hline
				\hline
				$\tau_1$ & \{8\} \\
				\hline
				$\tau_2$ & \{7\} \\
				\hline
			\end{tabular}
		\end{center}
		\caption{Points d'ordonnancement dans l'espace $A(2)$}\label{schedP::2}
		\end{table}
	
	
		L'espace de tolérance $A(1)$ est alors représenté par
                l'ensemble d'équations \ref{equations::2}.
		\begin{equation}
			\left\{
				\begin{split}
					& A_1(2) \leq 5 \wedge A_1(2) \leq 4 \\
					& A_2(2) + A_1(2) \leq 1 \wedge A_2(2) \leq 0
				\end{split}\label{equations::2}
			\right.
		\end{equation}
		menant à $A_1(2)=1$ et $A_2(2)=0$.
	\item[$\bullet$] Espace de tolérance $A(3)$: L'ensemble de points
          d'ordonnancement à considérer est donné dans la Table \ref{schedP::3}. \\
		\begin{table}[h!]
		\begin{center}
			\begin{tabular}{|c||c|}
				\hline
				$\tau_i$ & $\mathrm{schedP}_i$ \\
				\hline
				\hline
				$\tau_1$ & \{8\} \\
				\hline
			\end{tabular}
		\end{center}
		\caption{Points d'ordonnancement dans l'espace $A(3)$}\label{schedP::3}
		\end{table}
		
		L'espace de tolérance $A(3)$ est alors représenté par
                l'équation \ref{equation::3}. Comme on peut le
                voir, aucune marge de tolérance strictement positive ne
                satisfait cette équation, entraînant $A_1(3)=0$.
		\begin{equation}
			A_1(3) \leq 1 \wedge A_1(3) \leq 0
		\label{equation::3}
		\end{equation}
\end{itemize}
\end{exmpl}
%%%%%%%%%% Allowance Implementation %%%%%%%%%%
\subsection{Implémentation de la marge de tolérance}\label{sec:allowanceImplementation}

Nous présentons maintenant un mécanisme en-ligne pour la gestion de la marge
de tolérance qui peut être implémenté en utilisant exclusivement des timers.
Nous appellerons ce mécanisme LET (\emph{Latest Execution Time}).

\begin{definition}
  Soit $t_i$ l'instant de requête du $k^\text{ième}$ job instancié par la
  tâche $\tau_i$, avec $\chi_i \geq \ell$. $\mathsf{LET}_i^{\ell}(t_i)$ est
  défini comme le moment d'exécution au plus tard $J_k^i$ en cas de
  dépassement de coût d'exécution pire cas de niveau $\ell$, jusqu'auquel  il
  n'est pas nécessaire de désactiver des tâches de criticité inférieure pour
  respecter les contraintes temporelles des tâches de criticité supérieure ou
  égale à $\ell$.
\end{definition}

Nous montrons maintenant comment calculer le $\mathsf{LET}$ d'une tâche
$\tau_i$, et ce $\mathsf{LET}$ sera utilisé pour déterminer l'instant à partir
duquel les tâches de criticité inférieure nécessitent d'être désactivées.

\begin{definition}
Soit $J_k^i$ le $k^\text{ième}$ job instancié à l'instant $t_i$ par la tâche
$\tau_i$ avec une criticité $\chi_i \geq \ell$. L'instant d'exécution au plus
tard (LET) pour $J_k^i$ au niveau de cricité $\ell$ est calculé à l'instant
$t_i$ comme suit:
	\begin{equation}
		\begin{split}
			&\forall \ell \in [1,\mathnormal{L}]: \\
			&\mathsf{LET}_i^{\ell}(t_i) = \max\left\lgroup t_i, \max\limits_{\tau_j \in \mathrm{hp}^R(i)} \left( \mathsf{LET}_j^\ell(t_j) \right) \right\rgroup \\
			&\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad+ C_i(\ell) + A_i(\ell)
		\end{split}
	\end{equation}
L'instant d'exécution au plus tard des jobs $J$ de $\mathrm{lp}^R(i,\ell)$ est
alors calculé comme suit:
	\begin{equation}
		\forall J \in \mathrm{lp}^R(i,\ell): \mathsf{LET}_j^{\ell}(t_j) = \mathsf{LET}_j^{\ell}(t_j) + C_i(\ell) + A_i(\ell)
	\end{equation}
\end{definition}

Basé sur le $\mathsf{LET}_i^{\ell}(t_i)$ d'un job dont le niveau de criticité
est supérieur à $\ell$, on peut initialiser le timer en charge de détecter un
dépassement d'exécution pire cas de niveau $\ell$ après lequel toutes les
tâches de criticité inférieure à $\ell$ doivent être désactivées. Nous
n'initialisons pas de timer pour les jobs dont la criticité est égale à
$\ell$ étant donné que nous ne serons pas sujet à un dépassement de coût d'exécution
de niveau $\ell$. Nous devons cependant calculer leur $\mathsf{LET}$ quand
bien même il serait nécessaire de calculer le $\mathsf{LET}$ des autres jobs.\\

\begin{exmpl}
L'implémentation de la marge de tolérance est illustrée en utilisant l'Exemple
\ref{ex:mcTaskSet1}, et il est assumé que toutes les tâches de criticité au
moins égale à $\ell+1$ peuvent être sujettes à un dépassement de coût
d'exécution de niveau $\ell$. La marge de tolérance et
l'instant d'excution au plus tard du premier job de chaque tâche calculés, ces
derniers sont représentés dans la Table \ref{ex:table}.
\begin{table}[h!]
	\begin{center}
		\begin{tabular}{|c||c|c|c|c|c|}
		\hline
			Task & $A_i(1)$ & $A_i(2)$ & $\mathsf{LET}_i^{1}(0)$ & $\mathsf{LET}_i^{2}(0)$ & $\mathsf{LET}_i^{3}(0)$ \\
		\hline
		\hline
			$\tau_3$ & 1 & 1 & 2 & 4 & 7 \\
		\hline
			$\tau_2$ & 1 & 0 & 4 & 7 & $\times$ \\
		\hline
			$\tau_1$ & 0 & 0 & 5 & $\times$ & $\times$ \\
		\hline
		\end{tabular}\caption{Exemple de trois tâches ordonnancées en priorité fixe}\label{ex:table}
	\end{center}
\end{table}

La Figure \ref{ex:LET0} illustre un scénario pour lequel à la fois $\tau_3$ et
$\tau_2$ dépassent leur coût d'exécution pire cas de niveau de criticité 1,
mais sans nécessiter d'interruption de la tâche $\tau_1$, qui possède encore
assez de temps pour terminer sa propre exécution. Si le mécanisme de marge de
tolérance n'avait pas été utilisé, la criticité du scénario aurait été
augmentée à l'instant 1, empêchant la tâche $\tau_1$ de compléter son
exécution.

\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.45]{./figures/Let(0).png}
		\caption{Exemple de $\mathsf{LET}_i^1(0)$}\label{ex:LET0}
	\end{center}
\end{figure}

De manière similaire, la Figure \ref{ex:LET1} illustre un scénario où $\tau_3$
dépasse son coût d'exécution pire cas de niveau de criticité 2, mais complète
son exécution suffisamment tôt pour éviter l'interruption de la tâche
$\tau_2$, qui possède encore assez de temps pour compléter son exécution pour
une durée égale à son coût d'exécution pire cas de son propre niveau de
criticité. Si le principe de marge de tolérance n'avait pas été utilisé, la
criticité du scénario aurait été augmenté à l'instant 3, empêchant la tâche
$\tau_2$ de compléter son exécution.
	
\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.45]{./figures/Let(1).png}
		\caption{Exemple de $\mathsf{LET}_i^2(0)$}\label{ex:LET1}
	\end{center}
\end{figure}

Pour finir, la Figure  \ref{ex:allowanceReuse} illustre la récupération de la
marge de tolérance.En effet, la tâche $\tau_3$ avait une marge de tolérance de
une unité de temps, mais a pu compléter son exécution avant de nécessiter son
usage. Cela a permis à la tâche $\tau_2$ de profiter de deux unités de temps
complémentaires pour terminer son exécution sans pour autant nécessiter
l'interruption de la tâche $\tau_1$.
	
\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.45]{./figures/AllowanceReuse.png}
		\caption{Récupération de la marge de tolérance}\label{ex:allowanceReuse}
	\end{center}
\end{figure}
\end{exmpl}

%%%%%%%%%% Resetting Criticality %%%%%%%%%%
\subsection{Réinitialiser la Criticité}\label{sec:resettingCriticality}

Le mécanisme présenté en Section \ref{sec:allowanceImplementation} nous permet
d'accroître le délai de suspension d'une tâche de criticité plus faible le
plus possible, empêchant de désactiver des jobs qui auraient pu avoir
suffisamment de temps pour compléter leur exécution. Néanmoins, dans certains
cas et à un niveau de criticité donné, une tâche peut nécessiter plus de temps
pour compléter son exécution que la marge de tolérance ne lui permet. Dans ce
cas, le niveau de criticité du scénario a besoin d'être augmenté.\\
Dans cette Section, nous étudions la pertinence de conserver les tâches de
priorité inférieure suspendues. Nous pensons que, si il est nécessaire de
susprendre des tâches de priorité inférieure pour garantir les contraintes
temporelles de tâches de criticité supérieure, cette décision reste
réversible, et qu'il existe un instant où toutes les tâches peuvent de nouveau
s'exécuter en concurrence, quel que soit leur niveau de criticité.\\

Au travers de cette Section, nous pensons à l'inverse de ce que le
Lemme \ref{lem1} suggère, à savoir que dès que le scénario atteint le niveau de criticité
$\ell$, toutes les tâches de criticité inférieure nécessitent d'être
désactivées.
Les définitions et résultats que nous présentons peuvent néanmoins être
adaptés pour prendre en compte le Lemme \ref{lem1}.

\begin{definition}
Si le scénario courant est de niveau de criticité $\ell$, un instant
d'inactivité de niveau $\ell$ (level-$l$ idle time) $t$ sur le processeur est défini comme un instant
durant lequel aucun job de criticité au moins égale à $\ell$ n'est disponible,
en attente d'ordonnancement à l'instant $t$.
\end{definition}

\begin{theorem}\label{theo:decreaseCriticality}
Soit $\tau$ un ensemble de tâche périodique à criticité mixte
ordonnançable. Dès que un instant d'inactivité de niveau $\ell$ se produit
dans l'ordonnancement de $\tau$, le niveau de criticité du scénario peut être
réinitialisé à sa valeur la plus basse.
\end{theorem}

\begin{proof}
Soit $t_{\text{idle}}$ le premier instant d'inactivité de niveau $\ell$ dans
l'ordonnancement de $\tau$ (avec $t_{\text{idle}} > 0$). Cela signifie que
tous les jobs instanciés par une tâche dont le niveau de criticité est au moins
aussi élevé que que la criticité du scénario à l'instant $t_{\text{idle}}$ ont
complété leur exécution, et qu'aucun job n'est disponible. Soit $\tau_i$
n'importe quelle tâche de $\tau$ qui a été désactivée avant $t_{\text{idle}}$.
Nous devons montrer qu'à l'instant $t_{\text{idle}}$, tous les jobs instanciés
par $\tau_i$ peuvent à nouveau recevoir $C_i(\chi_i)$ unités de temps pour
leur exécution dans n'importe scénario de criticité d'au plus $\chi_i$. Soit
$J_i$ le premier job instancié par $\tau_i$ à l'instant $t_i$ ($t_i \geq
t_{\text{idle}}$). On distingue deux cas:
  
 \begin{enumerate}
	\item $t_i$ est l'instant critique pour $\tau_i$: il en suit que le
          temps de réponse de $J_i$ sera le plus grand parmis tous les jobs
          instancié par $\tau_i$. Mais comme $\tau$ est ordonnançable au sens
          de la criticité mixte, nous
          savons que $J_i$ respecte malgré tout son échéance si il s'exécute
          jusqu'à $C_i(\chi_i)$ unité de temps et que aucune des autres tâches $\tau_j$
          n'instancie de job qui s'exécute pour plus de $C_j(\chi_i)$ unités
          de temps.
	\item $t_i$ n'est pas un instant critique pour $\tau_i$: dans ce cas,
          nous savons que le temps de réponse de $J_i$ sera inférieur ou égal
          au coût d'exécution pire cas de la tâche $\tau_i$. Mais nous avons
          prouvé que $J_i$ peut respecter son échéance si il avait été
          instancié à un instant critique pour la tâche. Il en suit que $J_i$
          reespectera également son échéance dans un instant non-critique.
\end{enumerate}
\end{proof}

\begin{exmpl}
Considérons une nouvelle fois l'ensemble de tâches $\tau$ présenté dans
l'Exemple \ref{ex:mcTaskSet1}, et un scénario possible pour cet ensemble de
tâche illustré dans la Figure \ref{ex:decreaseCriticality}. Le premier job
instancié par la tâche $\tau_3$ complète son exécution après 7 unités de
temps. Le niveau de criticité du scénario a alors atteint le niveau 2 à
l'instant $t = 1$, et le niveau 3 à l'instant $t = 3$. En conséquence, à la
fois $\tau_1$ et $\tau_2$ ont été désactivées. A l'instant $t = 7$, un instant
d'inactivité de niveau 3 se présente, donc le niveau de criticité peut alors
être réinitialisé à 1, et les jobs instanciés par $\tau_1$ et $\tau_2$ peuvent
être à nouveau considérés. La tâche $\tau_2$ instancie son job suivant à
l'instant $t = 7$, mais il est préempté par la tâche $\tau_3$ à l'instant $t =
8$. Etant donné que $\tau_3$ a complété son exécution, après 3 unités de temps, le
niveau de criticité du scénario atteint la valeur 2, et la tâche $\tau_1$ doit
être désactivée. Cependant, $\tau_2$ est encore apte à respecter son échéance.
A l'instant $t = 13$, un instant d'inactivité de niveau 2 se présente, et le
niveau de criticité est réinitialisé à nouveau. Cela permet à toutes les
tâches d'instancier un job de nouveau apte à respecter son échéance.
\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.5]{./figures/decreaseCriticality.png}
		\caption{Diminution de priorité}\label{ex:decreaseCriticality}
	\end{center}
\end{figure}
\end{exmpl}

%%%%%%%%%% Simulations %%%%%%%%%%
\subsection{Simulations}\label{sec:simulation}

Dans cette Section, on compare les performances de trois solutions possible
pour traiter l'accroissement de criticité lors de l'ordonnancement d'ensembles
de tâches à criticité mixte:
\begin{enumerate}
	\item L'approche traditionnelle (TA): dès qu'une tâche $\tau_i$
          dépasse son coût d'exécution pire cas de niveau de criticité $\ell$,
          la criticité du scénario est augmentée, et toutes les tâches
          $\tau_j$ avec $\chi_j = \ell$ ayant une priorité inférieure à
          $\tau_i$ sont désactivées.
	\item L'approche traditionnelle, étendue avec un mécanisme de
          diminution de criticité (CD):dès qu'une tâche $\tau_i$ dépasse son
          coût d'exécution pire cas de niveau de criticité $\ell$, la
          criticité du scénario est augmentée et toutes les tâches $\tau_j$
          avec $\chi_j = \ell$ ayant une priorité inférieure à $\tau_i$ sont
          désactivées. Néanmoins, dès qu'un instant d'inactivité de niveau
          $\ell$ se présente, la criticité du système est réinitialisée à sa
          valeur la plus basse.
	\item L'approche traditionnelle, étendue avec un mécanisme de
          diminution de criticité et avec le concept de marge de tolérance
          (CD-A): dès qu'une tâche $\tau_i$ dépasse son
          coût d'exécution pire cas de niveau de criticité $\ell$ plus sa
          marge de tolérance, la criticité du scénario est augmentée et toutes
          les tâches $\tau_j$ avec $\chi_j = \ell$ ayant une priorité inférieure
          à $\tau_i$ sont désactivées. Néanmoins, dès qu'un instant
          d'inactivité de niveau $\ell$ se présente, la criticité du scénario
          est réinitialisée à sa valeur la plus basse.
\end{enumerate}

A chaque job $J_k^i$ instancié par une tâche $\tau_i$ est assignée une durée
$c_{i,k}^e$ dans l'intervalle $[1,C_i(\chi_i)]$, en utilisant une distribution
triangulaire. Sachant qu'un job ne termine son exécution ni après un très
court instant ni après une très longue durée mais plutôt après une durée
intermédiaire, l'usage d'une distribution triangulaire est un moyen de
représenter cette probabilité. Ainsi, ce qui suit permet de concentrer la
plupart des probabilités autour d'une valeur appelée le {\it mode}. Comme le
montre la Figure \ref{fig:triangularDistribution}, pour une tâche $\tau_i$, la
limite basse de la distribution est mise à 0, et la limite haute à
$C_i(\chi_i)$, et le mode de la distribution est égal à
$\frac{C_i(\chi_i)}{3}$. Cela signifie qu'un job va la plupart du temps
terminer son exécution après une consommation proche de 33\% de son coût
d'exécution pire cas de son niveau de criticité propre. Nous générons alors un
nombre aléatoire $r$ qui suit cette distribution particulière, et $c_{i,k}^e =
\lceil r \rceil$.

\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.3]{./figures/triangularDistribution.png}
		\caption{Distribution triangulaire pour la tâche $\tau_i$}\label{fig:triangularDistribution}
	\end{center}
\end{figure}

La durée exacte de chaque job est complètement indépendante de la durée exacte
des jobs précédents instanciés par la même tâche. Un job $J_k^i$ complètera
son exécution dès que l'ordonnanceur lui aura fourni un total de $c_{i,k}^e$
unités de temps, mais cette durée n'est pas connue à l'avance par
l'ordonnanceur.\\

Nous analysons les ensembles de tâches $\tau$ composés d'un nombre de tâches à
criticité mixte $|\tau|$ variant entre 4 et 8, avec une criticité bornée par
4. Pour l'approche CD-A, le nombre de tâches en faute est mis à $k = |\tau|$,
pour s'assurer que la criticité est augmentée du fait d'une tâche dépassant
son coût d'exécution pire cas à un niveau de criticité donné plus sa marge de
tolérance, et non parce que le nombre de tâches en faute dépasse $k$.

Nous avons comparé le nombre moyen de jobs qui ont dû être supprimés par les
trois méthodes. Nous avons alors généré 100 ensembles de tâches à criticité
mixte et réitéré les simulations pour de multiples bornes supérieures sur
chaque charge de tâche (on réfère à cette borne supérieure en tant que
$U_{\text{max}}(\tau_i)$). Le Tableau \ref{fig:results} et la Figure
\ref{fig:resultsGraphical} présentent les résultats de ces simulations. L'axe
des X représente la charge maximum par tâche $U_{\text{max}}(\tau_i)$,
tandis que l'axe des Y représente le pourcentage moyen de jobs ayant été
supprimés.

\begin{table}[h!]
	\begin{center}
		\begin{tabular}{|c||c|c|c|}
			\hline
			$U_{\text{max}}(\tau_i)$ & TA & CD & CD-A \\
			\hline
			\hline
			0.1	& 33.4223\% & 9.3976\% & 1.4071\% \\
			\hline
			0.2 & 32.9436\% & 11.7511\% & 4.2982\% \\
			\hline
			0.3	& 34.0782\% & 13.3883\% & 6.2279\% \\
			\hline
			0.4	& 38.2408\% & 15.6153\% & 9.4358\% \\
			\hline
			0.5	& 42.7098\% & 19.4652\% & 13.052\% \\
			\hline
			0.6	& 42.3251\% & 20.0583\% & 14.2854\% \\
			\hline
			0.7	& 42.9011\% & 21.8738\% & 16.7087\% \\
			\hline
			0.8	& 48.0304\% & 23.05\% & 17.1582\% \\
			\hline
			0.9	& 50.266\% & 24.0808\% & 19.1672\% \\
			\hline
			1.0 & 50.1776\% & 26.1121\% & 21.1875\% \\
			\hline
		\end{tabular}\caption{Pourcentage moyen de job supprimés en fonction de  $U_{\text{max}}(\tau_i)$}\label{fig:results}
	\end{center}
\end{table}

\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.57]{./figures/resultats.png}
		\caption{Pourcentage moyen de jobs supprimés en fonction de la charge\label{fig:resultsGraphical}}
	\end{center}
\end{figure}

Nous observons que le mécanisme de diminution de criticité peut réduire le
nombre de jobs supprimés de 25\% dans le pire cas, tandis que cette réduction
peut atteindre plus de 30\% lorsque la charge de chaque tâche est faible.
Nous constatons de plus que ce mécanisme est accrût avec la marge de
tolérance, le nombre de job supprimés étant réduit de 5\% à 9\% de plus.\\

Nous observons que plus la charge de chaque tâche est faible, plus le
mécanisme de marge de tolérance est efficace. Cela est du au fait qu'une marge
de tolérance plus grande peut être apportée à chaque tâche.

%%%%%%%%%% Conclusion %%%%%%%%%%
%\subsection{Conclusion}\label{conclusion}
%In this paper, we have studied two principles that allow us to relax the strictness of mixed-criticality
%tasks scheduling using a fixed priority strategy. Those principles are the allowance on WCETs and the
%criticality decreasing mechanism. We showed how the allowance could be computed using feasibility conditions
%relying on the worst-case response time of a task according to a criticality level, and suggested a simple
%mechanism that implements it denoted LET. We then proved that idle times could be used to decrease the
%overall criticality of the system. Experiments furthermore attested that the criticality decreasing mechanism 
%Mcould reduce up to 24\% the number of jobs that had to be suspended, while the allowance could decrease
%this number by an additional 8\%.


\subsection{Conclusion}\label{conclusion}
Le principe de criticité mixte peut donc être intégré dans la passerelle afin
de pouvoir traiter au mieux l'ensemble des tâches nécessaires pour répondre au
besoin systronique sur un environnement matériel limité, formalisé par
l'Exigence \hyperlink{REQTEMPS002}.\\
Les différents ensembles de tâches à criticité mixte, intégrés chacun dans un compartiment
spatial et temporel autonome pour des raison de sécurité, peuvent être ordonnancés de
manière efficace en intégrant à la fois le concept de marge de tolérance et le
concept de réinitialisation de la criticité. Il reste cependant une limitation
en terme d'affinité de l'ensemble de tâche, limité pour le moment à un seul
c{\oe}ur du processeur. Dans le cadre de ma thèse, je considère que de tels ensembles de
tâches sont seuls sur le c{\oe}ur du processeur sur lequel ils sont assignés. Néanmoins, en cas de
partage du c{\oe}ur entre plusieurs compartiments en mode TDM parmis lesquels
au moins un compartiment habrite un ensemble de tâches à criticté mixte, l'ordonnançabilité
d'un tel ensemble doit être résolue.

