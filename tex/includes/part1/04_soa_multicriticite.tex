%%
%%
%% hardware_impacts.tex for thesis in /doctorat/these/tex
%%
%% Made by Philippe THIERRY
%% Login   <Philippe THIERRYreseau-libre.net>
%%
%% Started on  Fri Mar 12 16:36:41 2010 Philippe THIERRY
%% Last update Mon Aug 30 17:00:21 2010 Philippe THIERRY

\chapter{L'ordonnancement hiérarchique de tâches}
\label{sec:hierarchique}
\doMinitoc

\paragraph{}
{\it Afin de répondre au besoin des architectures MILS et MLS, l'usage d'un
separation kernel est une des solutions logicielles proposée. Cette
architecture, impliquant potentiellement la virtualisation de certaines
tâches, induit un ordonnancement hiérarchique de ces dernières. Dans ce
chapitre est décrit l'état de l'art de l'ordonnancement hiérarchique.}

\section{Principe de l'ordonnancement hiérarchique}

\subsection{Principes généraux et théorie de l'ordonnancement hiérarchique}

\paragraph{}
On parle d'ordonnancement hiérarchique lorsqu'une tâche est ordonnancée au
travers de deux politiques d'ordonnancement distinctes hiérarchisées. Dans les
systèmes temps réels, on considère alors un ensemble de jeux $\Gamma_i$ de
tâches exécutés en concurrence. Pour chaque jeux de tâches, on considère un ensemble de tâches
$\tau^i_j$ qui lui sont associées. On définit alors
\begin{enumerate}
\item Une politique d'ordonnancement des jeux de tâches, nommé ordonnancement
global
\item Une politique d'ordonnancement des tâches dans un jeu donné, nommé
ordonnancement local
\end{enumerate}

\paragraph{}
L'ordonnancement hiérarchique a été beaucoup étudié ces dernières années. La
capacité à ordonnancer de manière concurrente des jeux de tâches sur un même
c{\oe}ur processeur permet de pouvoir prendre en considération des classes de
tâches et différencier leur ordonnancement en fonction de leur profil. Ces
différents travaux ont pour hypothèse une connaissance initiale de l'ensemble
des tâches, hypothèse d'entrée exigée dans les systèmes temps réels
dur\cite{methodhierarchical}. 

\paragraph{}
La répartition des tâches par familles se fait en fonction des exigences de
réactivité. La Figure \ref{fig:hierarchical_sample} décrit une répartition
classique telle que décrite dans \cite{methodhierarchical}.

\begin{figure}
\label{fig:hierarchical_sample}
\input{figures/hierarchical_sample.tex}
\caption{Répartition type des tâches par jeux autonomes, en fonctions des exigences de réactivité}
\end{figure}

\paragraph{}
Analyse de concurrence des systèmes temps réels à ordonnancement hierarchique
\cite{regehr_evolving_2003}\\
Calcul du temps de réponse sur un système temps réel à ordonnancement
hierarchique sur base de priorité fixe
\cite{balbastre_exact_2009}\\
Ordonnancement hiérarchique SMP
\cite{chandra_hierarchical_2008}\\
Le rôle de la virtualisation dont les systèmes embarqués
\cite{heiser_role_2008}



\subsection{Ordonnancement hiérarchique et principe de virtualisation}

\paragraph{}
Lorsque la hiérarchisation de
l'ordonnancement provient du principe de virtualisation, les deux politiques
d'ordonnancement s'ignorent souvent l'une l'autre. En conséquence, les ordonnanceurs
en-ligne ne sont plus éligibles pour l'ordonnancement global, faute d'information sur la politique
d'ordonnancement intérieur à chaque jeu de tâche. Ce dernier est donc en
général de type FP (Fixed Priority). Ce type de restriction est décrit dans
\cite{cucinotta_respecting_2009} où les auteurs expliquent l'impact de
l'ordonnanceur global sur la capacité des tâches virtualisées à rester
ordonnançable. Différents travaux \cite{cucinotta_respecting_2009}\cite{rtvm} ont été
fait sur la base de solution open-source comme Xen\cite{barham2003xen} ou
KVM\cite{kivity2007kvm}.

\paragraph{}
Du fait de la hiérarchisation de l'ordonnancement des tâches, on parle alors
de d'un ordonnancement de type X/Y, ou X spécifie l'ordonnancement des
machines virtuelles $\Gamma_i, i \in { a, b, c ... }$, Y définissant
l'ordonnancement des tâches $\tau^i_j$ de la machines virtuelle $\Gamma_i$.\\
Un exemple d'ordonnancement hiérarchique est l'EDF/RM, où les tâches sont
ordonnancées suivant une politique de type EDF et les jeux de tâches des
différentes machines virtuelles sont ordonnancés suivant une politique de type RM.
Les calculs d'ordonnançabilité sont impactés par le principe de hiérarchie, et nécessitent donc
d'être considérés de manière spécifique.

\paragraph{}
Du fait de la hiérarchisation de l'ordonnancement des tâches, on parle alors
de d'un ordonnancement de type X/Y, ou X spécifie l'ordonnancement des
machines virtuelles $\Gamma_i, i \in { a, b, c ... }$, Y définissant
l'ordonnancement des tâches $\tau^i_j$ de la machines virtuelle $\Gamma_i$.\\
Un exemple d'ordonnancement hiérarchique est l'EDF/RM, où les tâches sont
ordonnancées suivant une politique de type EDF et les jeux de tâches des
différentes machines virtuelles sont ordonnancés suivant une politique de type RM.
Les calculs d'ordonnançabilité sont impactés par le principe de hiérarchie, et nécessitent donc
d'être considérés de manière spécifique.


\paragraph{}
Dans la solution Xen, une implémentation de S-EDF a été faite afin d'assurer
une réservation de ressource CPU minimum dans une fenêtre temporelle aux
différentes machines virtuelles. Cependant, cette solution a ses limitations,
principalement lorsque les tâches temps réelles impliques un grand nombre
d'entrées/sorties, impactant le respect de l'ordonnancement des autres
machines virtuelles\cite{cucinotta_respecting_2009}.\\
KVM utilise une architecture différente, puisqu'il implique un hôte pouvant
ordonnancer des tâches potentiellement temps réel à côté de machines
virtuelles. Dans ce cas, les tâches natives (non virtualisées) impactent
potentiellement fortement l'ordonnancement des machines virtuelles et des jeux
de tâches associés, comme le décrivent T. Cucinotta, g. Anastasi et L. Abeni
dans \cite{rtvm}. L'emploi d'un ordonnanceur de type CBS (Constant Bandwidth Server\cite{abeni1998integrating})
permet d'assurer une réservation stricte de charge processeur pour les
différentes machines virtuelles, limitant fortement l'impact des tâches
natives. La gestion concurrentes de jeux de tâches temps réels virtualisé et
de jeux de tâches natifs (ordonnancés directement par l'hôte) est donc un
problème complexe à résoudre. Dans le cadre des architectures MILS, ce type
d'architecture est malheureusement nécessaire afin de pouvoir traiter les
moniteurs de sécurité comme des tâches du {\it separation kernel}, ces
dernières ne pouvant être intégrés à un OS virtualisés sans perdre leur
certifiabilité.

%saewong2002analysis

\section{A propos de l'ordonnancement hiérarchique sur base TDM}

\paragraph{}
La considération d'un ordonnancement de jeu de tâche de type TDM est un cas
intéressant d'ordonnancement hiérarchique. Les jeux de tâches sont ordonnancés
de manière stricte via la définition d'un motif répétitif d'ordonnancement. La
politique d'ordonnancement des tâches doit donc considérer deux propriétés:
\begin{itemize}
\item La charge processeur allouée au compartiment, impactant la capacité à
ordonnancer les tâches en terme de charge
\item La période d'élection du compartiment, impactant la capacité à respecter
les deadlines des tâches
\end{itemize}

\paragraph{}
J'ai étudié cette problématique d'ordonnançabilité afin de valider le fait
que plusieurs jeux de tâches ordonnancés en TDM restaient certifiable en terme
d'ordonnançabilité pure\cite{tdmsched}.


\chapter{A propos de l'état de l'art de l'ordonnancement de tâche à multiple criticité}
\doMinitoc

\section{Principe de la multi-criticité}

\subsection{Propriété des tâches multi-critique}

\paragraph{}
En 2007, S. Vestal\cite{vestal2007preemptive} a décrit le principe d'une tâche
multi-critique. On définit une tâche à multiple criticité en définissant
plusieurs pire cas d'exécution (WCET), chaque WCET étant associé à un niveau
de criticité. La multiplicité des coûts d'exécution pire cas viens du niveau
d'assurance exigé par chaque niveau de criticité. Plus ce dernier est élevé,
plus l'assurance demandée par la certification est forte. En conséquence, la
mesure d'exécution pire cas est de plus en plus pessimiste afin de garantir
que la tâche respecte son WCET. Ainsi, une tâche de faible niveau de criticité
peut s'appuyer sur une mesure probabiliste, dont le WCET est forcément plus
faible qu'une mesure formelle du profil d'exécution d'une tâche.

\paragraph{}
On définit pour chaque tâche de l'ensemble de tâches un niveau de criticité en
fonction de son importance. Un système s'exécute par défaut dans le domaine de
criticité le plus faible. Si une tâche de criticité supérieure au domaine
courant dépasse le WCET qui lui est donné pour ce domaine, on
considère qu'il faut changer de domaine de criticité. On accroît alors le
domaine de criticité du système et on désactive les tâches dont le niveau de
criticité est inférieur au nouveau domaine de criticité actif. Ceci est fait afin de
maintenir l'ordonançabilité des tâches critiques, ces dernières ayant alors un
WCET plus élevé, correspondant à celui du domaine de criticité nouvellement
actif.

%To insert: \cite{handlemulticrit}

\subsection{A propos De l'ordonnancement d'un taskset multi-critique}

\paragraph{}
Mixed-Criticality scheduling is an emerging research domain and one which is gaining
increasing interest. Vestal \cite{Vestal2007} initially introduced
the mixed-criticality task model. In his work, he highlighted the difficulty in computing
exact worst-case execution times, and observed that in practice, the higher the degree
of assurance required that a task will never exceed its worst-case execution time, the
more conservative the approximation of the latter becomes. This degree of assurance is
characterized by a level of criticality. He also suggested a fixed-task-priority strategy
based on the Audsley priority assignment scheme \cite{Audsley_1991}. Dorin et al.
\cite{Dorin2010} proved that under the restricted case of independent 
task systems with constrained-deadlines, Vestal's modified Audsley's approach was optimal
in the class of fixed-task priority algorithms. Nowadays, the Mixed-Criticality
(MC)-Schedulability problem is commonly known to arise in two different contexts. The first
one is concerned with applications that are subject to multiple certification requirements.
In this context, different Certification Authorities (CA) need to validate the application
functionalities. Nevertheless, the more critical a functionality is, the more pessimistic
the CA will be in the approximation of the WCET. Baruah et al. \cite{Baruah2010}
studied mixed-criticality systems in this context, but restricted their work to a set of
mixed-criticality jobs. In particular, Baruah \cite{bbalmms} pointed out the intractability
of the MC-Schedulability problem, and quantified the fundamental limitations of MC-Scheduling
for certification considerations. To tackle the intractability of MC-Scheduling, they suggest
two sufficient schedulability conditions, referred to as the WCR-schedulability and
OCBP-schedulability conditions. Later, Baruah and Li \cite{Li2010} extended
their previous work and suggested a fixed-job-priority scheduling strategy based on their
OCBP-schedulability condition. Baruah et al. also adapted the Earliest Deadline First algorithm
to mixed-criticality systems, by modifying the deadlines of tasks. This approach is known as
EDF-VD. More recently, Guan et al. \cite{gpmw} presented a new approach for scheduling
mixed-criticality systems, which relies on an offline fixed-job-priority ordering computation,
which is then used on-line by the scheduler. At the same time, Baruah et al. \cite{RBaruah2011a}
formalized the response time analysis for mixed-criticality tasks. \\
The second context in which mixed-criticality is defined considers that among all functionalities
deployed on a single computing platform, some might be more critical, in the sense that they are
more important, than others. In this context, Lakshmanan et al.
\cite{Niz2009,Lakshmanan2011} observe that a reservation
based approach, meant to isolate functionalities and prevent interferences, might lead to a
criticality inversion problem, where a less critical task is favoured over a high critical task
because the latter exceeded its reserved time partition. They suggested a new approach, termed
zero-slack scheduling, to avoid this problem.\\
Sensitivity analysis was previously studied by Bini et al.
\cite{bini_buttazzo,Bini2006}. They discussed the concept of a feasibility
region which allows one to determine the space of possible values for a particular task parameter.
The allowance mechanism was initially introduced by Bougueroua et al. \cite{bougueroua_george_midonnet}
in the context of traditional task sets subject to WCET overruns faults. Their work focused on
determining the largest value that could be added to a task's worst-case execution time such that
the whole task set remains schedulable, assuming a sliding window fault model.

