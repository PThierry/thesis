%%
%%
%% software_impacts.tex for thesis in /doctorat/these/tex
%%
%% Made by Philippe THIERRY
%% Login   <Philippe THIERRYreseau-libre.net>
%%
%% Started on  Fri Mar 12 16:42:22 2010 Philippe THIERRY
%% Last update Fri Feb  4 13:40:15 2011 Philippe THIERRY
%%

\chapter{Software impact}
\doMinitoc

\section{On the operating system complexity}

\subsection{About the different existing software architectures}

\subsubsection{Real-Time operating systems}

FIXME: voir avec JML, DR et Laurent les architectures de moninteurs

\subsubsection{Modular and monolithic kernel architectures}

\paragraph{}
Les noyaux monolitiques et modulaires  sont  des  logiciels  riches,  fournissant  un  grand  nombre
de services aux processus qu'ils gèrent.\\
Il fournissent ainsi les éléments de base comme  la  gestion  du  matériel  sous-jacent,  de  l'ordonnancement
ou encore de la mémoire, mais également des services à  valeur  ajoutée,  comme  les  pilotes  des  différents
périphériques matériels, les implémentations de protocoles comme les piles réseau, USB,  et  ainsi  de  suite.

\paragraph{}
Un système s'appuyant sur une architecture de type noyau monolithique ou modulaire, comme  Windows  ou  Linux,
est par essence un système intelligent, mais dont le comportement du noyau  est  difficilement  prédictible.\\
En effet, du fait d'héberger une grande partie de la complexité logicielle dans le noyau génère une consommation
de cycles processeurs par celui-ci beaucoup plus importante.  Ainsi, les traitements effectués  par  le  noyau
qui ne sont pas dépendant d'un réveil par un processus ordonnancé, comme le routage de flux  réseau,  provoque
en conséquence des perturbations dans le calcul du WCET si ceux-ci  ne  sont  pas  pris  en  compte.

\paragraph{}
Ainsi, l'emploi d'un noyau monolithique faisant du traitement de flux réseau génère un overhead  mesurable  de
manière empirique.  Malheureusement, la richesse des fonctionnalitées hébergées  dans  le  noyau  implique  de
maîtriser complètement l'environnement  d'exécution  et  pas  seulement  l'ensemble  les  processus  hébergés.
Cette maîtrise est rarement effective dans les cas réels.

\subsubsection{Micro-kernel architecture}

\paragraph{}
Les micro-noyaux, à l'inverse de noyaux monolithiques, ne  traîtent  qu'un  ensemble  de  service
restreints.\\
On retrouve ainsi  la  gestion  du  BSP\footnote{pour  les  systèmes  embarqués,  ensemble  du  code
spécifique à la carte fournissant une couche de base utilisable pour le noyau.   Il  contient  entre
autre un support minimum pour pouvoir charger le noyau et les pilotes minimum au bon  fonctionnement
du noyau lui-même} et les services de base que sont le support de la  mémoire  (implémentation  d'un
allocateur mémoire type mmap, le support de l'ordonnancement (plus ou moins riche), la  gestion  des
interruptions et des exceptions, et la  gestion  des  processus  (cration,  destruction  de  taches,
en  couplage   avec   l'ordonnanceur).

\paragraph{}
Ces services de base ont l'avantage de consommer peu de cycles processeur.   Ainsi,  la  maîtrise  du  taskset
permet de borner le coût d'exécution des éléments de  création  de  taches  ou  encore  d'ordonnancement.   La
gestion des exceptions et des interruptions  pose  par  essence  des  problématique  de  prédictibilité,  mais
il est envisageable de définir une borne suppérieure en  terme  de  WCET\footnote{confer  la  partie  suivante
FIXME: faire une ref}, permettant en conséquence de  rester  compatible  des  exigences  de  temps  réel  dur.

\paragraph{}
La faible empreinte CPU des micro-noyaux implique cependant de  réintégrer  au  niveau  du  jeu  de  tâche  la
richesse perdue au niveau noyau.  Ainsi,  les  pilotes  de  périphériques,  les  piles  protocolaires  doivent
être implémentées en tant que  tache(s)  logicielle(s)  ordonnancée(s)  (du  point  de  vue  du  micro-noyau).
Ainsi, un traitement de type routage de flux réseau entre  en  compte  dans  le  calcul  de  l'oronnançabilité
d'un jeu de tache comme un tache à part entière, et permet ainsi d'en contrôler l'ordonnancement et  l'impact.

\paragraph{}
On intègre ainsi l'ordonnancement de tâches faisant du traitement de flux au travers  d'un  lien  de
dépendance d'exécution entre les différentes tâches et la pile réseau  à  proprement  parlé.   Dans  le  cadre
d'un ordonnancement strict, il devient possible de mesurer le volume  de  flux  maximum  pouvant  être  traité
par le système, sans impacter les autres tâches.

\paragraph{}
Une telle architecture peut ainsi être prise en compte dans un système hybride faisant à la fois  du
routage de flux en "tache de  fond"  et  du  traitement  frontal  (par  exemple  cartographie,  communication)
comme on peut  par  exemple  l'imaginer  dans  le  cas  de  terminaux  légers  sur  réseaux  ad-hoc.

%\subsubsection{}

\section{The scheduler overhead}

\paragraph{}
L'exécution de l'ordonnanceur possède également un coût.  Selon l'implémentation, ce coût peut  être
en $O(1)$, en $O(n)$ voire plus.  Le coût  d'exécution  de  l'ordonnanceur  est  bornable  et  l'on
pourrait intégrer son coût comme une tache.  Cependant, son shéma d'exécution ne  correspond  pas  à
celui de l'ensemble de tache qu'il ordonnance.  Ainsi ce dernier ne peut être  considéré  comme  une
tache de l'ensemble de taches courant, mais comme un surcoût à intégrer à l'ensemble des  taches  de
l'ensemble de tache.\\
Il est donc nécessaire à la fois de connaître le WCET de l'ordonnanceur, mais également de connaître
le nombre de préemption maximum de chaque tache afin de pouvoir définir une borne maximum du surcoût
de l'ordonnanceur.  La difficulté revient ici à définir une  borne  la  moins  pessimiste  possible.

\section{Software architecture}

\subsection{On the software call tree and branching impact}

\subsection{The memory consumption and memory mapping}

Data alignment should also be in this section.

\subsection{The I/O usage and its impact}

\subsection{Critical sections and lock management}

\subsection{Software parallelism}

Threads, parallèlisations par optimisation

\section{Toolchain behaviour and effects}

Alignement  des   structures   de   données   sur   les   lignes   de   caches,   en   fonction   de
l'algorithme de gestion de cache.
Optimisation...
